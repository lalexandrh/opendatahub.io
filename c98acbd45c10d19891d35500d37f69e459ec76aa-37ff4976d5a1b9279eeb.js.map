{"version":3,"file":"c98acbd45c10d19891d35500d37f69e459ec76aa-37ff4976d5a1b9279eeb.js","mappings":"2LAAA,+qBCIO,MAAMA,EAAuC,CAChD,CACIC,MAAO,2BACPC,KAAM,mCAEV,CACID,MAAO,0BACPC,KAAM,kCAEV,CACID,MAAO,qCACPC,KAAM,6CAEV,CACID,MAAO,mCACPC,KAAM,2CAEV,CACID,MAAO,mCACPC,KAAM,2CAEV,CACID,MAAO,uBACPC,KAAM,wBAEV,CACID,MAAO,sCACPC,KAAM,8CAEV,CACID,MAAO,mBACPC,KAAM,2BAEV,CACID,MAAO,0CACPC,KAAM,kDAEV,CACID,MAAO,iCACPC,KAAM,yCAEV,CACID,MAAO,iCACPC,KAAM,yCAEV,CACID,MAAO,qCACPC,KAAM,6CAEV,CACID,MAAO,4BACPC,KAAM,oCAEV,CACID,MAAO,sCACPC,KAAM,8CAEV,CACID,MAAO,qDACPC,KAAM,0DAEV,CACID,MAAO,kDACPC,KAAM,wCAEV,CACID,MAAO,2BACPC,KAAM,mCAEV,CACID,MAAO,yBACPC,KAAM,uBAEV,CACID,MAAO,qBACPC,KAAM,6BAEV,CACID,MAAO,yCACPC,KAAM,iDAEV,CACID,MAAO,eACPC,KAAM,sBAEV,CACID,MAAO,oBACPC,KAAM,2BAEV,CACID,MAAO,UACPC,KAAM,sBACNC,SAAU,CACN,CACIF,MAAO,gBACPC,KAAM,uBAEV,CACID,MAAO,kBACPC,KAAM,mBA2UTE,GA3KqBC,EAAAA,EAKAA,EAAAA,EAYAA,EAAAA,EAKAA,EAAAA,EAaAA,EAAAA,EAKAA,EAAAA,EAKAA,EAAAA,EAiBAA,EAAAA,EAKAA,EAAAA,EAYAA,EAAAA,EAKAA,EAAAA,EAKAA,EAAAA,EAYAA,EAAAA,EAKAA,EAAAA,EAKAA,EAAAA,EAkBAA,EAAAA,EAKAA,EAAAA,EAKAA,EAAAA,EAcAA,EAAAA,EAKAA,EAAAA,EAKAA,EAAAA,EAQW,CACzC,OAAU,CACN,CACI,MAAS,gCACT,QAAW,IACX,SAAY,CACR,CACI,MAAS,gBAEb,CACI,MAAS,iBAEb,CACI,MAAS,cAEb,CACI,MAAS,2BAEb,CACI,MAAS,mCAEb,CACI,MAAS,4BAKzB,KAAQ,CACJ,CACI,MAAS,gCACT,QAAW,IACX,SAAY,CACR,CACI,MAAS,eACT,YAAe,4JAEnB,CACI,MAAS,gBACT,YAAe,2BAEnB,CACI,MAAS,cAEb,CACI,MAAS,2BAEb,CACI,MAAS,kCACT,YAAe,4BAEnB,CACI,MAAS,wBACT,YAAe,yCAI3B,CACI,MAAS,+BACT,QAAW,IACX,SAAY,CACR,CACI,MAAS,eACT,YAAe,uEAGnB,CACI,MAAS,gBACT,YAAe,mBAGnB,CACI,MAAS,cAEb,CACI,MAAS,2BAEb,CACI,MAAS,kCACT,YAAe,qBAGnB,CACI,MAAS,wBACT,YAAe,gFAI3B,CACI,MAAS,iCACT,QAAW,IACX,SAAY,CACR,CACI,MAAS,eACT,YAAe,sCAEnB,CACI,MAAS,aACT,YAAe,qBAEnB,CACI,MAAS,2BAEb,CACI,MAAS,oBACT,YAAe,wDAEnB,CACI,MAAS,iCACT,YAAe,yDAEnB,CACI,MAAS,kCACT,YAAe,oEAI3B,CACI,MAAS,qCACT,QAAW,IACX,SAAY,CACR,CACI,MAAS,gBACT,YAAe,wCAEnB,CACI,MAAS,uCAEb,CACI,MAAS,yDACT,YAAe,2CAEnB,CACI,MAAS,6EAEb,CACI,MAAS,gCACT,YAAe,yeAI3B,CACI,MAAS,sCACT,QAAW,IACX,SAAY,CACR,CACI,MAAS,gCACT,IAAO,+DAEX,CACI,MAAS,oBACT,IAAO,6DACP,YAAe,uDAEnB,CACI,MAAS,2BACT,YAAe,8EAEnB,CACI,MAAS,gBACT,YAAe,4CAEnB,CACI,MAAS,6BACT,IAAO,qEAEX,CACI,MAAS,uBACT,IAAO,yDACP,YAAe,0JAI3B,CACI,MAAS,8BACT,QAAW,IACX,SAAY,CACR,CACI,MAAS,yDACT,YAAe,6EAEnB,CACI,MAAS,kCACT,YAAe,kEACf,IAAO,qDAEX,CACI,MAAS,kDACT,YAAe,6DAEnB,CACI,MAAS,0CACT,YAAe,mEAEnB,CACI,MAAS,6BACT,YAAe,mFAI3B,CACI,MAAS,gCACT,QAAW,IACX,SAAY,CACR,CACI,MAAS,eACT,YAAe,qEACf,IAAO,oFAEX,CACI,MAAS,sBACT,YAAe,kJAEnB,CACI,MAAS,QACT,YAAe,6IAEnB,CACI,MAAS,aACT,YAAe,yJAEnB,CACI,MAAS,yBACT,YAAe,wLAEnB,CACI,MAAS,0BACT,YAAe,uEAI3B,CACI,MAAS,mCACT,QAAW,EACX,IAAO,qDACP,SAAY,CACR,CACI,MAAS,mBACT,YAAe,0EACf,IAAO,8DAEX,CACI,MAAS,qBACT,YAAe,qCACf,IAAO,yDAEX,CACI,MAAS,+BACT,YAAe,4DAEnB,CACI,MAAS,0BACT,YAAe,sFACf,IAAO,6DAEX,CACI,MAAS,uCACT,YAAe,uIACf,IAAO,gEAInB,CACI,MAAS,0CACT,QAAW,GACX,IAAO,qDACP,SAAY,CACR,CACI,MAAS,eACT,YAAe,iFACf,IAAO,yDAEX,CACI,MAAS,0BACT,MAAS,EACT,YAAe,sFACf,IAAO,6DAEX,CACI,MAAS,eACT,MAAS,OACT,YAAe,0IAEnB,CACI,MAAS,QACT,YAAe,oFAEnB,CACI,MAAS,iBACT,YAAe,gDACf,IAAO,8DAEX,CACI,MAAS,oBACT,YAAe,0GAEnB,CACI,MAAS,0BACT,YAAe,kHACf,IAAO,8DAEX,CACI,MAAS,oCACT,YAAe,iHACf,IAAO,8DAInB,CACI,MAAS,yCACT,QAAW,GACX,IAAO,oDACP,SAAY,CACR,CACI,MAAS,iBACT,YAAe,wLAEnB,CACI,MAAS,oCACT,YAAe,iHACf,IAAO,2DACP,MAAS,IAEb,CACI,MAAS,mDACT,YAAe,gEACf,IAAO,8DAEX,CACI,MAAS,kDACT,YAAe,sIAEnB,CACI,MAAS,QACT,YAAe,yJAI3B,CACI,MAAS,uCACT,QAAW,GACX,SAAY,CACR,CACI,MAAS,sBACT,YAAe,6OAEnB,CACI,MAAS,kBACT,YAAe,gFAEnB,CACI,MAAS,qCACT,YAAe,qLAEnB,CACI,MAAS,+BACT,MAAS,GACT,IAAO,6DACP,YAAe,4HAEnB,CACI,MAAS,oCACT,MAAS,EACT,IAAO,6DACP,YAAe,6EAI3B,CACI,MAAS,wCACT,QAAW,GACX,SAAY,CACR,CACI,MAAS,4BACT,YAAe,4CAEnB,CACI,MAAS,sCACT,YAAe,iFAEnB,CACI,MAAS,mBACT,YAAe,0DAEnB,CACI,MAAS,iBACT,YAAe,8FAEnB,CACI,MAAS,qBACT,YAAe,4D","sources":["webpack://opendatahub.io/./src/content/assets/img/placeholder.svg","webpack://opendatahub.io/./src/const.ts"],"sourcesContent":["export default \"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI2ODAuNzY0IiBoZWlnaHQ9IjUyOC4zNTQiIHZpZXdCb3g9IjAgMCAxODAuMTE5IDEzOS43OTQiPjxnIHRyYW5zZm9ybT0idHJhbnNsYXRlKC0xMy41OSAtNjYuNjM5KSIgcGFpbnQtb3JkZXI9ImZpbGwgbWFya2VycyBzdHJva2UiPjxwYXRoIGZpbGw9IiNkMGQwZDAiIGQ9Ik0xMy41OTEgNjYuNjM5SDE5My43MXYxMzkuNzk0SDEzLjU5MXoiLz48cGF0aCBkPSJtMTE4LjUwNyAxMzMuNTE0LTM0LjI0OSAzNC4yNDktMTUuOTY4LTE1Ljk2OC00MS45MzggNDEuOTM3SDE3OC43MjZ6IiBvcGFjaXR5PSIuNjc1IiBmaWxsPSIjZmZmIi8+PGNpcmNsZSBjeD0iNTguMjE3IiBjeT0iMTA4LjU1NSIgcj0iMTEuNzczIiBvcGFjaXR5PSIuNjc1IiBmaWxsPSIjZmZmIi8+PHBhdGggZmlsbD0ibm9uZSIgZD0iTTI2LjExMSA3Ny42MzRoMTUyLjYxNHYxMTYuMDk5SDI2LjExMXoiLz48L2c+PC9zdmc+\"","import { LinkedContent, PersonaBenefits, RoadmapDataType, SideNavItemConfig } from \"./types\";\nimport logo from \"./content/assets/img/logos/datahub_mark_color-blkbg.png\";\nimport placeholderImage from \"./content/assets/img/placeholder.svg\";\n\nexport const DOCS_NAVIGATION: SideNavItemConfig[] = [\n    {\n        title: \"Installing Open Data Hub\",\n        slug: \"/docs/installing-open-data-hub/\",\n    },\n    {\n        title: \"Upgrading Open Data Hub\",\n        slug: \"/docs/upgrading-open-data-hub/\",\n    },\n    {\n        title: \"Getting started with Open Data Hub\",\n        slug: \"/docs/getting-started-with-open-data-hub/\"\n    },\n    {\n        title: \"Working on data science projects\",\n        slug: \"/docs/working-on-data-science-projects/\"\n    },\n    {\n        title: \"Working in your data science IDE\",\n        slug: \"/docs/working-in-your-data-science-ide/\"\n    },\n    {\n        title: \"Creating a workbench\",\n        slug: \"/docs/api-workbench/\"\n    },    \n    {\n        title: \"Working with data science pipelines\",\n        slug: \"/docs/working-with-data-science-pipelines/\"\n    },\n    {\n        title: \"Deploying models\",\n        slug: \"/docs/deploying-models/\"\n    },\n    {\n        title: \"Configuring your model-serving platform\",\n        slug: \"/docs/configuring-your-model-serving-platform/\"\n    },\n    {\n        title: \"Managing and monitoring models\",\n        slug: \"/docs/managing-and-monitoring-models/\"\n    },\n    {\n        title: \"Monitoring data science models\",\n        slug: \"/docs/monitoring-data-science-models/\"\n    },\n    {\n        title: \"Working with distributed workloads\",\n        slug: \"/docs/working-with-distributed-workloads/\"\n    },\n    {\n        title: \"Working with accelerators\",\n        slug: \"/docs/working-with-accelerators/\"\n    },\n    {\n        title: \"Working with connected applications\",\n        slug: \"/docs/working-with-connected-applications/\"\n    },\n    {\n        title: \"Working with data in an S3-compatible object store\",\n        slug: \"/docs/working-with-data-in-s3-compatible-object-store/\"\n    },\n    {\n        title: \"Working with model registries and model catalog\",\n        slug: \"/docs/working-with-model-registries/\"\n    },\n    {\n        title: \"Working with Llama Stack\",\n        slug: \"/docs/working-with-llama-stack/\"\n    },\n    {\n        title: \"Managing Open Data Hub\",\n        slug: \"/docs/managing-odh/\"\n    },\n    {\n        title: \"Managing resources\",\n        slug: \"/docs/managing-resources/\"\n    },\n    {\n        title: \"Working with machine learning features\",\n        slug: \"/docs/working-with-machine-learning-features/\"\n    },\n    {\n        title: \"Architecture\",\n        slug: \"/docs/architecture\"\n    },\n    {\n        title: \"Tiered Components\",\n        slug: \"/docs/tiered-components\"\n    },\n    {\n        title: \"Roadmap\",\n        slug: \"/docs/release-notes\",\n        children: [\n            {\n                title: \"Release Notes\",\n                slug: \"/docs/release-notes\"\n            },\n            {\n                title: \"Future Releases\",\n                slug: \"/docs/future\"\n            }\n        ]\n    }\n]\n\nconst LINKED_CONTENT: LinkedContent[] = [\n    {\n        title: \"Uploading data to Ceph via command line\",\n        url: \"https://youtu.be/d6X1xvDXewM\",\n        type: \"video\",\n        categories: [\"Tutorial\"]\n    },\n\n    {\n        title: \"AI on OpenShift\",\n        url: \"https://www.youtube.com/watch?v=MD1x2IT7rdg\",\n        type: \"video\",\n    },\n    {\n        title: \"Fraud Detection using the Open Data Hub\",\n        url: \"https://youtu.be/IcQ2bhsw_kQ\",\n        type: \"video\",\n    },\n\n    {\n        title: \"Kubecon 2020: How to Use Kubernetes to Build a Data Lake for AI Workloads\",\n        url: \"https://www.youtube.com/watch?v=0HIelZ3qMLE\",\n        type: \"video\",\n        categories: [\"Conference talk\"]\n    },\n    {\n        title: \"Kubecon 2020: Is There a Place For Distributed Storage For AI/ML on Kubernetes?\",\n        url: \"https://www.youtube.com/watch?v=9XhbXtPKttM&feature=youtu.be\",\n        type: \"video\",\n        categories: [\"Conference talk\"]\n    },\n    {\n        title: \"ML Pipelines with Kubeflow, Argo and Open Data Hub\",\n        url: \"https://youtu.be/NZOky2Gm0iA?list=PLU1vS0speL2bxDVhBGZOiNQotzkdxJ8ln\",\n        type: \"video\",\n        categories: [\"Conference talk\"]\n    },\n    {\n        title: \"Scalable Kafka Deployment on OpenShift for ML\",\n        url: \"https://youtu.be/og_Abr9jZJU?list=PLU1vS0speL2bxDVhBGZOiNQotzkdxJ8ln\",\n        type: \"video\",\n        categories: [\"Conference talk\"]\n    },\n    {\n        title: \"MLFlow: Experiment Tracking on OpenShift\",\n        url: \"https://youtu.be/WgEKfAj7PLc?list=PLU1vS0speL2bxDVhBGZOiNQotzkdxJ8ln\",\n        type: \"video\",\n        categories: [\"Conference talk\"]\n    },\n    {\n        title: \"Scaling your Open Data Hub for Fun and Production\",\n        url: \"https://youtu.be/dkuTaxWUrfE?list=PLU1vS0speL2bxDVhBGZOiNQotzkdxJ8ln\",\n        type: \"video\",\n        categories: [\"Conference talk\"]\n    },\n    {\n        title: \"An Introduction to Unsupervised Deep Learning\",\n        url: \"https://youtu.be/tpDV8nUv45c?list=PLU1vS0speL2bxDVhBGZOiNQotzkdxJ8ln\",\n        type: \"video\",\n        categories: [\"Conference talk\"]\n    },\n    {\n        title: \"Unsupervised NLP for Log Anomaly Detection\",\n        url: \"https://youtu.be/Dt81qwza-zA?list=PLU1vS0speL2bxDVhBGZOiNQotzkdxJ8ln\",\n        type: \"video\",\n        categories: [\"Conference talk\"]\n    },\n    {\n        title: \"Sentiment Analysis Service in a DevOps Environment\",\n        url: \"https://youtu.be/2QJ367chSS0?list=PLU1vS0speL2bxDVhBGZOiNQotzkdxJ8ln\",\n        type: \"video\",\n        categories: [\"Conference talk\"]\n    },\n    {\n        title: \"Machine Learning with Open Source Infrastructure\",\n        url: \"https://youtu.be/K8G_0z5jbcA?list=PLU1vS0speL2bxDVhBGZOiNQotzkdxJ8ln\",\n        type: \"video\",\n        categories: [\"Conference talk\"]\n    },\n    {\n        title: \"AIOps: Anomaly Detection with Prometheus and Istio\",\n        url: \"https://youtu.be/5lT-GajT_Wo?list=PLU1vS0speL2bxDVhBGZOiNQotzkdxJ8ln\",\n        type: \"video\",\n        categories: [\"Conference talk\"]\n    },\n    {\n        title: \"Presto: Cloud Native SQL-on-Anything\",\n        url: \"https://youtu.be/73VZaP3Mh-M?list=PLU1vS0speL2bxDVhBGZOiNQotzkdxJ8ln\",\n        type: \"video\",\n        categories: [\"Conference talk\"]\n    },\n    {\n        title: \"Data Science in the Open Cloud Exchange Model\",\n        url: \"https://youtu.be/KWDUkm1ZeKY?list=PLU1vS0speL2bxDVhBGZOiNQotzkdxJ8ln\",\n        type: \"video\",\n        categories: [\"Conference talk\"]\n    },\n    {\n        title: \"Ceph Object Storage for AI and ML Workloads\",\n        url: \"https://www.youtube.com/watch?v=n2IW3VIZmg4\",\n        type: \"video\",\n        categories: [\"Conference talk\"]\n    },\n    {\n        title: \"Data Exploration with JupyterHub on OpenShift\",\n        url: \"https://www.youtube.com/watch?v=by0l3b55i7g\",\n        type: \"video\",\n        categories: [\"Conference talk\"]\n    },\n    {\n        title: \"Building AI with Ceph and OpenShift\",\n        url: \"https://www.youtube.com/watch?v=B6E7SyxOB2M\",\n        type: \"video\",\n        categories: [\"Conference talk\"]\n    },\n    {\n        title: \"Using the Massachusetts Open Cloud Data Hub to perform Data Science Experiments\",\n        url: \"https://www.youtube.com/watch?v=iUJ6RGfY0JQ\",\n        type: \"video\",\n        categories: [\"Conference talk\"]\n    },\n    {\n        title: \"Using the Mass Open Cloud to perform Data Science Experiments\",\n        url: \"https://youtu.be/CZwUCgkKIc4\",\n        type: \"video\",\n        categories: [\"Conference talk\"]\n    },\n    {\n        title: \"ML Workloads with GPUs on Openshift 4\",\n        url: \"https://www.youtube.com/watch?v=RbJurxB4RSo&feature=youtu.be\",\n        type: \"video\",\n        categories: [\"Conference talk\"]\n    },\n\n    {\n        title: \"Innovate @Open podcast\",\n        url: \"https://grhpodcasts.s3.amazonaws.com/opendatahub1908.mp3\",\n        type: \"audio\",\n    },\n]\n\n\nexport const PERSONAS: PersonaBenefits = [\n    {\n        name: \"IT Operator\",\n        benefits: [\n            {\n                title: \"Effortless Deployment\",\n                body: \"Deploy the Open Data Hub (ODH) AI platform within minutes, enabling swift provisioning and setup by IT operators. ODH offers an accelerated path to accessing AI/ML tools for data scientists.\",\n                imageUrl: placeholderImage,\n                features: [\n                    {\n                        title: \"Streamlined Integration\",\n                        body: \"Integrate seamlessly with popular open-source AI/ML tools, providing a unified user experience for data scientists.\",\n                        imageUrl: logo,\n                    },\n                    {\n                        title: \"Rapid Deployment of Resources\",\n                        body: \"Decrease the time it takes to deploy the necessary resources for data scientists, enabling them to start working quickly and efficiently.\",\n                        imageUrl: logo,\n                    },\n                ],\n            },\n            {\n                title: \"Democratized Access\",\n                body: \"Democratize access to open-source AI/ML tools by making them easily available to data scientists. ODH empowers IT operators to meet the increasing demand for these tools.\",\n                imageUrl: placeholderImage,\n                features: [\n                    {\n                        title: \"Unified User Experience\",\n                        body: \"Provide data scientists with a unified user experience across a range of popular open-source AI/ML tools, facilitating seamless collaboration and productivity.\",\n                        imageUrl: logo,\n                    },\n                    {\n                        title: \"Open-Source Integration\",\n                        body: \"Integrate with a diverse range of open-source AI/ML tools, allowing data scientists to leverage the best tools for their specific needs.\",\n                        imageUrl: logo,\n                    },\n                ],\n            },\n            {\n                title: \"Customization\",\n                body: \"Effortlessly customize the Open Data Hub (ODH) to meet specific requirements, such as adjusting notebook and model server sizes, hiding or displaying specific components, adding custom tiles to the launcher, importing custom images, and more.\",\n                link: \"/docs/\",\n                imageUrl: placeholderImage,\n                features: [\n                    {\n                        title: \"Custom Notebook Images\",\n                        body: \"Create and deploy custom notebook images, empowering users to start their work with the necessary software already installed.\",\n                        imageUrl: logo,\n                    },\n                    {\n                        title: \"Resource Access Control\",\n                        body: \"Leverage OpenShift's built-in capabilities to precisely control users' access to resources, ensuring optimal security and privacy measures.\",\n                        imageUrl: logo,\n                    },\n                    {\n                        title: \"Taints for Resource Access Restriction\",\n                        body: \"Effectively utilize taints to restrict access to specific resources within the ODH environment, enhancing security and resource management.\",\n                        imageUrl: logo,\n                    },\n                ],\n            },\n        ],\n    },\n    {\n        name: \"Data Scientist\",\n        benefits: [\n            {\n                title: \"Jupyter Notebooks\",\n                body: \"Utilize Jupyter notebooks to create and train machine learning models.\",\n                imageUrl: placeholderImage,\n                features: [\n                    {\n                        title: \"R Studio Support\",\n                        body: \"Leverage R Studio for creating and training machine learning models.\",\n                        imageUrl: logo,\n                    },\n                    {\n                        title: \"Open Source AI Tools\",\n                        body: \"Utilize a wide range of open source tools for data science, including TensorFlow, PyTorch, and more.\",\n                        imageUrl: logo,\n                    },\n                ],\n            },\n            {\n                title: \"Model Serving\",\n                body: \"Serve trained models and create endpoints for seamless integration into applications.\",\n                imageUrl: placeholderImage,\n                features: [\n                    {\n                        title: \"Repeatable Experiments\",\n                        body: \"Implement data science pipelines using Kubeflow Pipelines and Tekton to create repeatable experiments for consistent and reliable results.\",\n                        imageUrl: logo,\n                    },\n                    {\n                        title: \"Model Explainability\",\n                        body: \"Enhance model interpretability and gain insights into the factors driving predictions using TrustyAI.\",\n                        imageUrl: logo,\n                    },\n                    {\n                        title: \"Streamlined Deployment\",\n                        body: \"Effortlessly deploy machine learning models in production environments, including popular cloud-based platforms.\",\n                        imageUrl: logo,\n                    },\n                ],\n            },\n            {\n                title: \"Collaboration and Connectivity\",\n                body: \"Collaborate with colleagues to share models and work together on projects.\",\n                imageUrl: placeholderImage,\n                features: [\n                    {\n                        title: \"Shared Model Access\",\n                        body: \"Collaborate with colleagues by accessing their models and sharing your own.\",\n                        imageUrl: logo,\n                    },\n                    {\n                        title: \"Efficient Project Organization\",\n                        body: \"Leverage project management capabilities to efficiently organize your work and collaborate with colleagues.\",\n                        imageUrl: logo,\n                    },\n                    {\n                        title: \"Access External Data Sources\",\n                        body: \"Connect seamlessly to external data sources like Amazon S3 for comprehensive data exploration and analysis.\",\n                        imageUrl: logo,\n                    },\n                ],\n            }\n        ],\n    },\n    {\n        name: \"App Developer\",\n        benefits: [\n            {\n                title: \"Enhanced Development Experience\",\n                body: \"Improve your development experience with seamless VS Code integration and version control.\",\n                link: \"/docs/\",\n                imageUrl: placeholderImage,\n                features: [\n                    {\n                        title: \"VS Code Support\",\n                        body: \"Enjoy seamless integration with Visual Studio Code (VS Code), a powerful development environment for building your applications.\",\n                        imageUrl: logo,\n                    },\n                    {\n                        title: \"Endpoint Creation and Management\",\n                        body: \"Efficiently create and manage multiple model endpoints to serve your application needs.\",\n                        imageUrl: logo,\n                    },\n                    {\n                        title: \"Manual Model Server Deployment\",\n                        body: \"Containerize and serve models manually\",\n                        imageUrl: logo,\n                    },\n                ],\n            },\n            {\n                title: \"Streamlined Workflow Management\",\n                body: \"Improve your application development workflow with granular pipeline control and GitOps integration.\",\n                link: \"/docs/\",\n                imageUrl: placeholderImage,\n                features: [\n\n                    {\n                        title: \"CI/CD Integration\",\n                        body: \"Leverage CI/CD tools to streamline your application development lifecycle and ensure efficient deployment processes.\",\n                        imageUrl: logo,\n                    },\n                    {\n                        title: \"GitOps Integration\",\n                        body: \"Integrate Pipelines into a GitOps process to streamline application deployment to stage and production environments.\",\n                        imageUrl: logo,\n                    },\n                    {\n                        title: \"Application and Model Versioning\",\n                        body: \"Efficiently manage versions of your applications and models for better organization and tracking.\",\n                        imageUrl: logo,\n                    },\n                ],\n            },\n        ],\n    }\n];\n\nexport const ROADMAP_DATA: RoadmapDataType = {\n    \"future\": [\n        {\n            \"title\": \"Open Data Hub 1.8 (July 2023)\",\n            \"version\": 1.8,\n            \"children\": [\n                {\n                    \"title\": \"ODH Operator\"\n                },\n                {\n                    \"title\": \"ODH Dashboard\"\n                },\n                {\n                    \"title\": \"Model Mesh\"\n                },\n                {\n                    \"title\": \"TrustyAI Explainability\"\n                },\n                {\n                    \"title\": \"Data Science Pipelines operator\"\n                },\n                {\n                    \"title\": \"Distributed Workloads\"\n                }\n            ]\n        }\n    ],\n    \"past\": [\n        {\n            \"title\": \"Open Data Hub 1.7 (June 2023)\",\n            \"version\": 1.7,\n            \"children\": [\n                {\n                    \"title\": \"ODH Operator\",\n                    \"description\": \"ODH Operator image now includes a local copy of the release version of the ODH Core deployment manifests that can be referenced from any supported kfdef\"\n                },\n                {\n                    \"title\": \"ODH Dashboard\",\n                    \"description\": \"Update to version v2.11\"\n                },\n                {\n                    \"title\": \"Model Mesh\"\n                },\n                {\n                    \"title\": \"TrustyAI Explainability\"\n                },\n                {\n                    \"title\": \"Data Science Pipelines operator\",\n                    \"description\": \"Update to version v1.0.0\"\n                },\n                {\n                    \"title\": \"Distributed Workloads\",\n                    \"description\": \"Upgrade to Project CodeFlare v0.0.4\"\n                }\n            ]\n        },\n        {\n            \"title\": \"Open Data Hub 1.6 (May 2023)\",\n            \"version\": 1.6,\n            \"children\": [\n                {\n                    \"title\": \"ODH Operator\",\n                    \"description\": \"Default to the `rolling` OLM release channel and deprecate `stable`\"\n\n                },\n                {\n                    \"title\": \"ODH Dashboard\",\n                    \"description\": \"Upgrade to v2.9\"\n\n                },\n                {\n                    \"title\": \"Model Mesh\"\n                },\n                {\n                    \"title\": \"TrustyAI Explainability\"\n                },\n                {\n                    \"title\": \"Data Science Pipelines operator\",\n                    \"description\": \"Upgrade to v0.2.0\"\n\n                },\n                {\n                    \"title\": \"Distributed Workloads\",\n                    \"description\": \"Incubation of the Distributed Workloads stack supporting the CodeFlare SDK\"\n                }\n            ]\n        },\n        {\n            \"title\": \"Open Data Hub 1.5 (April 2023)\",\n            \"version\": 1.5,\n            \"children\": [\n                {\n                    \"title\": \"ODH Operator\",\n                    \"description\": \"Migration to the operator-sdk 1.24\"\n                },\n                {\n                    \"title\": \"Model Mesh\",\n                    \"description\": \"Update to v0.11.0\"\n                },\n                {\n                    \"title\": \"TrustyAI Explainability\"\n                },\n                {\n                    \"title\": \"Jupyter Notebooks\",\n                    \"description\": \"Add Python 3.8 / 3.9 versions of all notebook images\"\n                },\n                {\n                    \"title\": \"ODH Dashboard Model Serving UI\",\n                    \"description\": \"Add intial UI support for the new Model Serving stack\"\n                },\n                {\n                    \"title\": \"Data Science Pipelines operator\",\n                    \"description\": \"Adds support for namespace isolation of Data Science Pipelines\"\n                }\n            ]\n        },\n        {\n            \"title\": \"Open Data Hub 1.4 - (October 2022)\",\n            \"version\": 1.4,\n            \"children\": [\n                {\n                    \"title\": \"Model Serving\",\n                    \"description\": \"Updates to the etcd and minio setups\"\n                },\n                {\n                    \"title\": \"Support for ODH Notebook Controller\"\n                },\n                {\n                    \"title\": \"ODH Dashboard Admin UI and Notebook Controller backend\",\n                    \"description\": \"Add UI support for admin configurations\"\n                },\n                {\n                    \"title\": \"Deployment of Data Science Pipelines based on Kubeflow Pipelines (Tekton)\"\n                },\n                {\n                    \"title\": \"ODH Re-architecture - Phase 1\",\n                    \"description\": \"Categorize existing components (as of ODH v1.3.0) into support Tiers for updates/deprecation and designate maintainers Tiered approach <br> - Tier 0 - ODH Core <br> - Tier 1 - Long Term community support with assigned MAINTAINERS and full test suite <br> - Tier 2 - Any components in the <a href=\\\"https://github.com/opendatahub-io-contrib\\\" >opendatahub-io-contrib</a> org that are not included in the ODH Core deployment but maintain ODH integrations of interest to the community<br>\"\n                }\n            ]\n        },\n        {\n            \"title\": \"Open Data Hub 1.3 - (May/June 2022)\",\n            \"version\": 1.3,\n            \"children\": [\n                {\n                    \"title\": \"Tutorials and website cleanup\",\n                    \"url\": \"https://github.com/opendatahub-io/opendatahub.io/projects/1\"\n                },\n                {\n                    \"title\": \"Dashboard updates\",\n                    \"url\": \"https://github.com/opendatahub-io/odh-dashboard/projects/2\",\n                    \"description\": \"Admin -  Bring your own notebooks+ Cluster Settings\"\n                },\n                {\n                    \"title\": \"Bring your own notebooks\",\n                    \"description\": \"Allow admins the flexibility to provide to users their own notebook images\"\n                },\n                {\n                    \"title\": \"Model Serving\",\n                    \"description\": \"Implementation of Model Mesh using Oauth\"\n                },\n                {\n                    \"title\": \"Community governance model\",\n                    \"url\": \"https://github.com/opendatahub-io/opendatahub-community/issues/11\"\n                },\n                {\n                    \"title\": \"Kubeflow 1.5 support\",\n                    \"url\": \"https://github.com/opendatahub-io/manifests/projects/2\",\n                    \"description\": \"Includes ability to install Kubeflow v1.5.0 components on OpenShift <br> Support for the integration of Service Mesh with Kubeflow v1.5 on OpenShift\"\n                }\n            ]\n        },\n        {\n            \"title\": \"Open Data Hub 1.2 - Q4 2021\",\n            \"version\": 1.2,\n            \"children\": [\n                {\n                    \"title\": \"JupyterHub Custom Notebooks User Interface improvement\",\n                    \"description\": \"Add User Interface elements for users to enter new custom notebook images\"\n                },\n                {\n                    \"title\": \"Kubeflow 1.3 on OCP 4.6/4.7/4.8\",\n                    \"description\": \"Enable Kubeflow 1.3 on OCP 4.6/4.7/4.8 by resolving all issues.\",\n                    \"url\": \"https://github.com/kubeflow/manifests/issues/1895\"\n                },\n                {\n                    \"title\": \"Kubeflow integration with Red Hat Service Mesh.\",\n                    \"description\": \"Replace Istio stack with Red Hat Serivce Mesh in Kubeflow\"\n                },\n                {\n                    \"title\": \"ODH and KF authentication architecture.\",\n                    \"description\": \"Architect an integrated authentication solution for ODH and KF.\"\n                },\n                {\n                    \"title\": \"KF 1.3.1 OCP Stack update.\",\n                    \"description\": \"This includes updating the Kubeflow 1.3.1 openshift stack to work on OCP 4.4+\"\n                }\n            ]\n        },\n        {\n            \"title\": \"Open Data Hub 1.1 - July 2021\",\n            \"version\": 1.1,\n            \"children\": [\n                {\n                    \"title\": \"Kubeflow 1.3\",\n                    \"description\": \"Update the Openshift Kubeflow distribution to Kubeflow version 1.3\",\n                    \"url\": \"https://github.com/kubeflow/manifests/tree/v1.3.0/distributions/stacks/openshift\"\n                },\n                {\n                    \"title\": \"Openshift Pipelines\",\n                    \"description\": \"Installation of Red Hat OpenShift Pipelines along with all of the required custom resources to enable a workflow supported by Tekton pipelines\"\n                },\n                {\n                    \"title\": \"Trino\",\n                    \"description\": \"Trino is a fast distributed SQL query engine that can integrate with multiple data sources such as S3, SQL databases, and NoSQL databases\"\n                },\n                {\n                    \"title\": \"JupyterHub\",\n                    \"description\": \"Updates include new Spawner user interface,ability to customize and specify JupyterHub PostgreSQL parameters and new notebook images with JupyterLab.\"\n                },\n                {\n                    \"title\": \"Open Data Hub operator\",\n                    \"description\": \"Updates include support for Operator Level 4 (Deep Insights), new Prometheus metrics collection, new Grafana Dashboard and new status field to reflect operator installation status.\"\n                },\n                {\n                    \"title\": \"Open Data Hub Dashboard\",\n                    \"description\": \"Integrated with Openshift Authentication to access the dashboard.\"\n                }\n            ]\n        },\n        {\n            \"title\": \"Open Data Hub 1.0 - January 2021\",\n            \"version\": 1,\n            \"url\": \"https://github.com/orgs/opendatahub-io/projects/12\",\n            \"children\": [\n                {\n                    \"title\": \"ODH Data Catalog\",\n                    \"description\": \"Migrate Open Data Hub Data Catalog component from Ansible to Kustomize.\",\n                    \"url\": \"https://github.com/opendatahub-io/odh-manifests/issues/222\"\n                },\n                {\n                    \"title\": \"Kubeflow KFServing\",\n                    \"description\": \"Enable KFServing in Open Data Hub.\",\n                    \"url\": \"https://github.com/opendatahub-io/manifests/issues/63\"\n                },\n                {\n                    \"title\": \"Kubeflow Pipelines on Tekton\",\n                    \"description\": \"Enable Kubeflow Pipelines using Tekton in Open Data Hub.\"\n                },\n                {\n                    \"title\": \"Disconnected Deployment\",\n                    \"description\": \"Investigate and introduce ability to deploy ODH on disconnected OpenShift clusters.\",\n                    \"url\": \"https://github.com/opendatahub-io/odh-manifests/issues/15\"\n                },\n                {\n                    \"title\": \"JupyterHub Spawner UI Rearchitecture\",\n                    \"description\": \"Replace existing static HTML spawner UI with dynamic React base one which will allow for more customization and easier extensabiliy.\",\n                    \"url\": \"https://github.com/opendatahub-io/odh-manifests/issues/146\"\n                }\n            ]\n        },\n        {\n            \"title\": \"Open Data Hub 0.9 - End of October 2020\",\n            \"version\": 0.9,\n            \"url\": \"https://github.com/orgs/opendatahub-io/projects/11\",\n            \"children\": [\n                {\n                    \"title\": \"Kubeflow 1.2\",\n                    \"description\": \"Add OpenShift stack in Kubeflow 1.2 to achieve release sync between ODH and KF\",\n                    \"url\": \"https://github.com/opendatahub-io/manifests/issues/54\"\n                },\n                {\n                    \"title\": \"Disconnected Deployment\",\n                    \"moved\": 1,\n                    \"description\": \"Investigate and introduce ability to deploy ODH on disconnected OpenShift clusters.\",\n                    \"url\": \"https://github.com/opendatahub-io/odh-manifests/issues/15\"\n                },\n                {\n                    \"title\": \"UBI based KF\",\n                    \"moved\": \"1.1+\",\n                    \"description\": \"Continuation of the \\\"UBI based ODH\\\" expanding to Kubeflow project and looking at what does it take to move Kubeflow components to UBI.\"\n                },\n                {\n                    \"title\": \"CI/CD\",\n                    \"description\": \"Continuation of the of the effort to design and create a complete CI/CD process.\"\n                },\n                {\n                    \"title\": \"Object Storage\",\n                    \"description\": \"Add an Object Storage tool based on Rook-Ceph\",\n                    \"url\": \"https://github.com/opendatahub-io/odh-manifests/issues/149\"\n                },\n                {\n                    \"title\": \"Enable Monitoring\",\n                    \"description\": \"Continuation of the effort to enable Prometheus enpoints in all Open Data Hub and Kubeflow components.\"\n                },\n                {\n                    \"title\": \"Open Data Hub Dashboard\",\n                    \"description\": \"Team is currently creating an Open Data Hub dashboard that will be the entry point to all installed components.\",\n                    \"url\": \"https://github.com/opendatahub-io/odh-manifests/issues/186\"\n                },\n                {\n                    \"title\": \"Notebooks to Pipelines with Elyra\",\n                    \"description\": \"Added a JupyterLab notebook image that includes Elyra. Elyra converts notebooks to Argo or Kubeflow pipelines.\",\n                    \"url\": \"https://github.com/opendatahub-io/odh-manifests/pull/171\"\n                }\n            ]\n        },\n        {\n            \"title\": \"Open Data Hub 0.8 - End of August 2020\",\n            \"version\": 0.8,\n            \"url\": \"https://github.com/orgs/opendatahub-io/projects/8\",\n            \"children\": [\n                {\n                    \"title\": \"ODH JupyterHub\",\n                    \"description\": \"Forked JupyterHub repos under Open Data Hub github repo for maintaining new changes. Added notebook images to Thoth Station for building. Added ability to launch JupyterLab images.\"\n                },\n                {\n                    \"title\": \"Notebooks to Pipelines with Elyra\",\n                    \"description\": \"Added a JupyterLab notebook image that includes Elyra. Elyra converts notebooks to Argo or Kubeflow pipelines.\",\n                    \"url\": \"https://github.com/opendatahub-io/odh-manifests/pull/171\",\n                    \"moved\": 0.9\n                },\n                {\n                    \"title\": \"Mixing ODH & KF components- Distributed Training\",\n                    \"description\": \"Added Pytorch operator to work with Open Data Hub components.\",\n                    \"url\": \"https://github.com/opendatahub-io/odh-manifests/issues/147\"\n                },\n                {\n                    \"title\": \"Mixing ODH & KF components- Kubeflow Monitoring\",\n                    \"description\": \"Added monitoring to Kubeflow components by enabling monitoring to Argo and adding Prometheus and Grafana to Kubeflow installation.\"\n                },\n                {\n                    \"title\": \"CI/CD\",\n                    \"description\": \"Added more tests to Open Data Hub components including Kafka and Superset and enhanced JupyterHub testing by adding Selenium for web portal testing\"\n                }\n            ]\n        },\n        {\n            \"title\": \"Open Data Hub 0.7 - End of June 2020\",\n            \"version\": 0.7,\n            \"children\": [\n                {\n                    \"title\": \"KF 1.0 on OpenShift\",\n                    \"description\": \"The main goal of this initiative is to verify Kubeflow 1.0 works on OpenShift and fix the issues we find. Another goal is to document and ideally automate some of the verification process to start enabling the CI for KF on OpenSHift.\"\n                },\n                {\n                    \"title\": \"CI improvements\",\n                    \"description\": \"Extending tests for all components, enabling CI for the operator repository.\"\n                },\n                {\n                    \"title\": \"Mixing ODH & KF components (start)\",\n                    \"description\": \"Proving users can mix ODH and KF components, compiling a prioritized list of components to be verified and fixed, proving on the first component (probably TF Job or Pytorch Job)\"\n                },\n                {\n                    \"title\": \"Add Object Storage Component\",\n                    \"moved\": 0.9,\n                    \"url\": \"https://github.com/opendatahub-io/odh-manifests/issues/104\",\n                    \"description\": \"Since ODH relies on S3 compatible object storage, add dependency on some minimal install of OpenShift Container Storage.\"\n                },\n                {\n                    \"title\": \"Convert Data Catalog to Kustomize\",\n                    \"moved\": 1,\n                    \"url\": \"https://github.com/opendatahub-io/odh-manifests/issues/105\",\n                    \"description\": \"Data Catalog is the last component missing the conversion to Kustomize.\"\n                }\n            ]\n        },\n        {\n            \"title\": \"Open Data Hub 0.6 - End of April 2020\",\n            \"version\": 0.6,\n            \"children\": [\n                {\n                    \"title\": \"Rebase ODH on KF operator\",\n                    \"description\": \"Use Kubeflow operator as a base for ODH.\"\n                },\n                {\n                    \"title\": \"Convert ODH components to Kustomize\",\n                    \"description\": \"Convert all ODH components to Kustomize to match Kubeflow deployment tooling.\"\n                },\n                {\n                    \"title\": \"Start CI for ODH\",\n                    \"description\": \"Investicate and kickstart ODH CI based on OpenShift CI\"\n                },\n                {\n                    \"title\": \"Move to Github\",\n                    \"description\": \"Since the goal of this release is to get closer to KF community, we need to move to Github\"\n                },\n                {\n                    \"title\": \"Add Apache Airflow\",\n                    \"description\": \"Add Apache Airflow as a component into Open Data Hub\"\n                }\n            ]\n        }\n    ]\n}\n"],"names":["DOCS_NAVIGATION","title","slug","children","ROADMAP_DATA","logo"],"sourceRoot":""}