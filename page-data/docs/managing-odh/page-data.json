{"componentChunkName":"component---src-templates-docs-page-tsx","path":"/docs/managing-odh/","result":{"data":{"allFile":{"edges":[{"node":{"childAsciidoc":{"fields":{"slug":"/docs/README/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/api-workbench/"},"sections":[{"parentId":null,"name":"Overview","level":1,"index":0,"id":"api-workbench-overview_api-workbench"},{"parentId":null,"name":"Creating a custom image by using the <code>ImageStream</code> CRD","level":1,"index":1,"id":"api-custom-image-creating_api-workbench"},{"parentId":null,"name":"Creating a workbench by using the <code>Notebook</code> CRD","level":1,"index":2,"id":"api-workbench-creating_api-workbench"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/configuring-your-model-serving-platform/"},"sections":[{"parentId":null,"name":"About model-serving platforms","level":1,"index":0,"id":"configuring-your-model-serving-platform_odh-admin"},{"parentId":"configuring-your-model-serving-platform_odh-admin","name":"About model serving","level":2,"index":0,"id":"about-model-serving_odh-admin"},{"parentId":"about-model-serving_odh-admin","name":"Model serving platform","level":3,"index":0,"id":"_model_serving_platform"},{"parentId":"about-model-serving_odh-admin","name":"NVIDIA NIM model serving platform","level":3,"index":1,"id":"_nvidia_nim_model_serving_platform"},{"parentId":"configuring-your-model-serving-platform_odh-admin","name":"Model-serving runtimes","level":2,"index":1,"id":"model-serving-runtimes_odh-admin"},{"parentId":"model-serving-runtimes_odh-admin","name":"ServingRuntime","level":3,"index":0,"id":"_servingruntime"},{"parentId":"model-serving-runtimes_odh-admin","name":"InferenceService","level":3,"index":1,"id":"_inferenceservice"},{"parentId":"configuring-your-model-serving-platform_odh-admin","name":"Model-serving runtimes for accelerators","level":2,"index":2,"id":"model-serving-runtimes-for-accelerators_odh-admin"},{"parentId":"model-serving-runtimes-for-accelerators_odh-admin","name":"NVIDIA GPUs","level":3,"index":0,"id":"_nvidia_gpus"},{"parentId":"model-serving-runtimes-for-accelerators_odh-admin","name":"Intel Gaudi accelerators","level":3,"index":1,"id":"_intel_gaudi_accelerators"},{"parentId":"model-serving-runtimes-for-accelerators_odh-admin","name":"AMD GPUs","level":3,"index":2,"id":"_amd_gpus"},{"parentId":"model-serving-runtimes-for-accelerators_odh-admin","name":"IBM Spyre AI accelerators on x86 and IBM Z","level":3,"index":3,"id":"_ibm_spyre_ai_accelerators_on_x86_and_ibm_z"},{"parentId":"model-serving-runtimes-for-accelerators_odh-admin","name":"Supported model-serving runtimes","level":3,"index":4,"id":"supported-model-serving-runtimes_odh-admin"},{"parentId":"model-serving-runtimes-for-accelerators_odh-admin","name":"Tested and verified model-serving runtimes","level":3,"index":5,"id":"tested-verified-runtimes_odh-admin"},{"parentId":null,"name":"Configuring model servers","level":1,"index":1,"id":"_configuring_model_servers"},{"parentId":"_configuring_model_servers","name":"Enabling the model serving platform","level":2,"index":0,"id":"enabling-the-model-serving-platform_odh-admin"},{"parentId":"_configuring_model_servers","name":"Enabling speculative decoding and multi-modal inferencing","level":2,"index":1,"id":"enabling-speculative-decoding-and-multi-modal-inferencing_odh-admin"},{"parentId":"_configuring_model_servers","name":"Adding a custom model-serving runtime","level":2,"index":2,"id":"adding-a-custom-model-serving-runtime_odh-admin"},{"parentId":"_configuring_model_servers","name":"Adding a tested and verified runtime","level":2,"index":3,"id":"adding-a-tested-and-verified-runtime_odh-admin"},{"parentId":null,"name":"Configuring model servers on the NVIDIA NIM model serving platform","level":1,"index":2,"id":"_configuring_model_servers_on_the_nvidia_nim_model_serving_platform"},{"parentId":"_configuring_model_servers_on_the_nvidia_nim_model_serving_platform","name":"Enabling the NVIDIA NIM model serving platform","level":2,"index":0,"id":"enabling-the-nvidia-nim-model-serving-platform_odh-admin"},{"parentId":null,"name":"Customizing model deployments","level":1,"index":3,"id":"_customizing_model_deployments"},{"parentId":"_customizing_model_deployments","name":"Customizing the parameters of a deployed model-serving runtime","level":2,"index":0,"id":"customizing-parameters-serving-runtime_odh-admin"},{"parentId":"_customizing_model_deployments","name":"Customizable model serving runtime parameters","level":2,"index":1,"id":"customizable-model-serving-runtime-parameters_odh-admin"},{"parentId":"_customizing_model_deployments","name":"Customizing the vLLM model-serving runtime","level":2,"index":2,"id":"Customizing-the-vllm-runtime_odh-admin"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/customize-models-to-build-gen-ai-applications/"},"sections":[{"parentId":null,"name":"Overview of the model customization workflow","level":1,"index":0,"id":"overview-of-the-model-customization-workflow_custom-models"},{"parentId":null,"name":"Set up your working environment","level":1,"index":1,"id":"set-up-your-working-environment_custom-models"},{"parentId":"set-up-your-working-environment_custom-models","name":"About the Red&#160;Hat Python Index","level":2,"index":0,"id":"about-the-python-index_custom-models"},{"parentId":"set-up-your-working-environment_custom-models","name":"Mirror the Python Index for your disconnected environment","level":2,"index":1,"id":"mirror-the-python-index_custom-models"},{"parentId":"set-up-your-working-environment_custom-models","name":"Install packages","level":2,"index":2,"id":"install-packages_custom-models"},{"parentId":"set-up-your-working-environment_custom-models","name":"Import example notebooks","level":2,"index":3,"id":"import-example-notebooks_custom-models"},{"parentId":"import-example-notebooks_custom-models","name":"Clone an example Git repository","level":3,"index":0,"id":"clone-an-example-git-repository_custom-models"},{"parentId":null,"name":"Prepare your data for AI consumption","level":1,"index":2,"id":"prepare-your-data-for-ai-consumption_custom-models"},{"parentId":"prepare-your-data-for-ai-consumption_custom-models","name":"Process data by using Docling","level":2,"index":0,"id":"_process_data_by_using_docling"},{"parentId":"prepare-your-data-for-ai-consumption_custom-models","name":"Explore the data processing examples","level":2,"index":1,"id":"explore-the-data-processing-examples_custom-models"},{"parentId":"prepare-your-data-for-ai-consumption_custom-models","name":"Automate data processing steps by building AI pipelines","level":2,"index":2,"id":"_automate_data_processing_steps_by_building_ai_pipelines"},{"parentId":"prepare-your-data-for-ai-consumption_custom-models","name":"Explore the kubeflow pipeline examples","level":2,"index":3,"id":"explore-the-kubeflow-pipeline-examples_custom-models"},{"parentId":null,"name":"Generate synthetic data","level":1,"index":3,"id":"generate-synthetic-data_custom-models"},{"parentId":"generate-synthetic-data_custom-models","name":"Explore the SDG Hub examples","level":2,"index":0,"id":"explore-the-sdg-hub-examples_custom-models"},{"parentId":"generate-synthetic-data_custom-models","name":"Guided example - Build a KFP pipeline for SDG","level":2,"index":1,"id":"guided-example-build-a-kfp-pipeline-for-sdg_custom-models"},{"parentId":null,"name":"Train the model by using your prepared data","level":1,"index":4,"id":"train-the-model-by-using-your-prepared-data_custom-models"},{"parentId":"train-the-model-by-using-your-prepared-data_custom-models","name":"Explore the Training Hub examples","level":2,"index":0,"id":"explore-the-training-hub-examples_custom-models"},{"parentId":"train-the-model-by-using-your-prepared-data_custom-models","name":"Estimate memory usage","level":2,"index":1,"id":"estimate-memory-usage_custom-models"},{"parentId":"train-the-model-by-using-your-prepared-data_custom-models","name":"Compare the performance of OSFT and SFT training algorithms","level":2,"index":2,"id":"compare-the-performance-of-osft-and-sft_custom-models"},{"parentId":"train-the-model-by-using-your-prepared-data_custom-models","name":"Distribute training jobs by using the KubeFlow Trainer Operator","level":2,"index":3,"id":"_distribute_training_jobs_by_using_the_kubeflow_trainer_operator"},{"parentId":"train-the-model-by-using-your-prepared-data_custom-models","name":"Distributed fine-tuning with Training Hub and Kubeflow Trainer","level":2,"index":4,"id":"_distributed_fine_tuning_with_training_hub_and_kubeflow_trainer"},{"parentId":null,"name":"End-to-end model customization workflow","level":1,"index":5,"id":"end-to-end-model-customization-workflow_custom-models"},{"parentId":null,"name":"Support philosophy: A secure platform","level":1,"index":6,"id":"support-philosophy_custom-models"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/deploying-models/"},"sections":[{"parentId":null,"name":"Storing models","level":1,"index":0,"id":"deploying-models_odh-user"},{"parentId":"deploying-models_odh-user","name":"Using OCI containers for model storage","level":2,"index":0,"id":"using-oci-containers-for-model-storage_odh-user"},{"parentId":"deploying-models_odh-user","name":"Storing a model in an OCI image","level":2,"index":1,"id":"storing-a-model-in-oci-image_odh-user"},{"parentId":"deploying-models_odh-user","name":"Uploading model files to a Persistent Volume Claim (PVC)","level":2,"index":2,"id":"uploading-model-files-to-pvc_odh-user"},{"parentId":null,"name":"Deploying models","level":1,"index":1,"id":"_deploying_models"},{"parentId":"_deploying_models","name":"Deploying models on the model serving platform","level":2,"index":0,"id":"deploying-models-on-the-model-serving-platform_odh-user"},{"parentId":"_deploying_models","name":"Deploying a model stored in an OCI image by using the CLI","level":2,"index":1,"id":"deploying-model-stored-in-oci-image_odh-user"},{"parentId":"_deploying_models","name":"Deploying models by using Distributed Inference with llm-d","level":2,"index":2,"id":"deploying-models-using-distributed-inference_odh-user"},{"parentId":"deploying-models-using-distributed-inference_odh-user","name":"Configuring authentication for Distributed Inference with llm-d using Red&#160;Hat Connectivity Link","level":3,"index":0,"id":"configuring-authentication-for-llmd_odh-user"},{"parentId":"deploying-models-using-distributed-inference_odh-user","name":"Enabling Distributed Inference with llm-d","level":3,"index":1,"id":"enabling-distributed-inference_odh-user"},{"parentId":"deploying-models-using-distributed-inference_odh-user","name":"Example usage for Distributed Inference with llm-d","level":3,"index":2,"id":"ref-example-distributed-inference_odh-user"},{"parentId":"ref-example-distributed-inference_odh-user","name":"Single-node GPU deployment","level":4,"index":0,"id":"_single_node_gpu_deployment"},{"parentId":"ref-example-distributed-inference_odh-user","name":"Multi-node deployment","level":4,"index":1,"id":"_multi_node_deployment"},{"parentId":"ref-example-distributed-inference_odh-user","name":"Intelligent inference scheduler with KV cache routing","level":4,"index":2,"id":"_intelligent_inference_scheduler_with_kv_cache_routing"},{"parentId":"deploying-models-using-distributed-inference_odh-user","name":"Configuring authentication for Distributed Inference with llm-d using Red&#160;Hat Connectivity Link","level":3,"index":3,"id":"configuring-authentication-for-llmd_odh-user"},{"parentId":"_deploying_models","name":"Monitoring models","level":2,"index":3,"id":"_monitoring_models"},{"parentId":"_monitoring_models","name":"Viewing performance metrics for a deployed model","level":3,"index":0,"id":"viewing-performance-metrics-for-deployed-model_odh-user"},{"parentId":"_monitoring_models","name":"Viewing model-serving runtime metrics for the model serving platform","level":3,"index":1,"id":"viewing-metrics-for-the-model-serving-platform_odh-user"},{"parentId":null,"name":"Deploying models on the NVIDIA NIM model serving platform","level":1,"index":2,"id":"_deploying_models_on_the_nvidia_nim_model_serving_platform"},{"parentId":"_deploying_models_on_the_nvidia_nim_model_serving_platform","name":"Deploying models on the NVIDIA NIM model serving platform","level":2,"index":0,"id":"deploying-models-on-the-NVIDIA-NIM-model-serving-platform_odh-user"},{"parentId":"_deploying_models_on_the_nvidia_nim_model_serving_platform","name":"Viewing NVIDIA NIM metrics for a NIM model","level":2,"index":1,"id":"viewing-nvidia-nim-metrics-for-a-nim-model_odh-user"},{"parentId":"_deploying_models_on_the_nvidia_nim_model_serving_platform","name":"Viewing performance metrics for a NIM model","level":2,"index":2,"id":"viewing-performance-metrics-for-a-nim-model_odh-user"},{"parentId":null,"name":"Making inference requests to deployed models","level":1,"index":3,"id":"_making_inference_requests_to_deployed_models"},{"parentId":"_making_inference_requests_to_deployed_models","name":"Accessing the authentication token for a deployed model","level":2,"index":0,"id":"accessing-authentication-token-for-deployed-model_odh-user"},{"parentId":"_making_inference_requests_to_deployed_models","name":"Accessing the inference endpoint for a deployed model","level":2,"index":1,"id":"accessing-inference-endpoint-for-model_odh-user"},{"parentId":"_making_inference_requests_to_deployed_models","name":"Making inference requests to models deployed on the model serving platform","level":2,"index":2,"id":"making-inference-requests-to-models-deployed-on-model-serving-platform_odh-user"},{"parentId":"_making_inference_requests_to_deployed_models","name":"Inference endpoints","level":2,"index":3,"id":"inference-endpoints_odh-user"},{"parentId":"inference-endpoints_odh-user","name":"Caikit TGIS ServingRuntime for KServe","level":3,"index":0,"id":"_caikit_tgis_servingruntime_for_kserve"},{"parentId":"inference-endpoints_odh-user","name":"OpenVINO Model Server","level":3,"index":1,"id":"_openvino_model_server"},{"parentId":"inference-endpoints_odh-user","name":"vLLM NVIDIA GPU ServingRuntime for KServe","level":3,"index":2,"id":"_vllm_nvidia_gpu_servingruntime_for_kserve"},{"parentId":"inference-endpoints_odh-user","name":"vLLM Intel Gaudi Accelerator ServingRuntime for KServe","level":3,"index":3,"id":"_vllm_intel_gaudi_accelerator_servingruntime_for_kserve"},{"parentId":"inference-endpoints_odh-user","name":"vLLM AMD GPU ServingRuntime for KServe","level":3,"index":4,"id":"_vllm_amd_gpu_servingruntime_for_kserve"},{"parentId":"inference-endpoints_odh-user","name":"vLLM Spyre AI Accelerator ServingRuntime for KServe","level":3,"index":5,"id":"_vllm_spyre_ai_accelerator_servingruntime_for_kserve"},{"parentId":"inference-endpoints_odh-user","name":"vLLM Spyre s390x ServingRuntime for KServe","level":3,"index":6,"id":"_vllm_spyre_s390x_servingruntime_for_kserve"},{"parentId":"inference-endpoints_odh-user","name":"NVIDIA Triton Inference Server","level":3,"index":7,"id":"_nvidia_triton_inference_server"},{"parentId":"inference-endpoints_odh-user","name":"Seldon MLServer","level":3,"index":8,"id":"_seldon_mlserver"},{"parentId":"inference-endpoints_odh-user","name":"Additional resources","level":3,"index":9,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/enabling-ai-safety/"},"sections":[{"parentId":null,"name":"Enabling AI safety with Guardrails","level":1,"index":0,"id":"enabling-ai-safety-with-guardrails_safety"},{"parentId":"enabling-ai-safety-with-guardrails_safety","name":"Understanding detectors","level":2,"index":0,"id":"guardrails-detectors_safety"},{"parentId":"guardrails-detectors_safety","name":"Built-in Detector","level":3,"index":0,"id":"_built_in_detector"},{"parentId":"guardrails-detectors_safety","name":"The Hugging Face Detector serving runtime","level":3,"index":1,"id":"guardrails-configuring-the-hugging-face-detector-serving-runtime_safety"},{"parentId":"guardrails-configuring-the-hugging-face-detector-serving-runtime_safety","name":"Guardrails Detector Hugging Face serving runtime configuration values","level":4,"index":0,"id":"_guardrails_detector_hugging_face_serving_runtime_configuration_values"},{"parentId":"enabling-ai-safety-with-guardrails_safety","name":"Orchestrator Configuration Parameters","level":2,"index":1,"id":"guardrails-orchestrator-config-parameters_safety"},{"parentId":"enabling-ai-safety-with-guardrails_safety","name":"Guardrails Gateway Config Parameters","level":2,"index":2,"id":"guardrails-gateway-config-parameters_safety"},{"parentId":"enabling-ai-safety-with-guardrails_safety","name":"Deploying the Guardrails Orchestrator","level":2,"index":3,"id":"deploying-the-guardrails-orchestrator-service_safety"},{"parentId":"enabling-ai-safety-with-guardrails_safety","name":"Auto-configuring Guardrails","level":2,"index":4,"id":"guardrails-auto-config_safety"},{"parentId":"enabling-ai-safety-with-guardrails_safety","name":"Configuring the OpenTelemetry exporter","level":2,"index":5,"id":"configuring-the-opentelemetry-exporter_safety"},{"parentId":null,"name":"Using Guardrails for AI safety","level":1,"index":1,"id":"using-guardrails-for-ai-safety_safety"},{"parentId":"using-guardrails-for-ai-safety_safety","name":"Detecting PII and sensitive data","level":2,"index":0,"id":"_detecting_pii_and_sensitive_data"},{"parentId":"using-guardrails-for-ai-safety_safety","name":"Detecting personally identifiable information (PII) by using Guardrails with Llama Stack","level":2,"index":1,"id":"detecting-pii-by-using-guardrails-with-llama-stack_safety"},{"parentId":"using-guardrails-for-ai-safety_safety","name":"Filtering flagged content by sending requests to the regex detector","level":2,"index":2,"id":"filtering-flagged-content-by-sending-requests-to-the-regex-detector_safety"},{"parentId":"using-guardrails-for-ai-safety_safety","name":"Securing prompts","level":2,"index":3,"id":"_securing_prompts"},{"parentId":"using-guardrails-for-ai-safety_safety","name":"Mitigating Prompt Injection by using a Hugging Face Prompt Injection detector","level":2,"index":4,"id":"mitigating-prompt-injection-by-using-a-hugging-face-prompt-injection-detector_safety"},{"parentId":"using-guardrails-for-ai-safety_safety","name":"Moderating and safeguarding content","level":2,"index":5,"id":"_moderating_and_safeguarding_content"},{"parentId":"using-guardrails-for-ai-safety_safety","name":"Detecting hateful and profane language","level":2,"index":6,"id":"detecting-hateful-and-profane-language_safety"},{"parentId":"using-guardrails-for-ai-safety_safety","name":"Enforcing configured safety pipelines for LLM inference by using Guardrails Gateway","level":2,"index":7,"id":"enforcing-configured-safety-pipelines-for-llm-inference-using-guardrails-gateway_safety"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/evaluating-ai-systems/"},"sections":[{"parentId":null,"name":"Overview of evaluating AI systems","level":1,"index":0,"id":"overview-evaluating-ai-systems_evaluate"},{"parentId":null,"name":"Evaluating large language models","level":1,"index":1,"id":"evaluating-large-language-models_evaluate"},{"parentId":"evaluating-large-language-models_evaluate","name":"Setting up LM-Eval","level":2,"index":0,"id":"setting-up-lmeval_evaluate"},{"parentId":"evaluating-large-language-models_evaluate","name":"Enabling external resource access for LMEval jobs","level":2,"index":1,"id":"enabling-external-resource-access-for-lmeval-jobs_evaluate"},{"parentId":"enabling-external-resource-access-for-lmeval-jobs_evaluate","name":"Enabling online access and remote code execution for LMEval Jobs using the CLI","level":3,"index":0,"id":"enabling-online-access-and-remote-code-execution-LMEvalJob-using-the-cli_evaluate"},{"parentId":"enabling-external-resource-access-for-lmeval-jobs_evaluate","name":"Updating LMEval job configuration using the web console","level":3,"index":1,"id":"updating-lmeval-job-configuration-using-the-web-console_evaluate"},{"parentId":"evaluating-large-language-models_evaluate","name":"LM-Eval evaluation job","level":2,"index":2,"id":"lmeval-evaluation-job_evaluate"},{"parentId":"evaluating-large-language-models_evaluate","name":"LM-Eval evaluation job properties","level":2,"index":3,"id":"lmeval-evaluation-job-properties_evaluate"},{"parentId":"lmeval-evaluation-job-properties_evaluate","name":"Properties for setting up custom Unitxt cards, templates, or system prompts","level":3,"index":0,"id":"_properties_for_setting_up_custom_unitxt_cards_templates_or_system_prompts"},{"parentId":"evaluating-large-language-models_evaluate","name":"Performing model evaluations in the dashboard","level":2,"index":4,"id":"performing-model-evaluations-in-the-dashboard_evaluate"},{"parentId":"evaluating-large-language-models_evaluate","name":"LM-Eval scenarios","level":2,"index":5,"id":"lmeval-scenarios_evaluate"},{"parentId":"lmeval-scenarios_evaluate","name":"Accessing Hugging Face models with an environment variable token","level":3,"index":0,"id":"accessing-hugging-face-models-with-an-environment-variable-token_evaluate"},{"parentId":"lmeval-scenarios_evaluate","name":"Using a custom Unitxt card","level":3,"index":1,"id":"using-a-custom-unitxt-card_evaluate"},{"parentId":"lmeval-scenarios_evaluate","name":"Using PVCs as storage","level":3,"index":2,"id":"using-pvcs-as-storage_evaluate"},{"parentId":"using-pvcs-as-storage_evaluate","name":"Managed PVCs","level":4,"index":0,"id":"_managed_pvcs"},{"parentId":"using-pvcs-as-storage_evaluate","name":"Existing PVCs","level":4,"index":1,"id":"_existing_pvcs"},{"parentId":"lmeval-scenarios_evaluate","name":"Using a KServe Inference Service","level":3,"index":3,"id":"using-a-kserve-inference-service_evaluate"},{"parentId":"lmeval-scenarios_evaluate","name":"Setting up LM-Eval S3 Support","level":3,"index":4,"id":"setting-up-lmeval-s3-support_evaluate"},{"parentId":"lmeval-scenarios_evaluate","name":"Using LLM-as-a-Judge metrics with LM-Eval","level":3,"index":5,"id":"using-llm-as-a-judge-metrics-with-lmeval_evaluate"},{"parentId":null,"name":"Using llama stack with TrustyAI","level":1,"index":2,"id":"using-llama-stack-with-trustyai_evaluate"},{"parentId":"using-llama-stack-with-trustyai_evaluate","name":"Using Llama Stack external evaluation provider with lm-evaluation-harness in TrustyAI","level":2,"index":0,"id":"using-llama-stack-external-evaluation-provider-with-lm-evaluation-harness-in-TrustyAI_evaluate"},{"parentId":"using-llama-stack-with-trustyai_evaluate","name":"Running custom evaluations with LM-Eval and Llama Stack","level":2,"index":1,"id":"running-custom-evaluations-with-LMEval-and-llama-stack_evaluate"},{"parentId":"using-llama-stack-with-trustyai_evaluate","name":"Detecting personally identifiable information (PII) by using Guardrails with Llama Stack","level":2,"index":2,"id":"detecting-pii-by-using-guardrails-with-llama-stack_evaluate"},{"parentId":null,"name":"Evaluating RAG systems with Ragas","level":1,"index":3,"id":"evaluating-rag-systems-with-ragas_evaluate"},{"parentId":"evaluating-rag-systems-with-ragas_evaluate","name":"About Ragas evaluation","level":2,"index":0,"id":"_about_ragas_evaluation"},{"parentId":"_about_ragas_evaluation","name":"Key Ragas metrics","level":3,"index":0,"id":"_key_ragas_metrics"},{"parentId":"_about_ragas_evaluation","name":"Use cases for Ragas in AI engineering workflows","level":3,"index":1,"id":"_use_cases_for_ragas_in_ai_engineering_workflows"},{"parentId":"_about_ragas_evaluation","name":"Ragas provider deployment modes","level":3,"index":2,"id":"_ragas_provider_deployment_modes"},{"parentId":"evaluating-rag-systems-with-ragas_evaluate","name":"Setting up the Ragas inline provider for development","level":2,"index":1,"id":"setting-up-ragas-inline-provider_evaluate"},{"parentId":"evaluating-rag-systems-with-ragas_evaluate","name":"Configuring the Ragas remote provider for production","level":2,"index":2,"id":"configuring-ragas-remote-provider-for-production_evaluate"},{"parentId":"evaluating-rag-systems-with-ragas_evaluate","name":"Evaluating RAG system quality with Ragas metrics","level":2,"index":3,"id":"evaluating-rag-system-quality-with-ragas_evaluate"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/experimenting-with-models-in-the-gen-ai-playground/"},"sections":[{"parentId":null,"name":"Experimenting with models in the gen AI playground","level":1,"index":0,"id":"experimenting-with-models-in-the-gen-ai-playground_rhoai-user"},{"parentId":"experimenting-with-models-in-the-gen-ai-playground_rhoai-user","name":"Playground overview","level":2,"index":0,"id":"playground-overview_rhoai-user"},{"parentId":"playground-overview_rhoai-user","name":"Core capabilities","level":3,"index":0,"id":"_core_capabilities"},{"parentId":"experimenting-with-models-in-the-gen-ai-playground_rhoai-user","name":"Playground prerequisites","level":2,"index":1,"id":"playground-prerequisites_rhoai-user"},{"parentId":"playground-prerequisites_rhoai-user","name":"Cluster administrator prerequisites","level":3,"index":0,"id":"_cluster_administrator_prerequisites"},{"parentId":"playground-prerequisites_rhoai-user","name":"User prerequisites","level":3,"index":1,"id":"_user_prerequisites"},{"parentId":"playground-prerequisites_rhoai-user","name":"Model and runtime requirements for the playground","level":3,"index":2,"id":"_model_and_runtime_requirements_for_the_playground"},{"parentId":"_model_and_runtime_requirements_for_the_playground","name":"Key model selection factors","level":4,"index":0,"id":"_key_model_selection_factors"},{"parentId":"_model_and_runtime_requirements_for_the_playground","name":"Example model configuration","level":4,"index":1,"id":"_example_model_configuration"},{"parentId":"playground-prerequisites_rhoai-user","name":"Configuring Model Control Protocol (MCP) servers","level":3,"index":3,"id":"configuring-model-control-protocol-servers_rhoai-user"},{"parentId":"experimenting-with-models-in-the-gen-ai-playground_rhoai-user","name":"About the AI assets endpoint page","level":2,"index":2,"id":"About-the-ai-assets-endpoint-page_rhoai-user"},{"parentId":"experimenting-with-models-in-the-gen-ai-playground_rhoai-user","name":"Configuring a playground for your project","level":2,"index":3,"id":"configuring-a-playground-for-your-project_rhoai-user"},{"parentId":"experimenting-with-models-in-the-gen-ai-playground_rhoai-user","name":"Testing baseline model responses","level":2,"index":4,"id":"testing-baseline-model-responses_rhoai-user"},{"parentId":"experimenting-with-models-in-the-gen-ai-playground_rhoai-user","name":"Testing your model with retrieval augmented generation (RAG)","level":2,"index":5,"id":"testing-your-model-with-rag_rhoai-user"},{"parentId":"testing-your-model-with-rag_rhoai-user","name":"Understanding RAG settings","level":3,"index":0,"id":"understanding-rag-settings_rhoai-user"},{"parentId":"experimenting-with-models-in-the-gen-ai-playground_rhoai-user","name":"Testing with model control protocol (MCP) servers","level":2,"index":6,"id":"testing-with-model-control-protocol-servers_rhoai-user"},{"parentId":"experimenting-with-models-in-the-gen-ai-playground_rhoai-user","name":"Exporting your playground configuration","level":2,"index":7,"id":"exporting-your-playground-configuration_rhoai-user"},{"parentId":"experimenting-with-models-in-the-gen-ai-playground_rhoai-user","name":"Updating your playground configuration","level":2,"index":8,"id":"updating-your-playground-configuration_rhoai-user"},{"parentId":"experimenting-with-models-in-the-gen-ai-playground_rhoai-user","name":"Deleting a playground from your project","level":2,"index":9,"id":"Deleting-a-playground-from-your-project_rhoai-user"},{"parentId":"experimenting-with-models-in-the-gen-ai-playground_rhoai-user","name":"Next steps","level":2,"index":10,"id":"next-steps_rhoai-user"},{"parentId":"experimenting-with-models-in-the-gen-ai-playground_rhoai-user","name":"Troubleshooting playground issues","level":2,"index":11,"id":"troubleshooting-playground-issues_rhoai-user"},{"parentId":"troubleshooting-playground-issues_rhoai-user","name":"The chatbot thinks indefinitely","level":3,"index":0,"id":"_the_chatbot_thinks_indefinitely"},{"parentId":"troubleshooting-playground-issues_rhoai-user","name":"The model does not use RAG data","level":3,"index":1,"id":"_the_model_does_not_use_rag_data"},{"parentId":"troubleshooting-playground-issues_rhoai-user","name":"MCP servers are missing from the UI","level":3,"index":2,"id":"_mcp_servers_are_missing_from_the_ui"},{"parentId":"troubleshooting-playground-issues_rhoai-user","name":"The model fails to call MCP tools","level":3,"index":3,"id":"_the_model_fails_to_call_mcp_tools"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/getting-started-with-open-data-hub/"},"sections":[{"parentId":null,"name":"Overview","level":1,"index":0,"id":"overview-for-getting-started_get-started"},{"parentId":"overview-for-getting-started_get-started","name":"Data science workflow","level":2,"index":0,"id":"_data_science_workflow"},{"parentId":"overview-for-getting-started_get-started","name":"About this guide","level":2,"index":1,"id":"_about_this_guide"},{"parentId":"overview-for-getting-started_get-started","name":"Glossary of common terms","level":2,"index":2,"id":"glossary-of-common-terms_get-started"},{"parentId":null,"name":"Logging in to Open Data Hub","level":1,"index":1,"id":"logging-in_get-started"},{"parentId":"logging-in_get-started","name":"Viewing installed Open Data Hub components","level":2,"index":0,"id":"viewing-installed-components_get-started"},{"parentId":null,"name":"Creating a project","level":1,"index":2,"id":"creating-a-project_get-started"},{"parentId":null,"name":"Creating a workbench and selecting an IDE","level":1,"index":3,"id":"creating-a-workbench-select-ide_get-started"},{"parentId":"creating-a-workbench-select-ide_get-started","name":"About workbench images","level":2,"index":0,"id":"about-workbench-images_get-started"},{"parentId":"creating-a-workbench-select-ide_get-started","name":"Creating a workbench","level":2,"index":1,"id":"creating-a-project-workbench_get-started"},{"parentId":null,"name":"Next steps","level":1,"index":4,"id":"next-steps_get-started"},{"parentId":"next-steps_get-started","name":"Additional resources","level":2,"index":0,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/installing-open-data-hub/"},"sections":[{"parentId":null,"name":"Installing Open Data Hub version 2","level":1,"index":0,"id":"installing-odh-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Configuring custom namespaces","level":2,"index":0,"id":"configuring-custom-namespaces"},{"parentId":"installing-odh-v2_installv2","name":"Installing the Open Data Hub Operator version 2","level":2,"index":1,"id":"installing-the-odh-operator-v2_installv2"},{"parentId":"installing-odh-v2_installv2","name":"Installing Open Data Hub components","level":2,"index":2,"id":"installing-odh-components_installv2"},{"parentId":null,"name":"Configuring pipelines with your own Argo Workflows instance","level":1,"index":1,"id":"configuring-pipelines-with-your-own-argo-workflows-instance_install"},{"parentId":null,"name":"Installing the distributed workloads components","level":1,"index":2,"id":"installing-the-distributed-workloads-components_install"},{"parentId":null,"name":"Accessing the dashboard","level":1,"index":3,"id":"accessing-the-dashboard_install"},{"parentId":null,"name":"Working with certificates","level":1,"index":4,"id":"working-with-certificates_certs"},{"parentId":"working-with-certificates_certs","name":"Understanding how Open Data Hub handles certificates","level":2,"index":0,"id":"understanding-certificates_certs"},{"parentId":"working-with-certificates_certs","name":"Adding certificates","level":2,"index":1,"id":"_adding_certificates"},{"parentId":"working-with-certificates_certs","name":"Adding certificates to a cluster-wide CA bundle","level":2,"index":2,"id":"adding-certificates-to-a-cluster-ca-bundle_certs"},{"parentId":"working-with-certificates_certs","name":"Adding certificates to a custom CA bundle","level":2,"index":3,"id":"adding-certificates-to-a-custom-ca-bundle_certs"},{"parentId":"working-with-certificates_certs","name":"Using self-signed certificates with Open Data Hub components","level":2,"index":4,"id":"_using_self_signed_certificates_with_open_data_hub_components"},{"parentId":"_using_self_signed_certificates_with_open_data_hub_components","name":"Accessing S3-compatible object storage with self-signed certificates","level":3,"index":0,"id":"accessing-s3-compatible-object-storage-with-self-signed-certificates_certs"},{"parentId":"_using_self_signed_certificates_with_open_data_hub_components","name":"Configuring a certificate for pipelines","level":3,"index":1,"id":"configuring-a-certificate-for-pipelines_certs"},{"parentId":"_using_self_signed_certificates_with_open_data_hub_components","name":"Configuring a certificate for workbenches","level":3,"index":2,"id":"configuring-a-certificate-for-workbenches_certs"},{"parentId":"_using_self_signed_certificates_with_open_data_hub_components","name":"Using the cluster-wide CA bundle for the model serving platform","level":3,"index":3,"id":"using-the-cluster-CA-bundle-for-model-serving_certs"},{"parentId":"working-with-certificates_certs","name":"Managing certificates without the Open Data Hub Operator","level":2,"index":5,"id":"managing-certificates-without-the-operator_certs"},{"parentId":"working-with-certificates_certs","name":"Removing the CA bundle","level":2,"index":6,"id":"_removing_the_ca_bundle"},{"parentId":"_removing_the_ca_bundle","name":"Removing the CA bundle from all namespaces","level":3,"index":0,"id":"removing-the-ca-bundle-from-all-namespaces_certs"},{"parentId":"_removing_the_ca_bundle","name":"Removing the CA bundle from a single namespace","level":3,"index":1,"id":"removing-the-ca-bundle-from-a-single-namespace_certs"},{"parentId":null,"name":"Viewing logs and audit records","level":1,"index":5,"id":"viewing-logs-and-audit-records_install"},{"parentId":"viewing-logs-and-audit-records_install","name":"Configuring the Open Data Hub Operator logger","level":2,"index":0,"id":"configuring-the-operator-logger_install"},{"parentId":"configuring-the-operator-logger_install","name":"Viewing the Open Data Hub Operator logs","level":3,"index":0,"id":"_viewing_the_open_data_hub_operator_logs"},{"parentId":"viewing-logs-and-audit-records_install","name":"Viewing audit records","level":2,"index":1,"id":"viewing-audit-records_install"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/managing-and-monitoring-models/"},"sections":[{"parentId":null,"name":"Managing model-serving runtimes","level":1,"index":0,"id":"managing-and-monitoring-models_cluster-admin"},{"parentId":"managing-and-monitoring-models_cluster-admin","name":"Adding a custom model-serving runtime","level":2,"index":0,"id":"adding-a-custom-model-serving-runtime_cluster-admin"},{"parentId":null,"name":"Managing and monitoring models","level":1,"index":1,"id":"_managing_and_monitoring_models"},{"parentId":"_managing_and_monitoring_models","name":"Setting a timeout for KServe","level":2,"index":0,"id":"setting-timeout-for-kserve_cluster-admin"},{"parentId":"_managing_and_monitoring_models","name":"Deploying models by using multiple GPU nodes","level":2,"index":1,"id":"deploying-models-using-multiple-gpu-nodes_cluster-admin"},{"parentId":"_managing_and_monitoring_models","name":"Configuring an inference service for Kueue","level":2,"index":2,"id":"configuring-an-inference-service-for-kueue_cluster-admin"},{"parentId":"_managing_and_monitoring_models","name":"Configuring an inference service for Spyre","level":2,"index":3,"id":"configuring-inference-service-for-spyre_cluster-admin"},{"parentId":"_managing_and_monitoring_models","name":"Optimizing performance and tuning","level":2,"index":4,"id":"_optimizing_performance_and_tuning"},{"parentId":"_optimizing_performance_and_tuning","name":"Determining GPU requirements for LLM-powered applications","level":3,"index":0,"id":"determining-gpu-requirements-for-llm-powered-applications_cluster-admin"},{"parentId":"_optimizing_performance_and_tuning","name":"Performance considerations for text-summarization and retrieval-augmented generation (RAG) applications","level":3,"index":1,"id":"performance-considerations-for-document-based-apps_cluster-admin"},{"parentId":"_optimizing_performance_and_tuning","name":"Inference performance metrics","level":3,"index":2,"id":"inference-performance-metrics_cluster-admin"},{"parentId":"inference-performance-metrics_cluster-admin","name":"Latency","level":4,"index":0,"id":"_latency"},{"parentId":"inference-performance-metrics_cluster-admin","name":"Throughput","level":4,"index":1,"id":"_throughput"},{"parentId":"inference-performance-metrics_cluster-admin","name":"Cost per million tokens","level":4,"index":2,"id":"_cost_per_million_tokens"},{"parentId":"_optimizing_performance_and_tuning","name":"Configuring metrics-based autoscaling","level":3,"index":3,"id":"configuring-metrics-based-autoscaling_cluster-admin"},{"parentId":"_optimizing_performance_and_tuning","name":"Guidelines for metrics-based autoscaling","level":3,"index":4,"id":"guidelines-for-metrics-based-autoscaling_cluster-admin"},{"parentId":"guidelines-for-metrics-based-autoscaling_cluster-admin","name":"Choosing metrics for latency and throughput-optimized scaling","level":4,"index":0,"id":"_choosing_metrics_for_latency_and_throughput_optimized_scaling"},{"parentId":"guidelines-for-metrics-based-autoscaling_cluster-admin","name":"Choosing the right sliding window","level":4,"index":1,"id":"_choosing_the_right_sliding_window"},{"parentId":"guidelines-for-metrics-based-autoscaling_cluster-admin","name":"Optimizing HPA scale-down configuration","level":4,"index":2,"id":"_optimizing_hpa_scale_down_configuration"},{"parentId":"guidelines-for-metrics-based-autoscaling_cluster-admin","name":"Considering model size for optimal scaling","level":4,"index":3,"id":"_considering_model_size_for_optimal_scaling"},{"parentId":"_managing_and_monitoring_models","name":"Monitoring models","level":2,"index":5,"id":"_monitoring_models"},{"parentId":"_monitoring_models","name":"Configuring monitoring for the model serving platform","level":3,"index":0,"id":"configuring-monitoring-for-the-model-serving-platform_cluster-admin"},{"parentId":"_managing_and_monitoring_models","name":"Using Grafana to monitor model performance","level":2,"index":6,"id":"_using_grafana_to_monitor_model_performance"},{"parentId":"_using_grafana_to_monitor_model_performance","name":"Deploying a Grafana metrics dashboard","level":3,"index":0,"id":"deploying-a-grafana-metrics-dashboard_cluster-admin"},{"parentId":"_using_grafana_to_monitor_model_performance","name":"Deploying a vLLM/GPU metrics dashboard on a Grafana instance","level":3,"index":1,"id":"deploying-vllm-gpu-metrics-dashboard-grafana_cluster-admin"},{"parentId":"_using_grafana_to_monitor_model_performance","name":"Grafana metrics","level":3,"index":2,"id":"ref-grafana-metrics_cluster-admin"},{"parentId":"ref-grafana-metrics_cluster-admin","name":"Accelerator metrics","level":4,"index":0,"id":"ref-accelerator-metrics_cluster-admin"},{"parentId":"ref-grafana-metrics_cluster-admin","name":"CPU metrics","level":4,"index":1,"id":"ref-cpu-metrics_cluster-admin"},{"parentId":"ref-grafana-metrics_cluster-admin","name":"vLLM metrics","level":4,"index":2,"id":"ref-vllm-metrics_cluster-admin"},{"parentId":null,"name":"Managing and monitoring models on the NVIDIA NIM model serving platform","level":1,"index":2,"id":"_managing_and_monitoring_models_on_the_nvidia_nim_model_serving_platform"},{"parentId":"_managing_and_monitoring_models_on_the_nvidia_nim_model_serving_platform","name":"Customizing model selection options for the NVIDIA NIM model serving platform","level":2,"index":0,"id":"Customizing-model-selection-options_cluster-admin"},{"parentId":"_managing_and_monitoring_models_on_the_nvidia_nim_model_serving_platform","name":"Enabling NVIDIA NIM metrics for an existing NIM deployment","level":2,"index":1,"id":"enabling-nim-metrics-for-an-existing-nim-deployment_cluster-admin"},{"parentId":"enabling-nim-metrics-for-an-existing-nim-deployment_cluster-admin","name":"Enabling graph generation for an existing NIM deployment","level":3,"index":0,"id":"_enabling_graph_generation_for_an_existing_nim_deployment"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/managing-odh/"},"sections":[{"parentId":null,"name":"Managing users and groups","level":1,"index":0,"id":"managing-users-and-groups"},{"parentId":"managing-users-and-groups","name":"Overview of user types and permissions","level":2,"index":0,"id":"overview-of-user-types-and-permissions_managing-odh"},{"parentId":"managing-users-and-groups","name":"Viewing Open Data Hub users","level":2,"index":1,"id":"viewing-data-science-users_managing-odh"},{"parentId":"managing-users-and-groups","name":"Adding users to Open Data Hub user groups","level":2,"index":2,"id":"adding-users-to-user-groups_managing-odh"},{"parentId":"managing-users-and-groups","name":"Selecting Open Data Hub administrator and user groups","level":2,"index":3,"id":"selecting-admin-and-user-groups_managing-odh"},{"parentId":"managing-users-and-groups","name":"Deleting users","level":2,"index":4,"id":"_deleting_users"},{"parentId":"_deleting_users","name":"About deleting users and their resources","level":3,"index":0,"id":"about-deleting-users-and-resources_managing-odh"},{"parentId":"_deleting_users","name":"Stopping basic workbenches owned by other users","level":3,"index":1,"id":"stopping-basic-workbenches-owned-by-other-users_managing-odh"},{"parentId":"_deleting_users","name":"Revoking user access to basic workbenches","level":3,"index":2,"id":"revoking-user-access-to-basic-workbenches_managing-odh"},{"parentId":"_deleting_users","name":"Backing up storage data","level":3,"index":3,"id":"backing-up-storage-data_managing-odh"},{"parentId":"_deleting_users","name":"Cleaning up after deleting users","level":3,"index":4,"id":"cleaning-up-after-deleting-users_managing-odh"},{"parentId":null,"name":"Creating custom workbench images","level":1,"index":1,"id":"creating-custom-workbench-images"},{"parentId":"creating-custom-workbench-images","name":"Creating a custom image from a default Open Data Hub image","level":2,"index":0,"id":"creating-a-custom-image-from-default-image_custom-images"},{"parentId":"creating-custom-workbench-images","name":"Creating a custom image from your own image","level":2,"index":1,"id":"creating-a-custom-image-from-your-own-image_custom-images"},{"parentId":"creating-a-custom-image-from-your-own-image_custom-images","name":"Basic guidelines for creating your own workbench image","level":3,"index":0,"id":"_basic_guidelines_for_creating_your_own_workbench_image"},{"parentId":"creating-a-custom-image-from-your-own-image_custom-images","name":"Advanced guidelines for creating your own workbench image","level":3,"index":1,"id":"_advanced_guidelines_for_creating_your_own_workbench_image"},{"parentId":"creating-custom-workbench-images","name":"Enabling custom images in Open Data Hub","level":2,"index":2,"id":"enabling-custom-images_custom-images"},{"parentId":"creating-custom-workbench-images","name":"Importing a custom workbench image","level":2,"index":3,"id":"importing-a-custom-workbench-image_custom-images"},{"parentId":null,"name":"Managing applications that show in the dashboard","level":1,"index":2,"id":"managing-applications-that-show-in-the-dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Adding an application to the dashboard","level":2,"index":0,"id":"adding-an-application-to-the-dashboard_dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Preventing users from adding applications to the dashboard","level":2,"index":1,"id":"preventing-users-from-adding-applications-to-the-dashboard_dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Disabling applications connected to Open Data Hub","level":2,"index":2,"id":"disabling-applications-connected_dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Showing or hiding information about available applications","level":2,"index":3,"id":"showing-hiding-information-about-available-applications_dashboard"},{"parentId":"managing-applications-that-show-in-the-dashboard","name":"Hiding the default basic workbench application","level":2,"index":4,"id":"hiding-the-default-basic-workbench-application_dashboard"},{"parentId":null,"name":"Creating project-scoped resources","level":1,"index":3,"id":"creating-project-scoped-resources_managing-odh"},{"parentId":null,"name":"Allocating additional resources to Open Data Hub users","level":1,"index":4,"id":"allocating-additional-resources-to-users_managing-odh"},{"parentId":null,"name":"Customizing component deployment resources","level":1,"index":5,"id":"customizing-component-deployment-resources_managing-resources"},{"parentId":"customizing-component-deployment-resources_managing-resources","name":"Overview of component resource customization","level":2,"index":0,"id":"overview-of-component-resource-customization_managing-resources"},{"parentId":"customizing-component-deployment-resources_managing-resources","name":"Customizing component resources","level":2,"index":1,"id":"customizing-component-resources_managing-resources"},{"parentId":"customizing-component-deployment-resources_managing-resources","name":"Disabling component resource customization","level":2,"index":2,"id":"disabling-component-resource-customization_managing-resources"},{"parentId":"customizing-component-deployment-resources_managing-resources","name":"Re-enabling component resource customization","level":2,"index":3,"id":"reenabling-component-resource-customization_managing-resources"},{"parentId":null,"name":"Enabling accelerators","level":1,"index":6,"id":"enabling-accelerators"},{"parentId":"enabling-accelerators","name":"Enabling NVIDIA GPUs","level":2,"index":0,"id":"enabling-nvidia-gpus_managing-odh"},{"parentId":"enabling-accelerators","name":"Intel Gaudi AI Accelerator integration","level":2,"index":1,"id":"intel-gaudi-ai-accelerator-integration_managing-odh"},{"parentId":"intel-gaudi-ai-accelerator-integration_managing-odh","name":"Enabling Intel Gaudi AI accelerators","level":3,"index":0,"id":"enabling-intel-gaudi-ai-accelerators_managing-odh"},{"parentId":"enabling-accelerators","name":"AMD GPU Integration","level":2,"index":2,"id":"amd-gpu-integration_managing-odh"},{"parentId":"amd-gpu-integration_managing-odh","name":"Verifying AMD GPU availability on your cluster","level":3,"index":0,"id":"verifying-amd-gpu-availability-on-your-cluster_managing-odh"},{"parentId":"amd-gpu-integration_managing-odh","name":"Enabling AMD GPUs","level":3,"index":1,"id":"enabling-amd-gpus_managing-odh"},{"parentId":null,"name":"Managing workloads with Kueue","level":1,"index":7,"id":"managing-workloads-with-kueue"},{"parentId":"managing-workloads-with-kueue","name":"Overview of managing workloads with Kueue","level":2,"index":0,"id":"overview-of-managing-workloads-with-kueue_kueue"},{"parentId":"overview-of-managing-workloads-with-kueue_kueue","name":"Kueue management states","level":3,"index":0,"id":"_kueue_management_states"},{"parentId":"overview-of-managing-workloads-with-kueue_kueue","name":"Queue enforcement for projects","level":3,"index":1,"id":"_queue_enforcement_for_projects"},{"parentId":"overview-of-managing-workloads-with-kueue_kueue","name":"Restrictions for managing workloads with Kueue","level":3,"index":2,"id":"_restrictions_for_managing_workloads_with_kueue"},{"parentId":"overview-of-managing-workloads-with-kueue_kueue","name":"Kueue workflow","level":3,"index":3,"id":"kueue-workflow_kueue"},{"parentId":"managing-workloads-with-kueue","name":"Configuring workload management with Kueue","level":2,"index":1,"id":"configuring-workload-management-with-kueue_kueue"},{"parentId":"configuring-workload-management-with-kueue_kueue","name":"Enabling Kueue in the dashboard","level":3,"index":0,"id":"enabling-kueue-in-the-dashboard_kueue"},{"parentId":"managing-workloads-with-kueue","name":"Troubleshooting common problems with Kueue","level":2,"index":2,"id":"troubleshooting-common-problems-with-Kueue_kueue"},{"parentId":"troubleshooting-common-problems-with-Kueue_kueue","name":"A user receives a \"failed to call webhook\" error message for Kueue","level":3,"index":0,"id":"_a_user_receives_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":"troubleshooting-common-problems-with-Kueue_kueue","name":"A user receives a \"Default Local Queue &#8230;&#8203; not found\" error message","level":3,"index":1,"id":"_a_user_receives_a_default_local_queue_not_found_error_message"},{"parentId":"troubleshooting-common-problems-with-Kueue_kueue","name":"A user receives a \"local_queue provided does not exist\" error message","level":3,"index":2,"id":"_a_user_receives_a_local_queue_provided_does_not_exist_error_message"},{"parentId":"troubleshooting-common-problems-with-Kueue_kueue","name":"The pod provisioned by Kueue is terminated before the image is pulled","level":3,"index":3,"id":"_the_pod_provisioned_by_kueue_is_terminated_before_the_image_is_pulled"},{"parentId":"troubleshooting-common-problems-with-Kueue_kueue","name":"Additional resources","level":3,"index":4,"id":"_additional_resources"},{"parentId":"managing-workloads-with-kueue","name":"Migrating to the Red Hat build of Kueue Operator","level":2,"index":3,"id":"migrating-to-the-rhbok-operator_kueue"},{"parentId":null,"name":"Managing distributed workloads","level":1,"index":8,"id":"managing-distributed-workloads_managing-odh"},{"parentId":"managing-distributed-workloads_managing-odh","name":"Configuring quota management for distributed workloads","level":2,"index":0,"id":"configuring-quota-management-for-distributed-workloads_managing-odh"},{"parentId":"managing-distributed-workloads_managing-odh","name":"Example Kueue resource configurations for distributed workloads","level":2,"index":1,"id":"ref-example-kueue-resource-configurations_managing-odh"},{"parentId":"ref-example-kueue-resource-configurations_managing-odh","name":"NVIDIA GPUs without shared cohort","level":3,"index":0,"id":"_nvidia_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU resource flavor","level":4,"index":0,"id":"_nvidia_rtx_a400_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU resource flavor","level":4,"index":1,"id":"_nvidia_rtx_a1000_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU cluster queue","level":4,"index":2,"id":"_nvidia_rtx_a400_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU cluster queue","level":4,"index":3,"id":"_nvidia_rtx_a1000_gpu_cluster_queue"},{"parentId":"ref-example-kueue-resource-configurations_managing-odh","name":"NVIDIA GPUs and AMD GPUs without shared cohort","level":3,"index":1,"id":"_nvidia_gpus_and_amd_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU resource flavor","level":4,"index":0,"id":"_amd_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU resource flavor","level":4,"index":1,"id":"_nvidia_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU cluster queue","level":4,"index":2,"id":"_amd_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU cluster queue","level":4,"index":3,"id":"_nvidia_gpu_cluster_queue"},{"parentId":"managing-distributed-workloads_managing-odh","name":"Configuring a cluster for RDMA","level":2,"index":2,"id":"configuring-a-cluster-for-rdma_managing-odh"},{"parentId":"managing-distributed-workloads_managing-odh","name":"Troubleshooting common problems with distributed workloads for administrators","level":2,"index":3,"id":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"A user&#8217;s Ray cluster is in a suspended state","level":3,"index":0,"id":"_a_users_ray_cluster_is_in_a_suspended_state"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"A user&#8217;s Ray cluster is in a failed state","level":3,"index":1,"id":"_a_users_ray_cluster_is_in_a_failed_state"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"A user&#8217;s Ray cluster does not start","level":3,"index":2,"id":"_a_users_ray_cluster_does_not_start"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"A user cannot create a Ray cluster or submit jobs","level":3,"index":3,"id":"_a_user_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh","name":"Additional resources","level":3,"index":4,"id":"_additional_resources_2"},{"parentId":null,"name":"Configuring a central authentication service for an external OIDC identity provider","level":1,"index":9,"id":"configuring-external-oidc-provider_managing-odh"},{"parentId":"configuring-external-oidc-provider_managing-odh","name":"About centralized authentication Gateway API","level":2,"index":0,"id":"about-centralized-auth-oidc_managing-odh"},{"parentId":"configuring-external-oidc-provider_managing-odh","name":"Configuring OpenID Connect (OIDC) authentication for Gateway API","level":2,"index":1,"id":"configuring-oidc-auth-gateway-api_managing-odh"},{"parentId":"configuring-oidc-auth-gateway-api_managing-odh","name":"Security considerations","level":3,"index":0,"id":"_security_considerations"},{"parentId":"configuring-external-oidc-provider_managing-odh","name":"Troubleshooting common problems with Gateway API configuration","level":2,"index":2,"id":"troubleshooting-common-problems-gateway-api_managing-odh"},{"parentId":"troubleshooting-common-problems-gateway-api_managing-odh","name":"The <code>GatewayConfig</code> status shows as not ready","level":3,"index":0,"id":"_the_gatewayconfig_status_shows_as_not_ready"},{"parentId":"troubleshooting-common-problems-gateway-api_managing-odh","name":"Authentication proxy fails to start","level":3,"index":1,"id":"_authentication_proxy_fails_to_start"},{"parentId":"troubleshooting-common-problems-gateway-api_managing-odh","name":"The Gateway is inaccessible","level":3,"index":2,"id":"_the_gateway_is_inaccessible"},{"parentId":"troubleshooting-common-problems-gateway-api_managing-odh","name":"The OIDC authentication fails","level":3,"index":3,"id":"_the_oidc_authentication_fails"},{"parentId":"troubleshooting-common-problems-gateway-api_managing-odh","name":"The dashboard is not accessible after authentication","level":3,"index":4,"id":"_the_dashboard_is_not_accessible_after_authentication"},{"parentId":null,"name":"Backing up data","level":1,"index":10,"id":"backing-up-data_data-mgmt"},{"parentId":"backing-up-data_data-mgmt","name":"Backing up storage data","level":2,"index":0,"id":"backing-up-storage-data_data-mgmt"},{"parentId":"backing-up-data_data-mgmt","name":"Backing up your cluster","level":2,"index":1,"id":"backing-up-your-cluster_data-mgmt"},{"parentId":null,"name":"Managing observability","level":1,"index":11,"id":"managing-observability_managing-odh"},{"parentId":"managing-observability_managing-odh","name":"Enabling the observability stack","level":2,"index":0,"id":"enabling-the-observability-stack_managing-odh"},{"parentId":"managing-observability_managing-odh","name":"Collecting metrics from user workloads","level":2,"index":1,"id":"collecting-metrics-from-user-workloads_managing-odh"},{"parentId":"managing-observability_managing-odh","name":"Exporting metrics to external observability tools","level":2,"index":2,"id":"exporting-metrics-to-external-observability-tools_managing-odh"},{"parentId":"managing-observability_managing-odh","name":"Viewing traces in external tracing platforms","level":2,"index":3,"id":"viewing-traces-in-external-tracing-platforms_managing-odh"},{"parentId":"managing-observability_managing-odh","name":"Accessing built-in alerts","level":2,"index":4,"id":"accessing-built-in-alerts_managing-odh"},{"parentId":null,"name":"Viewing logs and audit records","level":1,"index":12,"id":"viewing-logs-and-audit-records_managing-odh"},{"parentId":"viewing-logs-and-audit-records_managing-odh","name":"Configuring the Open Data Hub Operator logger","level":2,"index":0,"id":"configuring-the-operator-logger_managing-odh"},{"parentId":"configuring-the-operator-logger_managing-odh","name":"Viewing the Open Data Hub Operator logs","level":3,"index":0,"id":"_viewing_the_open_data_hub_operator_logs"},{"parentId":"viewing-logs-and-audit-records_managing-odh","name":"Viewing audit records","level":2,"index":1,"id":"viewing-audit-records_managing-odh"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/managing-resources/"},"sections":[{"parentId":null,"name":"Selecting Open Data Hub administrator and user groups","level":1,"index":0,"id":"selecting-admin-and-user-groups_managing-resources"},{"parentId":null,"name":"Customizing the dashboard","level":1,"index":1,"id":"customizing-the-dashboard"},{"parentId":"customizing-the-dashboard","name":"Editing the dashboard configuration","level":2,"index":0,"id":"editing-the-dashboard-configuration_dashboard"},{"parentId":"customizing-the-dashboard","name":"Dashboard configuration options","level":2,"index":1,"id":"ref-dashboard-configuration-options_dashboard"},{"parentId":null,"name":"Importing a custom workbench image","level":1,"index":2,"id":"importing-a-custom-workbench-image_managing-resources"},{"parentId":null,"name":"Managing cluster PVC size","level":1,"index":3,"id":"managing-cluster-pvc-size"},{"parentId":"managing-cluster-pvc-size","name":"Configuring the default PVC size for your cluster","level":2,"index":0,"id":"configuring-the-default-pvc-size-for-your-cluster_managing-resources"},{"parentId":"managing-cluster-pvc-size","name":"Restoring the default PVC size for your cluster","level":2,"index":1,"id":"restoring-the-default-pvc-size-for-your-cluster_managing-resources"},{"parentId":null,"name":"Managing connection types","level":1,"index":4,"id":"managing-connection-types"},{"parentId":"managing-connection-types","name":"Viewing connection types","level":2,"index":0,"id":"viewing-connection-types_managing-resources"},{"parentId":"managing-connection-types","name":"Creating a connection type","level":2,"index":1,"id":"creating-a-connection-type_managing-resources"},{"parentId":"managing-connection-types","name":"Duplicating a connection type","level":2,"index":2,"id":"duplicating-a-connection-type_managing-resources"},{"parentId":"managing-connection-types","name":"Editing a connection type","level":2,"index":3,"id":"editing-a-connection-type_managing-resources"},{"parentId":"managing-connection-types","name":"Enabling a connection type","level":2,"index":4,"id":"enabling-a-connection-type_managing-resources"},{"parentId":"managing-connection-types","name":"Deleting a connection type","level":2,"index":5,"id":"deleting-a-connection-type_managing-resources"},{"parentId":null,"name":"Managing storage classes","level":1,"index":5,"id":"managing-storage-classes"},{"parentId":"managing-storage-classes","name":"About persistent storage","level":2,"index":0,"id":"about-persistent-storage_managing-resources"},{"parentId":"about-persistent-storage_managing-resources","name":"Storage classes in Open Data Hub","level":3,"index":0,"id":"_storage_classes_in_open_data_hub"},{"parentId":"about-persistent-storage_managing-resources","name":"Access modes","level":3,"index":1,"id":"_access_modes"},{"parentId":"_access_modes","name":"Using shared storage (RWX)","level":4,"index":0,"id":"_using_shared_storage_rwx"},{"parentId":"managing-storage-classes","name":"Configuring storage class settings","level":2,"index":1,"id":"configuring-storage-class-settings_managing-resources"},{"parentId":"managing-storage-classes","name":"Configuring the default storage class for your cluster","level":2,"index":2,"id":"configuring-the-default-storage-class-for-your-cluster_managing-resources"},{"parentId":"managing-storage-classes","name":"Overview of object storage endpoints","level":2,"index":3,"id":"overview-of-object-storage-endpoints_managing-resources"},{"parentId":"overview-of-object-storage-endpoints_managing-resources","name":"MinIO (On-Cluster)","level":3,"index":0,"id":"_minio_on_cluster"},{"parentId":"overview-of-object-storage-endpoints_managing-resources","name":"Amazon S3","level":3,"index":1,"id":"_amazon_s3"},{"parentId":"overview-of-object-storage-endpoints_managing-resources","name":"Other S3-Compatible Object Stores","level":3,"index":2,"id":"_other_s3_compatible_object_stores"},{"parentId":"overview-of-object-storage-endpoints_managing-resources","name":"Verification and Troubleshooting","level":3,"index":3,"id":"_verification_and_troubleshooting"},{"parentId":null,"name":"Managing basic workbenches","level":1,"index":6,"id":"managing-basic-workbenches"},{"parentId":"managing-basic-workbenches","name":"Accessing the administration interface for basic workbenches","level":2,"index":0,"id":"accessing-the-administration-interface-for-basic-workbenches_managing-resources"},{"parentId":"managing-basic-workbenches","name":"Starting basic workbenches owned by other users","level":2,"index":1,"id":"starting-basic-workbenches-owned-by-other-users_managing-resources"},{"parentId":"managing-basic-workbenches","name":"Accessing basic workbenches owned by other users","level":2,"index":2,"id":"accessing-basic-workbenches-owned-by-other-users_managing-resources"},{"parentId":"managing-basic-workbenches","name":"Stopping basic workbenches owned by other users","level":2,"index":3,"id":"stopping-basic-workbenches-owned-by-other-users_managing-resources"},{"parentId":"managing-basic-workbenches","name":"Stopping idle workbenches","level":2,"index":4,"id":"stopping-idle-workbenches_managing-resources"},{"parentId":"managing-basic-workbenches","name":"Adding workbench pod tolerations","level":2,"index":5,"id":"adding-workbench-pod-tolerations_managing-resources"},{"parentId":"managing-basic-workbenches","name":"Troubleshooting common problems in workbenches for administrators","level":2,"index":6,"id":"troubleshooting-common-problems-in-workbenches-for-administrators_managing-resources"},{"parentId":"troubleshooting-common-problems-in-workbenches-for-administrators_managing-resources","name":"A user receives a <strong>404: Page not found</strong> error when logging in to Jupyter","level":3,"index":0,"id":"_a_user_receives_a_404_page_not_found_error_when_logging_in_to_jupyter"},{"parentId":"troubleshooting-common-problems-in-workbenches-for-administrators_managing-resources","name":"A user&#8217;s workbench does not start","level":3,"index":1,"id":"_a_users_workbench_does_not_start"},{"parentId":"troubleshooting-common-problems-in-workbenches-for-administrators_managing-resources","name":"The user receives a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when they run notebook cells","level":3,"index":2,"id":"_the_user_receives_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_they_run_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/monitoring-data-science-models/"},"sections":[{"parentId":null,"name":"Overview of model monitoring","level":1,"index":0,"id":"overview-of-model-monitoring_monitor"},{"parentId":null,"name":"Configuring TrustyAI","level":1,"index":1,"id":"configuring-trustyai_monitor"},{"parentId":"configuring-trustyai_monitor","name":"Configuring monitoring for your model serving platform","level":2,"index":0,"id":"configuring-monitoring-for-your-model-serving-platform_monitor"},{"parentId":"configuring-trustyai_monitor","name":"Enabling the TrustyAI component","level":2,"index":1,"id":"enabling-trustyai-component_monitor"},{"parentId":"configuring-trustyai_monitor","name":"Configuring TrustyAI with a database","level":2,"index":2,"id":"configuring-trustyai-with-a-database_monitor"},{"parentId":"configuring-trustyai_monitor","name":"Installing the TrustyAI service for a project","level":2,"index":3,"id":"installing-trustyai-service_monitor"},{"parentId":"installing-trustyai-service_monitor","name":"Installing the TrustyAI service by using the dashboard","level":3,"index":0,"id":"installing-trustyai-service-using-dashboard_monitor"},{"parentId":"installing-trustyai-service_monitor","name":"Installing the TrustyAI service by using the CLI","level":3,"index":1,"id":"installing-trustyai-service-using-cli_monitor"},{"parentId":"configuring-trustyai_monitor","name":"Enabling TrustyAI Integration with KServe RawDeployment","level":2,"index":4,"id":"enabling-trustyai-kserve-integration_monitor"},{"parentId":null,"name":"Setting up TrustyAI for your project","level":1,"index":2,"id":"setting-up-trustyai-for-your-project_monitor"},{"parentId":"setting-up-trustyai-for-your-project_monitor","name":"Authenticating the TrustyAI service","level":2,"index":0,"id":"authenticating-trustyai-service_monitor"},{"parentId":"setting-up-trustyai-for-your-project_monitor","name":"Uploading training data to TrustyAI","level":2,"index":1,"id":"uploading-training-data-to-trustyai_monitor"},{"parentId":"setting-up-trustyai-for-your-project_monitor","name":"Sending training data to TrustyAI","level":2,"index":2,"id":"sending-training-data-to-trustyai_monitor"},{"parentId":"setting-up-trustyai-for-your-project_monitor","name":"Labeling data fields","level":2,"index":3,"id":"labeling-data-fields_monitor"},{"parentId":null,"name":"Monitoring model bias","level":1,"index":3,"id":"monitoring-model-bias_bias-monitoring"},{"parentId":"monitoring-model-bias_bias-monitoring","name":"Creating a bias metric","level":2,"index":0,"id":"creating-a-bias-metric_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the dashboard","level":3,"index":0,"id":"creating-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the CLI","level":3,"index":1,"id":"creating-a-bias-metric-using-cli_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Duplicating a bias metric","level":3,"index":2,"id":"duplicating-a-bias-metric_bias-monitoring"},{"parentId":"monitoring-model-bias_bias-monitoring","name":"Deleting a bias metric","level":2,"index":1,"id":"deleting-a-bias-metric_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the dashboard","level":3,"index":0,"id":"deleting-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the CLI","level":3,"index":1,"id":"deleting-a-bias-metric-using-cli_bias-monitoring"},{"parentId":"monitoring-model-bias_bias-monitoring","name":"Viewing bias metrics for a model","level":2,"index":2,"id":"viewing-bias-metrics_bias-monitoring"},{"parentId":"monitoring-model-bias_bias-monitoring","name":"Using bias metrics","level":2,"index":3,"id":"using-bias-metrics_bias-monitoring"},{"parentId":null,"name":"Monitoring data drift","level":1,"index":4,"id":"monitoring-data-drift_drift-monitoring"},{"parentId":"monitoring-data-drift_drift-monitoring","name":"Creating a drift metric","level":2,"index":0,"id":"creating-a-drift-metric_drift-monitoring"},{"parentId":"creating-a-drift-metric_drift-monitoring","name":"Creating a drift metric by using the CLI","level":3,"index":0,"id":"creating-a-drift-metric-using-cli_drift-monitoring"},{"parentId":"monitoring-data-drift_drift-monitoring","name":"Deleting a drift metric by using the CLI","level":2,"index":1,"id":"deleting-a-drift-metric-by-using-cli_drift-monitoring"},{"parentId":"monitoring-data-drift_drift-monitoring","name":"Viewing drift metrics for a model","level":2,"index":2,"id":"viewing-drift-metrics_drift-monitoring"},{"parentId":"monitoring-data-drift_drift-monitoring","name":"Using drift metrics","level":2,"index":3,"id":"using-drift-metrics_drift-monitoring"},{"parentId":"monitoring-data-drift_drift-monitoring","name":"Using a drift metric in a credit card scenario","level":2,"index":4,"id":"using-a-drift-metric-in-a-credit-card-scenario_drift-monitoring"},{"parentId":null,"name":"Using explainability","level":1,"index":5,"id":"using-explainability_explainers"},{"parentId":"using-explainability_explainers","name":"Requesting a LIME explanation","level":2,"index":0,"id":"requesting-a-lime-explanation_explainers"},{"parentId":"requesting-a-lime-explanation_explainers","name":"Requesting a LIME explanation by using the CLI","level":3,"index":0,"id":"requesting-a-lime-explanation-using-CLI_explainers"},{"parentId":"using-explainability_explainers","name":"Requesting a SHAP explanation","level":2,"index":1,"id":"requesting-a-shap-explanation_explainers"},{"parentId":"requesting-a-shap-explanation_explainers","name":"Requesting a SHAP explanation by using the CLI","level":3,"index":0,"id":"requesting-a-shap-explanation-using-CLI_explainers"},{"parentId":"using-explainability_explainers","name":"Using explainers","level":2,"index":2,"id":"using-explainers_explainers"},{"parentId":null,"name":"Evaluating large language models","level":1,"index":6,"id":"evaluating-large-language-models_monitor"},{"parentId":"evaluating-large-language-models_monitor","name":"Setting up LM-Eval","level":2,"index":0,"id":"setting-up-lmeval_monitor"},{"parentId":"evaluating-large-language-models_monitor","name":"Enabling external resource access for LMEval jobs","level":2,"index":1,"id":"enabling-external-resource-access-for-lmeval-jobs_monitor"},{"parentId":"enabling-external-resource-access-for-lmeval-jobs_monitor","name":"Enabling online access and remote code execution for LMEval Jobs using the CLI","level":3,"index":0,"id":"enabling-online-access-and-remote-code-execution-LMEvalJob-using-the-cli_monitor"},{"parentId":"enabling-external-resource-access-for-lmeval-jobs_monitor","name":"Updating LMEval job configuration using the web console","level":3,"index":1,"id":"updating-lmeval-job-configuration-using-the-web-console_monitor"},{"parentId":"evaluating-large-language-models_monitor","name":"LM-Eval evaluation job","level":2,"index":2,"id":"lmeval-evaluation-job_monitor"},{"parentId":"evaluating-large-language-models_monitor","name":"LM-Eval evaluation job properties","level":2,"index":3,"id":"lmeval-evaluation-job-properties_monitor"},{"parentId":"lmeval-evaluation-job-properties_monitor","name":"Properties for setting up custom Unitxt cards, templates, or system prompts","level":3,"index":0,"id":"_properties_for_setting_up_custom_unitxt_cards_templates_or_system_prompts"},{"parentId":"evaluating-large-language-models_monitor","name":"Performing model evaluations in the dashboard","level":2,"index":4,"id":"performing-model-evaluations-in-the-dashboard_monitor"},{"parentId":"evaluating-large-language-models_monitor","name":"LM-Eval scenarios","level":2,"index":5,"id":"lmeval-scenarios_monitor"},{"parentId":"lmeval-scenarios_monitor","name":"Accessing Hugging Face models with an environment variable token","level":3,"index":0,"id":"accessing-hugging-face-models-with-an-environment-variable-token_monitor"},{"parentId":"lmeval-scenarios_monitor","name":"Using a custom Unitxt card","level":3,"index":1,"id":"using-a-custom-unitxt-card_monitor"},{"parentId":"lmeval-scenarios_monitor","name":"Using PVCs as storage","level":3,"index":2,"id":"using-pvcs-as-storage_monitor"},{"parentId":"using-pvcs-as-storage_monitor","name":"Managed PVCs","level":4,"index":0,"id":"_managed_pvcs"},{"parentId":"using-pvcs-as-storage_monitor","name":"Existing PVCs","level":4,"index":1,"id":"_existing_pvcs"},{"parentId":"lmeval-scenarios_monitor","name":"Using a KServe Inference Service","level":3,"index":3,"id":"using-a-kserve-inference-service_monitor"},{"parentId":"lmeval-scenarios_monitor","name":"Setting up LM-Eval S3 Support","level":3,"index":4,"id":"setting-up-lmeval-s3-support_monitor"},{"parentId":"lmeval-scenarios_monitor","name":"Using LLM-as-a-Judge metrics with LM-Eval","level":3,"index":5,"id":"using-llm-as-a-judge-metrics-with-lmeval_monitor"},{"parentId":null,"name":"Evaluating RAG systems with Ragas","level":1,"index":7,"id":"evaluating-rag-systems-with-ragas_monitor"},{"parentId":"evaluating-rag-systems-with-ragas_monitor","name":"About Ragas evaluation","level":2,"index":0,"id":"_about_ragas_evaluation"},{"parentId":"_about_ragas_evaluation","name":"Key Ragas metrics","level":3,"index":0,"id":"_key_ragas_metrics"},{"parentId":"_about_ragas_evaluation","name":"Use cases for Ragas in AI engineering workflows","level":3,"index":1,"id":"_use_cases_for_ragas_in_ai_engineering_workflows"},{"parentId":"_about_ragas_evaluation","name":"Ragas provider deployment modes","level":3,"index":2,"id":"_ragas_provider_deployment_modes"},{"parentId":"evaluating-rag-systems-with-ragas_monitor","name":"Setting up the Ragas inline provider for development","level":2,"index":1,"id":"setting-up-ragas-inline-provider_monitor"},{"parentId":"evaluating-rag-systems-with-ragas_monitor","name":"Configuring the Ragas remote provider for production","level":2,"index":2,"id":"configuring-ragas-remote-provider-for-production_monitor"},{"parentId":"evaluating-rag-systems-with-ragas_monitor","name":"Evaluating RAG system quality with Ragas metrics","level":2,"index":3,"id":"evaluating-rag-system-quality-with-ragas_monitor"},{"parentId":null,"name":"Using llama stack with TrustyAI","level":1,"index":8,"id":"using-llama-stack-with-trustyai_monitor"},{"parentId":"using-llama-stack-with-trustyai_monitor","name":"Using Llama Stack external evaluation provider with lm-evaluation-harness in TrustyAI","level":2,"index":0,"id":"using-llama-stack-external-evaluation-provider-with-lm-evaluation-harness-in-TrustyAI_monitor"},{"parentId":"using-llama-stack-with-trustyai_monitor","name":"Running custom evaluations with LM-Eval and Llama Stack","level":2,"index":1,"id":"running-custom-evaluations-with-LMEval-and-llama-stack_monitor"},{"parentId":"using-llama-stack-with-trustyai_monitor","name":"Detecting personally identifiable information (PII) by using Guardrails with Llama Stack","level":2,"index":2,"id":"detecting-pii-by-using-guardrails-with-llama-stack_monitor"},{"parentId":null,"name":"Bias monitoring tutorial - Gender bias example","level":1,"index":9,"id":"bias-monitoring-tutorial_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Introduction","level":2,"index":0,"id":"t-bias-introduction_bias-tutorial"},{"parentId":"t-bias-introduction_bias-tutorial","name":"About the example models","level":3,"index":0,"id":"_about_the_example_models"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Setting up your environment","level":2,"index":1,"id":"t-bias-setting-up-your-environment_bias-tutorial"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Downloading the tutorial files","level":3,"index":0,"id":"_downloading_the_tutorial_files"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Logging in to the OpenShift cluster from the command line","level":3,"index":1,"id":"_logging_in_to_the_openshift_cluster_from_the_command_line"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Configuring monitoring for the model serving platform","level":3,"index":2,"id":"_configuring_monitoring_for_the_model_serving_platform"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Enabling the TrustyAI component","level":3,"index":3,"id":"enabling-trustyai-component_bias-tutorial"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Setting up a project","level":3,"index":4,"id":"_setting_up_a_project"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Authenticating the TrustyAI service","level":3,"index":5,"id":"_authenticating_the_trustyai_service"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Deploying models","level":2,"index":2,"id":"t-bias-deploying-models_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Sending training data to the models","level":2,"index":3,"id":"t-bias-sending-training-data-to-the-models_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Labeling data fields","level":2,"index":4,"id":"t-bias-labeling-data-fields_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Checking model fairness","level":2,"index":5,"id":"t-bias-checking-model-fairness_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Scheduling a fairness metric request","level":2,"index":6,"id":"t-bias-scheduling-a-fairness-metric-request_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Scheduling an identity metric request","level":2,"index":7,"id":"t-bias-scheduling-an-identity-metric-request_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Simulating real world data","level":2,"index":8,"id":"t-bias-simulating-real-world-data_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Reviewing the results","level":2,"index":9,"id":"t-bias-reviewing-the-results_bias-tutorial"},{"parentId":"t-bias-reviewing-the-results_bias-tutorial","name":"Are the models biased?","level":3,"index":0,"id":"_are_the_models_biased"},{"parentId":"t-bias-reviewing-the-results_bias-tutorial","name":"How does the production data compare to the training data?","level":3,"index":1,"id":"_how_does_the_production_data_compare_to_the_training_data"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/monitoring-your-ai-systems/"},"sections":[{"parentId":null,"name":"Overview of monitoring your AI systems","level":1,"index":0,"id":"overview-of-monitoring-your-ai-systems_monitor"},{"parentId":null,"name":"Configuring TrustyAI","level":1,"index":1,"id":"configuring-trustyai_monitor"},{"parentId":"configuring-trustyai_monitor","name":"Configuring monitoring for your model serving platform","level":2,"index":0,"id":"configuring-monitoring-for-your-model-serving-platform_monitor"},{"parentId":"configuring-trustyai_monitor","name":"Enabling the TrustyAI component","level":2,"index":1,"id":"enabling-trustyai-component_monitor"},{"parentId":"configuring-trustyai_monitor","name":"Configuring TrustyAI with a database","level":2,"index":2,"id":"configuring-trustyai-with-a-database_monitor"},{"parentId":"configuring-trustyai_monitor","name":"Installing the TrustyAI service for a project","level":2,"index":3,"id":"installing-trustyai-service_monitor"},{"parentId":"installing-trustyai-service_monitor","name":"Installing the TrustyAI service by using the dashboard","level":3,"index":0,"id":"installing-trustyai-service-using-dashboard_monitor"},{"parentId":"installing-trustyai-service_monitor","name":"Installing the TrustyAI service by using the CLI","level":3,"index":1,"id":"installing-trustyai-service-using-cli_monitor"},{"parentId":"configuring-trustyai_monitor","name":"Enabling TrustyAI Integration with KServe RawDeployment","level":2,"index":4,"id":"enabling-trustyai-kserve-integration_monitor"},{"parentId":null,"name":"Setting up TrustyAI for your project","level":1,"index":2,"id":"setting-up-trustyai-for-your-project_monitor"},{"parentId":"setting-up-trustyai-for-your-project_monitor","name":"Authenticating the TrustyAI service","level":2,"index":0,"id":"authenticating-trustyai-service_monitor"},{"parentId":"setting-up-trustyai-for-your-project_monitor","name":"Uploading training data to TrustyAI","level":2,"index":1,"id":"uploading-training-data-to-trustyai_monitor"},{"parentId":"setting-up-trustyai-for-your-project_monitor","name":"Sending training data to TrustyAI","level":2,"index":2,"id":"sending-training-data-to-trustyai_monitor"},{"parentId":"setting-up-trustyai-for-your-project_monitor","name":"Labeling data fields","level":2,"index":3,"id":"labeling-data-fields_monitor"},{"parentId":null,"name":"Monitoring model bias","level":1,"index":3,"id":"monitoring-model-bias_bias-monitoring"},{"parentId":"monitoring-model-bias_bias-monitoring","name":"Creating a bias metric","level":2,"index":0,"id":"creating-a-bias-metric_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the dashboard","level":3,"index":0,"id":"creating-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the CLI","level":3,"index":1,"id":"creating-a-bias-metric-using-cli_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Duplicating a bias metric","level":3,"index":2,"id":"duplicating-a-bias-metric_bias-monitoring"},{"parentId":"monitoring-model-bias_bias-monitoring","name":"Deleting a bias metric","level":2,"index":1,"id":"deleting-a-bias-metric_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the dashboard","level":3,"index":0,"id":"deleting-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the CLI","level":3,"index":1,"id":"deleting-a-bias-metric-using-cli_bias-monitoring"},{"parentId":"monitoring-model-bias_bias-monitoring","name":"Viewing bias metrics for a model","level":2,"index":2,"id":"viewing-bias-metrics_bias-monitoring"},{"parentId":"monitoring-model-bias_bias-monitoring","name":"Using bias metrics","level":2,"index":3,"id":"using-bias-metrics_bias-monitoring"},{"parentId":null,"name":"Bias monitoring tutorial - Gender bias example","level":1,"index":4,"id":"bias-monitoring-tutorial_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Introduction","level":2,"index":0,"id":"t-bias-introduction_bias-tutorial"},{"parentId":"t-bias-introduction_bias-tutorial","name":"About the example models","level":3,"index":0,"id":"_about_the_example_models"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Setting up your environment","level":2,"index":1,"id":"t-bias-setting-up-your-environment_bias-tutorial"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Downloading the tutorial files","level":3,"index":0,"id":"_downloading_the_tutorial_files"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Logging in to the OpenShift cluster from the command line","level":3,"index":1,"id":"_logging_in_to_the_openshift_cluster_from_the_command_line"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Configuring monitoring for the model serving platform","level":3,"index":2,"id":"_configuring_monitoring_for_the_model_serving_platform"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Enabling the TrustyAI component","level":3,"index":3,"id":"enabling-trustyai-component_bias-tutorial"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Setting up a project","level":3,"index":4,"id":"_setting_up_a_project"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Authenticating the TrustyAI service","level":3,"index":5,"id":"_authenticating_the_trustyai_service"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Deploying models","level":2,"index":2,"id":"t-bias-deploying-models_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Sending training data to the models","level":2,"index":3,"id":"t-bias-sending-training-data-to-the-models_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Labeling data fields","level":2,"index":4,"id":"t-bias-labeling-data-fields_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Checking model fairness","level":2,"index":5,"id":"t-bias-checking-model-fairness_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Scheduling a fairness metric request","level":2,"index":6,"id":"t-bias-scheduling-a-fairness-metric-request_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Scheduling an identity metric request","level":2,"index":7,"id":"t-bias-scheduling-an-identity-metric-request_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Simulating real world data","level":2,"index":8,"id":"t-bias-simulating-real-world-data_bias-tutorial"},{"parentId":"bias-monitoring-tutorial_bias-tutorial","name":"Reviewing the results","level":2,"index":9,"id":"t-bias-reviewing-the-results_bias-tutorial"},{"parentId":"t-bias-reviewing-the-results_bias-tutorial","name":"Are the models biased?","level":3,"index":0,"id":"_are_the_models_biased"},{"parentId":"t-bias-reviewing-the-results_bias-tutorial","name":"How does the production data compare to the training data?","level":3,"index":1,"id":"_how_does_the_production_data_compare_to_the_training_data"},{"parentId":null,"name":"Monitoring data drift","level":1,"index":5,"id":"monitoring-data-drift_drift-monitoring"},{"parentId":"monitoring-data-drift_drift-monitoring","name":"Creating a drift metric","level":2,"index":0,"id":"creating-a-drift-metric_drift-monitoring"},{"parentId":"creating-a-drift-metric_drift-monitoring","name":"Creating a drift metric by using the CLI","level":3,"index":0,"id":"creating-a-drift-metric-using-cli_drift-monitoring"},{"parentId":"monitoring-data-drift_drift-monitoring","name":"Deleting a drift metric by using the CLI","level":2,"index":1,"id":"deleting-a-drift-metric-by-using-cli_drift-monitoring"},{"parentId":"monitoring-data-drift_drift-monitoring","name":"Viewing drift metrics for a model","level":2,"index":2,"id":"viewing-drift-metrics_drift-monitoring"},{"parentId":"monitoring-data-drift_drift-monitoring","name":"Using drift metrics","level":2,"index":3,"id":"using-drift-metrics_drift-monitoring"},{"parentId":"monitoring-data-drift_drift-monitoring","name":"Using a drift metric in a credit card scenario","level":2,"index":4,"id":"using-a-drift-metric-in-a-credit-card-scenario_drift-monitoring"},{"parentId":null,"name":"Using explainability","level":1,"index":6,"id":"using-explainability_explainers"},{"parentId":"using-explainability_explainers","name":"Requesting a LIME explanation","level":2,"index":0,"id":"requesting-a-lime-explanation_explainers"},{"parentId":"requesting-a-lime-explanation_explainers","name":"Requesting a LIME explanation by using the CLI","level":3,"index":0,"id":"requesting-a-lime-explanation-using-CLI_explainers"},{"parentId":"using-explainability_explainers","name":"Requesting a SHAP explanation","level":2,"index":1,"id":"requesting-a-shap-explanation_explainers"},{"parentId":"requesting-a-shap-explanation_explainers","name":"Requesting a SHAP explanation by using the CLI","level":3,"index":0,"id":"requesting-a-shap-explanation-using-CLI_explainers"},{"parentId":"using-explainability_explainers","name":"Using explainers","level":2,"index":2,"id":"using-explainers_explainers"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/upgrading-open-data-hub/"},"sections":[{"parentId":null,"name":"Overview of upgrading Open Data Hub","level":1,"index":0,"id":"overview-of-upgrading-odh_upgrade"},{"parentId":null,"name":"Upgrading Open Data Hub version 2.0 to version 2.2 or later","level":1,"index":1,"id":"upgrading-odh-v2_upgradev2"},{"parentId":"upgrading-odh-v2_upgradev2","name":"Requirements for upgrading Open Data Hub version 2","level":2,"index":0,"id":"requirements-for-upgrading-odh-v2_upgradev2"},{"parentId":"upgrading-odh-v2_upgradev2","name":"Upgrading the Open Data Hub Operator","level":2,"index":1,"id":"upgrading-the-odh-operator_upgradev2"},{"parentId":null,"name":"Upgrading Open Data Hub version 1 to version 2","level":1,"index":2,"id":"upgrading-odh-v1-to-v2_upgradev1"},{"parentId":"upgrading-odh-v1-to-v2_upgradev1","name":"Requirements for upgrading Open Data Hub version 1","level":2,"index":0,"id":"requirements-for-upgrading-odh-v1_upgradev1"},{"parentId":"upgrading-odh-v1-to-v2_upgradev1","name":"Upgrading the Open Data Hub Operator","level":2,"index":1,"id":"upgrading-the-odh-operator_upgradev1"},{"parentId":null,"name":"Installing Open Data Hub components","level":1,"index":3,"id":"installing-odh-components_upgrade"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-in-your-data-science-ide/"},"sections":[{"parentId":null,"name":"Accessing your workbench IDE","level":1,"index":0,"id":"accessing-your-workbench-ide_ide"},{"parentId":null,"name":"Working in JupyterLab","level":1,"index":1,"id":"_working_in_jupyterlab"},{"parentId":"_working_in_jupyterlab","name":"Creating and importing Jupyter notebooks","level":2,"index":0,"id":"creating-and-importing-jupyter-notebooks_ide"},{"parentId":"creating-and-importing-jupyter-notebooks_ide","name":"Creating a Jupyter notebook","level":3,"index":0,"id":"creating-a-jupyter-notebook_ide"},{"parentId":"creating-and-importing-jupyter-notebooks_ide","name":"Uploading an existing notebook file to JupyterLab from local storage","level":3,"index":1,"id":"uploading-an-existing-notebook-file-to-jupyterlab-from-local-storage_ide"},{"parentId":"creating-and-importing-jupyter-notebooks_ide","name":"Deleting files into the trash directory of your workbench in Jupyter notebooks","level":3,"index":2,"id":"deleting-files-in-trash-directory_ide"},{"parentId":"deleting-files-in-trash-directory_ide","name":"Emptying the trash directory of your workbench in Jupyter notebooks","level":4,"index":0,"id":"emptying-trash-directory_ide"},{"parentId":"creating-and-importing-jupyter-notebooks_ide","name":"Additional resources","level":3,"index":3,"id":"_additional_resources"},{"parentId":"_working_in_jupyterlab","name":"Collaborating on Jupyter notebooks by using Git","level":2,"index":1,"id":"collaborating-on-jupyter-notebooks-by-using-git_ide"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_ide","name":"Uploading an existing notebook file from a Git repository by using JupyterLab","level":3,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_ide"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_ide","name":"Uploading an existing notebook file to JupyterLab from a Git repository by using the CLI","level":3,"index":1,"id":"uploading-an-existing-notebook-file-to-jupyterlab-from-a-git-repository-using-cli_ide"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_ide","name":"Updating your project with changes from a remote Git repository","level":3,"index":2,"id":"updating-your-project-with-changes-from-a-remote-git-repository_ide"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_ide","name":"Pushing project changes to a Git repository","level":3,"index":3,"id":"pushing-project-changes-to-a-git-repository_ide"},{"parentId":"_working_in_jupyterlab","name":"Managing Python packages","level":2,"index":2,"id":"managing-python-packages_ide"},{"parentId":"managing-python-packages_ide","name":"Viewing Python packages installed on your workbench","level":3,"index":0,"id":"viewing-python-packages-installed-on-your-workbench_ide"},{"parentId":"managing-python-packages_ide","name":"Installing Python packages on your workbench","level":3,"index":1,"id":"installing-python-packages-on-your-workbench_ide"},{"parentId":"_working_in_jupyterlab","name":"Troubleshooting common problems in workbenches for users","level":2,"index":3,"id":"troubleshooting-common-problems-in-workbenches-for-users_ide"},{"parentId":null,"name":"Working in code-server","level":1,"index":2,"id":"_working_in_code_server"},{"parentId":"_working_in_code_server","name":"Creating code-server workbenches","level":2,"index":0,"id":"creating-code-server-workbenches_ide"},{"parentId":"creating-code-server-workbenches_ide","name":"Creating a workbench","level":3,"index":0,"id":"creating-a-project-workbench_ide"},{"parentId":"creating-code-server-workbenches_ide","name":"Uploading an existing notebook file to code-server from local storage","level":3,"index":1,"id":"uploading-an-existing-notebook-file-to-code-server-from-local-storage_ide"},{"parentId":"_working_in_code_server","name":"Collaborating on workbenches in code-server by using Git","level":2,"index":1,"id":"collaborating-on-workbenches-in-code-server-by-using-git_ide"},{"parentId":"collaborating-on-workbenches-in-code-server-by-using-git_ide","name":"Uploading an existing notebook file from a Git repository by using code-server","level":3,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-code-server_ide"},{"parentId":"collaborating-on-workbenches-in-code-server-by-using-git_ide","name":"Uploading an existing notebook file to code-server from a Git repository by using the CLI","level":3,"index":1,"id":"uploading-an-existing-notebook-file-to-code-server-from-a-git-repository-using-cli_ide"},{"parentId":"collaborating-on-workbenches-in-code-server-by-using-git_ide","name":"Updating your project in code-server with changes from a remote Git repository","level":3,"index":2,"id":"updating-your-project-in-code-server-with-changes-from-a-remote-git-repository_ide"},{"parentId":"collaborating-on-workbenches-in-code-server-by-using-git_ide","name":"Pushing project changes in code-server to a Git repository","level":3,"index":3,"id":"pushing-project-changes-in-code-server-to-a-git-repository_ide"},{"parentId":"_working_in_code_server","name":"Managing Python packages in code-server","level":2,"index":2,"id":"managing-python-packages-in-code-server_ide"},{"parentId":"managing-python-packages-in-code-server_ide","name":"Viewing Python packages installed on your code-server workbench","level":3,"index":0,"id":"viewing-python-packages-installed-on-your-code-server-workbench_ide"},{"parentId":"managing-python-packages-in-code-server_ide","name":"Installing Python packages on your code-server workbench","level":3,"index":1,"id":"installing-python-packages-on-your-code-server-workbench_ide"},{"parentId":"_working_in_code_server","name":"Installing extensions with code-server","level":2,"index":3,"id":"installing-extensions-with-code-server_ide"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-on-projects/"},"sections":[{"parentId":null,"name":"Using projects","level":1,"index":0,"id":"using-projects_projects"},{"parentId":"using-projects_projects","name":"Creating a project","level":2,"index":0,"id":"creating-a-project_projects"},{"parentId":"using-projects_projects","name":"Updating a project","level":2,"index":1,"id":"updating-a-project_projects"},{"parentId":"using-projects_projects","name":"Deleting a project","level":2,"index":2,"id":"deleting-a-project_projects"},{"parentId":null,"name":"Using project workbenches","level":1,"index":1,"id":"using-project-workbenches_projects"},{"parentId":"using-project-workbenches_projects","name":"Creating a workbench and selecting an IDE","level":2,"index":0,"id":"creating-a-workbench-select-ide_projects"},{"parentId":"creating-a-workbench-select-ide_projects","name":"About workbench images","level":3,"index":0,"id":"about-workbench-images_projects"},{"parentId":"creating-a-workbench-select-ide_projects","name":"Creating a workbench","level":3,"index":1,"id":"creating-a-project-workbench_projects"},{"parentId":"using-project-workbenches_projects","name":"Starting a workbench","level":2,"index":1,"id":"starting-a-workbench_projects"},{"parentId":"using-project-workbenches_projects","name":"Updating a project workbench","level":2,"index":2,"id":"updating-a-project-workbench_projects"},{"parentId":"using-project-workbenches_projects","name":"Deleting a workbench from a project","level":2,"index":3,"id":"deleting-a-workbench-from-a-project_projects"},{"parentId":null,"name":"Using connections","level":1,"index":2,"id":"using-connections_projects"},{"parentId":"using-connections_projects","name":"Adding a connection to your project","level":2,"index":0,"id":"adding-a-connection-to-your-project_projects"},{"parentId":"using-connections_projects","name":"Updating a connection","level":2,"index":1,"id":"updating-a-connection_projects"},{"parentId":"using-connections_projects","name":"Deleting a connection","level":2,"index":2,"id":"deleting-a-connection_projects"},{"parentId":"using-connections_projects","name":"Using the connections API","level":2,"index":3,"id":"using-connections-api_projects"},{"parentId":"using-connections-api_projects","name":"Namespace isolation in connections API","level":3,"index":0,"id":"_namespace_isolation_in_connections_api"},{"parentId":"using-connections-api_projects","name":"Role-based access control (RBAC) requirements in connections API","level":3,"index":1,"id":"_role_based_access_control_rbac_requirements_in_connections_api"},{"parentId":"using-connections-api_projects","name":"Validation scope","level":3,"index":2,"id":"_validation_scope"},{"parentId":"using-connections-api_projects","name":"Using connection annotations based on workload type","level":3,"index":3,"id":"_using_connection_annotations_based_on_workload_type"},{"parentId":"using-connections-api_projects","name":"Creating an Amazon S3-compatible connection type using the connections API","level":3,"index":4,"id":"creating-s3-compatible-connection-type-api_projects"},{"parentId":"creating-s3-compatible-connection-type-api_projects","name":"Using an Amazon S3 connection with <code>InferenceService</code> custom resource","level":4,"index":0,"id":"_using_an_amazon_s3_connection_with_inferenceservice_custom_resource"},{"parentId":"creating-s3-compatible-connection-type-api_projects","name":"Using an Amazon S3 connection with <code>LLMInferenceService</code> custom resource","level":4,"index":1,"id":"_using_an_amazon_s3_connection_with_llminferenceservice_custom_resource"},{"parentId":"using-connections-api_projects","name":"Creating a URI-compatible connection type using the connections API","level":3,"index":5,"id":"creating-uri-compatible-connection-type-api_projects"},{"parentId":"creating-uri-compatible-connection-type-api_projects","name":"Using a URI connection with <code>InferenceService</code> custom resource","level":4,"index":0,"id":"_using_a_uri_connection_with_inferenceservice_custom_resource"},{"parentId":"creating-uri-compatible-connection-type-api_projects","name":"Using a URI connection with <code>LLMInferenceService</code> custom resource","level":4,"index":1,"id":"_using_a_uri_connection_with_llminferenceservice_custom_resource"},{"parentId":"using-connections-api_projects","name":"Creating an OCI-compatible connection type using the connections API","level":3,"index":6,"id":"creating-oci-compatible-connection-type-api_projects"},{"parentId":"creating-oci-compatible-connection-type-api_projects","name":"Using an OCI connection with <code>InferenceService</code> custom resource","level":4,"index":0,"id":"_using_an_oci_connection_with_inferenceservice_custom_resource"},{"parentId":"creating-oci-compatible-connection-type-api_projects","name":"Using an OCI connection with <code>LLMInferenceService</code> custom resource","level":4,"index":1,"id":"_using_an_oci_connection_with_llminferenceservice_custom_resource"},{"parentId":null,"name":"Configuring cluster storage","level":1,"index":3,"id":"configuring-cluster-storage_projects"},{"parentId":"configuring-cluster-storage_projects","name":"About persistent storage","level":2,"index":0,"id":"about-persistent-storage_projects"},{"parentId":"about-persistent-storage_projects","name":"Storage classes in Open Data Hub","level":3,"index":0,"id":"_storage_classes_in_open_data_hub"},{"parentId":"about-persistent-storage_projects","name":"Access modes","level":3,"index":1,"id":"_access_modes"},{"parentId":"_access_modes","name":"Using shared storage (RWX)","level":4,"index":0,"id":"_using_shared_storage_rwx"},{"parentId":"configuring-cluster-storage_projects","name":"Adding cluster storage to your project","level":2,"index":1,"id":"adding-cluster-storage-to-your-project_projects"},{"parentId":"configuring-cluster-storage_projects","name":"Updating cluster storage","level":2,"index":2,"id":"updating-cluster-storage_projects"},{"parentId":"configuring-cluster-storage_projects","name":"Changing the storage class for an existing cluster storage instance","level":2,"index":3,"id":"changing-the-storage-class-for-an-existing-cluster-storage-instance_projects"},{"parentId":"configuring-cluster-storage_projects","name":"Deleting cluster storage from a project","level":2,"index":4,"id":"deleting-cluster-storage-from-a-project_projects"},{"parentId":null,"name":"Managing access to projects","level":1,"index":4,"id":"managing-access-to-projects_projects"},{"parentId":"managing-access-to-projects_projects","name":"Granting access to a project","level":2,"index":0,"id":"granting-access-to-a-project_projects"},{"parentId":"managing-access-to-projects_projects","name":"Updating access to a project","level":2,"index":1,"id":"updating-access-to-a-project_projects"},{"parentId":"managing-access-to-projects_projects","name":"Removing access to a project","level":2,"index":2,"id":"removing-access-to-a-project_projects"},{"parentId":null,"name":"Creating project-scoped resources for your project","level":1,"index":5,"id":"creating-project-scoped-resources-for-your-project_projects"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-accelerators/"},"sections":[{"parentId":null,"name":"Overview of accelerators","level":1,"index":0,"id":"overview-of-accelerators_accelerators"},{"parentId":null,"name":"Enabling accelerators","level":1,"index":1,"id":"enabling-accelerators_accelerators"},{"parentId":null,"name":"Enabling NVIDIA GPUs","level":1,"index":2,"id":"enabling-nvidia-gpus_accelerators"},{"parentId":null,"name":"Intel Gaudi AI Accelerator integration","level":1,"index":3,"id":"intel-gaudi-ai-accelerator-integration_accelerators"},{"parentId":null,"name":"AMD GPU Integration","level":1,"index":4,"id":"amd-gpu-integration_accelerators"},{"parentId":"amd-gpu-integration_accelerators","name":"Verifying AMD GPU availability on your cluster","level":2,"index":0,"id":"verifying-amd-gpu-availability-on-your-cluster_accelerators"},{"parentId":"amd-gpu-integration_accelerators","name":"Enabling AMD GPUs","level":2,"index":1,"id":"enabling-amd-gpus_accelerators"},{"parentId":null,"name":"IBM Spyre integration","level":1,"index":5,"id":"ibm-spyre-integration_accelerators"},{"parentId":null,"name":"Working with hardware profiles","level":1,"index":6,"id":"working-with-hardware-profiles_accelerators"},{"parentId":"working-with-hardware-profiles_accelerators","name":"Creating a hardware profile","level":2,"index":0,"id":"creating-a-hardware-profile_accelerators"},{"parentId":"working-with-hardware-profiles_accelerators","name":"Updating a hardware profile","level":2,"index":1,"id":"updating-a-hardware-profile_accelerators"},{"parentId":"working-with-hardware-profiles_accelerators","name":"Deleting a hardware profile","level":2,"index":2,"id":"deleting-a-hardware-profile_accelerators"},{"parentId":"working-with-hardware-profiles_accelerators","name":"Configuring a recommended accelerator for workbench images","level":2,"index":3,"id":"configuring-a-recommended-accelerator-for-workbench-images_accelerators"},{"parentId":"working-with-hardware-profiles_accelerators","name":"Configuring a recommended accelerator for serving runtimes","level":2,"index":4,"id":"configuring-a-recommended-accelerator-for-serving-runtimes_accelerators"},{"parentId":null,"name":"About GPU time slicing","level":1,"index":7,"id":"about-gpu-time-slicing_accelerators"},{"parentId":null,"name":"Enabling GPU time slicing","level":1,"index":8,"id":"enabling-gpu-time-slicing_accelerators"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-ai-pipelines/"},"sections":[{"parentId":null,"name":"Managing AI pipelines","level":1,"index":0,"id":"managing-ai-pipelines_ai-pipelines"},{"parentId":"managing-ai-pipelines_ai-pipelines","name":"Configuring a pipeline server","level":2,"index":0,"id":"configuring-a-pipeline-server_ai-pipelines"},{"parentId":"configuring-a-pipeline-server_ai-pipelines","name":"Configuring a pipeline server with an external Amazon RDS database","level":3,"index":0,"id":"configuring-a-pipeline-server-with-an-external-amazon-rds-db_ai-pipelines"},{"parentId":"managing-ai-pipelines_ai-pipelines","name":"Defining a pipeline","level":2,"index":1,"id":"defining-a-pipeline_ai-pipelines"},{"parentId":"defining-a-pipeline_ai-pipelines","name":"Compiling the pipeline YAML with the Kubeflow Pipelines SDK","level":3,"index":0,"id":"compiling-the-pipeline-yaml-with-kfp-sdk_ai-pipelines"},{"parentId":"defining-a-pipeline_ai-pipelines","name":"Compiling Kubernetes-native manifests with the Kubeflow Pipelines SDK","level":3,"index":1,"id":"compiling-kubernetes-native-manifests-with-kfp-sdk_ai-pipelines"},{"parentId":"defining-a-pipeline_ai-pipelines","name":"Authenticating the Kubeflow Pipelines SDK with a pipeline server","level":3,"index":2,"id":"authenticating-kfp-sdk-with-pipeline-server_ai-pipelines"},{"parentId":"defining-a-pipeline_ai-pipelines","name":"Defining a pipeline by using the Kubernetes API","level":3,"index":3,"id":"defining-a-pipeline-by-using-the-kubernetes-api_ai-pipelines"},{"parentId":"defining-a-pipeline_ai-pipelines","name":"Migrating pipelines from database to Kubernetes API storage","level":3,"index":4,"id":"migrating-pipelines-from-database-to-kubernetes-api_ai-pipelines"},{"parentId":"managing-ai-pipelines_ai-pipelines","name":"Importing a pipeline","level":2,"index":2,"id":"importing-a-pipeline_ai-pipelines"},{"parentId":"managing-ai-pipelines_ai-pipelines","name":"Deleting a pipeline","level":2,"index":3,"id":"deleting-a-pipeline_ai-pipelines"},{"parentId":"managing-ai-pipelines_ai-pipelines","name":"Deleting a pipeline server","level":2,"index":4,"id":"deleting-a-pipeline-server_ai-pipelines"},{"parentId":"managing-ai-pipelines_ai-pipelines","name":"Viewing the details of a pipeline server","level":2,"index":5,"id":"viewing-the-details-of-a-pipeline-server_ai-pipelines"},{"parentId":"managing-ai-pipelines_ai-pipelines","name":"Viewing existing pipelines","level":2,"index":6,"id":"viewing-existing-pipelines_ai-pipelines"},{"parentId":"managing-ai-pipelines_ai-pipelines","name":"Overview of pipeline versions","level":2,"index":7,"id":"overview-of-pipeline-versions_ai-pipelines"},{"parentId":"managing-ai-pipelines_ai-pipelines","name":"Uploading a pipeline version","level":2,"index":8,"id":"uploading-a-pipeline-version_ai-pipelines"},{"parentId":"managing-ai-pipelines_ai-pipelines","name":"Deleting a pipeline version","level":2,"index":9,"id":"deleting-a-pipeline-version_ai-pipelines"},{"parentId":"managing-ai-pipelines_ai-pipelines","name":"Viewing the details of a pipeline version","level":2,"index":10,"id":"viewing-the-details-of-a-pipeline-version_ai-pipelines"},{"parentId":"managing-ai-pipelines_ai-pipelines","name":"Downloading a pipeline version","level":2,"index":11,"id":"downloading-a-pipeline-version_ai-pipelines"},{"parentId":"managing-ai-pipelines_ai-pipelines","name":"Overview of pipelines caching","level":2,"index":12,"id":"overview-of-pipelines-caching_ai-pipelines"},{"parentId":"overview-of-pipelines-caching_ai-pipelines","name":"Caching criteria","level":3,"index":0,"id":"_caching_criteria"},{"parentId":"overview-of-pipelines-caching_ai-pipelines","name":"Viewing cached steps in the Open Data Hub user interface","level":3,"index":1,"id":"_viewing_cached_steps_in_the_open_data_hub_user_interface"},{"parentId":"overview-of-pipelines-caching_ai-pipelines","name":"Controlling caching in pipelines","level":3,"index":2,"id":"controlling-caching-in-pipelines_ai-pipelines"},{"parentId":"controlling-caching-in-pipelines_ai-pipelines","name":"Disabling caching for individual tasks","level":4,"index":0,"id":"_disabling_caching_for_individual_tasks"},{"parentId":"controlling-caching-in-pipelines_ai-pipelines","name":"Disabling caching for a pipeline at submit time","level":4,"index":1,"id":"_disabling_caching_for_a_pipeline_at_submit_time"},{"parentId":"controlling-caching-in-pipelines_ai-pipelines","name":"Disabling caching for a pipeline at compile time","level":4,"index":2,"id":"_disabling_caching_for_a_pipeline_at_compile_time"},{"parentId":"controlling-caching-in-pipelines_ai-pipelines","name":"Disabling caching for all pipelines (pipeline server)","level":4,"index":3,"id":"_disabling_caching_for_all_pipelines_pipeline_server"},{"parentId":null,"name":"Managing pipeline experiments","level":1,"index":1,"id":"managing-pipeline-experiments_ai-pipelines"},{"parentId":"managing-pipeline-experiments_ai-pipelines","name":"Overview of pipeline experiments","level":2,"index":0,"id":"overview-of-pipeline-experiments_ai-pipelines"},{"parentId":"managing-pipeline-experiments_ai-pipelines","name":"Creating a pipeline experiment","level":2,"index":1,"id":"creating-a-pipeline-experiment_ai-pipelines"},{"parentId":"managing-pipeline-experiments_ai-pipelines","name":"Archiving a pipeline experiment","level":2,"index":2,"id":"archiving-a-pipeline-experiment_ai-pipelines"},{"parentId":"managing-pipeline-experiments_ai-pipelines","name":"Deleting an archived pipeline experiment","level":2,"index":3,"id":"deleting-an-archived-pipeline-experiment_ai-pipelines"},{"parentId":"managing-pipeline-experiments_ai-pipelines","name":"Restoring an archived pipeline experiment","level":2,"index":4,"id":"restoring-an-archived-pipeline-experiment_ai-pipelines"},{"parentId":"managing-pipeline-experiments_ai-pipelines","name":"Viewing pipeline task executions","level":2,"index":5,"id":"viewing-pipeline-task-executions_ai-pipelines"},{"parentId":"managing-pipeline-experiments_ai-pipelines","name":"Viewing pipeline artifacts","level":2,"index":6,"id":"viewing-pipeline-artifacts_ai-pipelines"},{"parentId":"managing-pipeline-experiments_ai-pipelines","name":"Comparing runs in an experiment","level":2,"index":7,"id":"comparing-runs-in-an-experiment_ai-pipelines"},{"parentId":"managing-pipeline-experiments_ai-pipelines","name":"Comparing runs in different experiments","level":2,"index":8,"id":"comparing-runs-in-different-experiments_ai-pipelines"},{"parentId":null,"name":"Managing pipeline runs","level":1,"index":2,"id":"managing-pipeline-runs_ai-pipelines"},{"parentId":"managing-pipeline-runs_ai-pipelines","name":"Overview of pipeline runs","level":2,"index":0,"id":"overview-of-pipeline-runs_ai-pipelines"},{"parentId":"managing-pipeline-runs_ai-pipelines","name":"Storing data with pipelines","level":2,"index":1,"id":"storing-data-with-pipelines_ai-pipelines"},{"parentId":"managing-pipeline-runs_ai-pipelines","name":"Understanding pipeline run workspaces","level":2,"index":2,"id":"configuring-pipeline-run-workspaces_ai-pipelines"},{"parentId":"configuring-pipeline-run-workspaces_ai-pipelines","name":"Configuring default workspace PVC settings in DSPA","level":3,"index":0,"id":"configuring-default-workspace-pvc-settings-in-dspa_ai-pipelines"},{"parentId":"configuring-pipeline-run-workspaces_ai-pipelines","name":"Adding external artifacts to pipeline run workspaces","level":3,"index":1,"id":"adding-external-artifacts-to-pipeline-run-workspaces_ai-pipelines"},{"parentId":"managing-pipeline-runs_ai-pipelines","name":"Viewing active pipeline runs","level":2,"index":3,"id":"viewing-active-pipeline-runs_ai-pipelines"},{"parentId":"managing-pipeline-runs_ai-pipelines","name":"Executing a pipeline run","level":2,"index":4,"id":"executing-a-pipeline-run_ai-pipelines"},{"parentId":"managing-pipeline-runs_ai-pipelines","name":"Stopping an active pipeline run","level":2,"index":5,"id":"stopping-an-active-pipeline-run_ai-pipelines"},{"parentId":"managing-pipeline-runs_ai-pipelines","name":"Duplicating an active pipeline run","level":2,"index":6,"id":"duplicating-an-active-pipeline-run_ai-pipelines"},{"parentId":"managing-pipeline-runs_ai-pipelines","name":"Viewing scheduled pipeline runs","level":2,"index":7,"id":"viewing-scheduled-pipeline-runs_ai-pipelines"},{"parentId":"managing-pipeline-runs_ai-pipelines","name":"Scheduling a pipeline run using a cron job","level":2,"index":8,"id":"scheduling-a-pipeline-run-using-a-cron-job_ai-pipelines"},{"parentId":"managing-pipeline-runs_ai-pipelines","name":"Scheduling a pipeline run","level":2,"index":9,"id":"scheduling-a-pipeline-run_ai-pipelines"},{"parentId":"managing-pipeline-runs_ai-pipelines","name":"Duplicating a scheduled pipeline run","level":2,"index":10,"id":"duplicating-a-scheduled-pipeline-run_ai-pipelines"},{"parentId":"managing-pipeline-runs_ai-pipelines","name":"Deleting a scheduled pipeline run","level":2,"index":11,"id":"deleting-a-scheduled-pipeline-run_ai-pipelines"},{"parentId":"managing-pipeline-runs_ai-pipelines","name":"Viewing the details of a pipeline run","level":2,"index":12,"id":"viewing-the-details-of-a-pipeline-run_ai-pipelines"},{"parentId":"managing-pipeline-runs_ai-pipelines","name":"Viewing archived pipeline runs","level":2,"index":13,"id":"viewing-archived-pipeline-runs_ai-pipelines"},{"parentId":"managing-pipeline-runs_ai-pipelines","name":"Archiving a pipeline run","level":2,"index":14,"id":"archiving-a-pipeline-run_ai-pipelines"},{"parentId":"managing-pipeline-runs_ai-pipelines","name":"Restoring an archived pipeline run","level":2,"index":15,"id":"restoring-an-archived-pipeline-run_ai-pipelines"},{"parentId":"managing-pipeline-runs_ai-pipelines","name":"Deleting an archived pipeline run","level":2,"index":16,"id":"deleting-an-archived-pipeline-run_ai-pipelines"},{"parentId":"managing-pipeline-runs_ai-pipelines","name":"Duplicating an archived pipeline run","level":2,"index":17,"id":"duplicating-an-archived-pipeline-run_ai-pipelines"},{"parentId":null,"name":"Working with pipeline logs","level":1,"index":3,"id":"working-with-pipeline-logs_ai-pipelines"},{"parentId":"working-with-pipeline-logs_ai-pipelines","name":"About pipeline logs","level":2,"index":0,"id":"about-pipeline-logs_ai-pipelines"},{"parentId":"working-with-pipeline-logs_ai-pipelines","name":"Viewing pipeline step logs","level":2,"index":1,"id":"viewing-pipeline-step-logs_ai-pipelines"},{"parentId":"working-with-pipeline-logs_ai-pipelines","name":"Downloading pipeline step logs","level":2,"index":2,"id":"downloading-pipeline-step-logs_ai-pipelines"},{"parentId":null,"name":"Working with pipelines in JupyterLab","level":1,"index":4,"id":"working-with-pipelines-in-jupyterlab_ai-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ai-pipelines","name":"Overview of pipelines in JupyterLab","level":2,"index":0,"id":"overview-of-pipelines-in-jupyterlab_ai-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ai-pipelines","name":"Accessing the pipeline editor","level":2,"index":1,"id":"accessing-the-pipeline-editor_ai-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ai-pipelines","name":"Disabling node caching in Elyra","level":2,"index":2,"id":"disabling-node-caching-in-elyra_ai-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ai-pipelines","name":"Creating a runtime configuration","level":2,"index":3,"id":"creating-a-runtime-configuration_ai-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ai-pipelines","name":"Updating a runtime configuration","level":2,"index":4,"id":"updating-a-runtime-configuration_ai-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ai-pipelines","name":"Deleting a runtime configuration","level":2,"index":5,"id":"deleting-a-runtime-configuration_ai-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ai-pipelines","name":"Duplicating a runtime configuration","level":2,"index":6,"id":"duplicating-a-runtime-configuration_ai-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ai-pipelines","name":"Running a pipeline in JupyterLab","level":2,"index":7,"id":"running-a-pipeline-in-jupyterlab_ai-pipelines"},{"parentId":"working-with-pipelines-in-jupyterlab_ai-pipelines","name":"Exporting a pipeline in JupyterLab","level":2,"index":8,"id":"exporting-a-pipeline-in-jupyterlab_ai-pipelines"},{"parentId":null,"name":"Troubleshooting DSPA component errors","level":1,"index":5,"id":"troubleshooting-dspa-component-errors_ai-pipelines"},{"parentId":"troubleshooting-dspa-component-errors_ai-pipelines","name":"Common errors across DSPA components","level":2,"index":0,"id":"_common_errors_across_dspa_components"},{"parentId":null,"name":"Additional resources","level":1,"index":6,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-connected-applications/"},"sections":[{"parentId":null,"name":"Viewing applications that are connected to Open Data Hub","level":1,"index":0,"id":"viewing-connected-applications_connected-apps"},{"parentId":null,"name":"Enabling applications that are connected to Open Data Hub","level":1,"index":1,"id":"enabling-applications-connected_connected-apps"},{"parentId":null,"name":"Removing disabled applications from the dashboard","level":1,"index":2,"id":"removing-disabled-applications_connected-apps"},{"parentId":null,"name":"Using basic workbenches","level":1,"index":3,"id":"using-basic-workbenches_connected-apps"},{"parentId":"using-basic-workbenches_connected-apps","name":"Starting a basic workbench","level":2,"index":0,"id":"starting-a-basic-workbench_connected-apps"},{"parentId":"using-basic-workbenches_connected-apps","name":"Creating and importing Jupyter notebooks","level":2,"index":1,"id":"creating-and-importing-jupyter-notebooks_connected-apps"},{"parentId":"creating-and-importing-jupyter-notebooks_connected-apps","name":"Creating a Jupyter notebook","level":3,"index":0,"id":"creating-a-jupyter-notebook_connected-apps"},{"parentId":"creating-and-importing-jupyter-notebooks_connected-apps","name":"Uploading an existing notebook file to JupyterLab from local storage","level":3,"index":1,"id":"uploading-an-existing-notebook-file-to-jupyterlab-from-local-storage_connected-apps"},{"parentId":"creating-and-importing-jupyter-notebooks_connected-apps","name":"Deleting files into the trash directory of your workbench in Jupyter notebooks","level":3,"index":2,"id":"deleting-files-in-trash-directory_connected-apps"},{"parentId":"deleting-files-in-trash-directory_connected-apps","name":"Emptying the trash directory of your workbench in Jupyter notebooks","level":4,"index":0,"id":"emptying-trash-directory_connected-apps"},{"parentId":"creating-and-importing-jupyter-notebooks_connected-apps","name":"Additional resources","level":3,"index":3,"id":"_additional_resources"},{"parentId":"using-basic-workbenches_connected-apps","name":"Collaborating on Jupyter notebooks by using Git","level":2,"index":2,"id":"collaborating-on-jupyter-notebooks-by-using-git_connected-apps"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_connected-apps","name":"Uploading an existing notebook file from a Git repository by using JupyterLab","level":3,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_connected-apps"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_connected-apps","name":"Uploading an existing notebook file to JupyterLab from a Git repository by using the CLI","level":3,"index":1,"id":"uploading-an-existing-notebook-file-to-jupyterlab-from-a-git-repository-using-cli_connected-apps"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_connected-apps","name":"Updating your project with changes from a remote Git repository","level":3,"index":2,"id":"updating-your-project-with-changes-from-a-remote-git-repository_connected-apps"},{"parentId":"collaborating-on-jupyter-notebooks-by-using-git_connected-apps","name":"Pushing project changes to a Git repository","level":3,"index":3,"id":"pushing-project-changes-to-a-git-repository_connected-apps"},{"parentId":"using-basic-workbenches_connected-apps","name":"Managing Python packages","level":2,"index":3,"id":"managing-python-packages_connected-apps"},{"parentId":"managing-python-packages_connected-apps","name":"Viewing Python packages installed on your workbench","level":3,"index":0,"id":"viewing-python-packages-installed-on-your-workbench_connected-apps"},{"parentId":"managing-python-packages_connected-apps","name":"Installing Python packages on your workbench","level":3,"index":1,"id":"installing-python-packages-on-your-workbench_connected-apps"},{"parentId":"using-basic-workbenches_connected-apps","name":"Updating workbench settings by restarting your workbench","level":2,"index":4,"id":"updating-workbench-settings-by-restarting-your-workbench_connected-apps"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-data-in-s3-compatible-object-store/"},"sections":[{"parentId":null,"name":"Prerequisites","level":1,"index":0,"id":"s3-prerequisites_s3"},{"parentId":null,"name":"Creating an S3 client","level":1,"index":1,"id":"creating-an-s3-client_s3"},{"parentId":null,"name":"Listing available buckets in your object store","level":1,"index":2,"id":"listing-available-amazon-buckets_s3"},{"parentId":null,"name":"Creating a bucket in your object store","level":1,"index":3,"id":"creating-an-s3-bucket_s3"},{"parentId":null,"name":"Listing files in your bucket","level":1,"index":4,"id":"listing-files-in-available-amazon-s3-buckets-using-notebook-cells_s3"},{"parentId":null,"name":"Downloading files from your bucket","level":1,"index":5,"id":"downloading-files-from-available-amazon-s3-buckets-using-notebook-cells_s3"},{"parentId":null,"name":"Uploading files to your bucket","level":1,"index":6,"id":"uploading-files-to-available-amazon-s3-buckets-using-notebook-cells_s3"},{"parentId":null,"name":"Copying files between buckets","level":1,"index":7,"id":"copying-files-to-between-buckets_s3"},{"parentId":null,"name":"Deleting files from your bucket","level":1,"index":8,"id":"Deleting-files-on-your-object-store_s3"},{"parentId":null,"name":"Deleting a bucket from your object store","level":1,"index":9,"id":"deleting-a-s3-bucket_s3"},{"parentId":null,"name":"Overview of object storage endpoints","level":1,"index":10,"id":"overview-of-object-storage-endpoints_s3"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"MinIO (On-Cluster)","level":2,"index":0,"id":"_minio_on_cluster"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"Amazon S3","level":2,"index":1,"id":"_amazon_s3"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"Other S3-Compatible Object Stores","level":2,"index":2,"id":"_other_s3_compatible_object_stores"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"Verification and Troubleshooting","level":2,"index":3,"id":"_verification_and_troubleshooting"},{"parentId":null,"name":"Accessing S3-compatible object storage with self-signed certificates","level":1,"index":11,"id":"accessing-s3-compatible-object-storage-with-self-signed-certificates_s3"},{"parentId":null,"name":"Additional resources","level":1,"index":12,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-distributed-workloads/"},"sections":[{"parentId":null,"name":"Overview of distributed workloads","level":1,"index":0,"id":"overview-of-distributed-workloads_distributed-workloads"},{"parentId":"overview-of-distributed-workloads_distributed-workloads","name":"Distributed workloads infrastructure","level":2,"index":0,"id":"_distributed_workloads_infrastructure"},{"parentId":"overview-of-distributed-workloads_distributed-workloads","name":"Types of distributed workloads","level":2,"index":1,"id":"_types_of_distributed_workloads"},{"parentId":null,"name":"Preparing the distributed training environment","level":1,"index":1,"id":"preparing-the-distributed-training-environment_distributed-workloads"},{"parentId":"preparing-the-distributed-training-environment_distributed-workloads","name":"Creating a workbench for distributed training","level":2,"index":0,"id":"creating-a-workbench-for-distributed-training_distributed-workloads"},{"parentId":"preparing-the-distributed-training-environment_distributed-workloads","name":"Using the cluster server and token to authenticate","level":2,"index":1,"id":"using-the-cluster-server-and-token-to-authenticate_distributed-workloads"},{"parentId":"preparing-the-distributed-training-environment_distributed-workloads","name":"Managing custom training images","level":2,"index":2,"id":"managing-custom-training-images_distributed-workloads"},{"parentId":"managing-custom-training-images_distributed-workloads","name":"About base training images","level":3,"index":0,"id":"about-base-training-images_distributed-workloads"},{"parentId":"managing-custom-training-images_distributed-workloads","name":"Creating a custom training image","level":3,"index":1,"id":"creating-a-custom-training-image_distributed-workloads"},{"parentId":"managing-custom-training-images_distributed-workloads","name":"Pushing an image to the integrated OpenShift image registry","level":3,"index":2,"id":"pushing-an-image-to-the-integrated-openshift-image-registry_distributed-workloads"},{"parentId":null,"name":"Running Ray-based distributed workloads","level":1,"index":2,"id":"running-ray-based-distributed-workloads_distributed-workloads"},{"parentId":"running-ray-based-distributed-workloads_distributed-workloads","name":"Running distributed data science workloads from Jupyter notebooks","level":2,"index":0,"id":"running-distributed-data-science-workloads-from-jupyter-notebooks_distributed-workloads"},{"parentId":"running-distributed-data-science-workloads-from-jupyter-notebooks_distributed-workloads","name":"Downloading the demo Jupyter notebooks from the CodeFlare SDK","level":3,"index":0,"id":"downloading-the-demo-jupyter-notebooks-from-the-codeflare-sdk_distributed-workloads"},{"parentId":"running-distributed-data-science-workloads-from-jupyter-notebooks_distributed-workloads","name":"Running the demo Jupyter notebooks from the CodeFlare SDK","level":3,"index":1,"id":"running-the-demo-jupyter-notebooks-from-the-codeflare-sdk_distributed-workloads"},{"parentId":"running-distributed-data-science-workloads-from-jupyter-notebooks_distributed-workloads","name":"Managing Ray clusters from within a Jupyter notebook","level":3,"index":2,"id":"managing-ray-clusters-from-within-a-jupyter-notebook_distributed-workloads"},{"parentId":"running-ray-based-distributed-workloads_distributed-workloads","name":"Running distributed data science workloads from AI pipelines","level":2,"index":1,"id":"running-distributed-data-science-workloads-from-ai-pipelines_distributed-workloads"},{"parentId":null,"name":"Running Training Operator-based distributed training workloads","level":1,"index":3,"id":"running-kfto-based-distributed-training-workloads_distributed-workloads"},{"parentId":"running-kfto-based-distributed-training-workloads_distributed-workloads","name":"Using the Kubeflow Training Operator to run distributed training workloads","level":2,"index":0,"id":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads","name":"Creating a Training Operator PyTorch training script ConfigMap resource","level":3,"index":0,"id":"creating-a-kfto-pytorch-training-script-configmap-resource_distributed-workloads"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads","name":"Creating a Training Operator PyTorchJob resource","level":3,"index":1,"id":"creating-a-kfto-pytorchjob-resource_distributed-workloads"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads","name":"Creating a Training Operator PyTorchJob resource by using the CLI","level":3,"index":2,"id":"creating-a-kfto-pytorchjob-resource-by-using-the-cli_distributed-workloads"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads","name":"Example Training Operator PyTorch training scripts","level":3,"index":3,"id":"example-kfto-pytorch-training-scripts_distributed-workloads"},{"parentId":"example-kfto-pytorch-training-scripts_distributed-workloads","name":"Example Training Operator PyTorch training script: NCCL","level":4,"index":0,"id":"ref-example-kfto-pytorch-training-script-nccldistributed-workloads"},{"parentId":"example-kfto-pytorch-training-scripts_distributed-workloads","name":"Example Training Operator PyTorch training script: DDP","level":4,"index":1,"id":"ref-example-kfto-pytorch-training-script-ddp_distributed-workloads"},{"parentId":"example-kfto-pytorch-training-scripts_distributed-workloads","name":"Example Training Operator PyTorch training script: FSDP","level":4,"index":2,"id":"ref-example-kfto-pytorch-training-script-fsdp_distributed-workloads"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads","name":"Example Dockerfile for a Training Operator PyTorch training script","level":3,"index":4,"id":"ref-example-dockerfile-for-a-kfto-pytorch-training-script_distributed-workloads"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_distributed-workloads","name":"Example Training Operator PyTorchJob resource for multi-node training","level":3,"index":5,"id":"ref-example-kfto-pytorchjob-resource-for-multi-node-training_distributed-workloads"},{"parentId":"running-kfto-based-distributed-training-workloads_distributed-workloads","name":"Using the Training Operator SDK to run distributed training workloads","level":2,"index":1,"id":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_distributed-workloads"},{"parentId":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_distributed-workloads","name":"Configuring a training job by using the Training Operator SDK","level":3,"index":0,"id":"configuring-a-training-job-by-using-the-kfto-sdk_distributed-workloads"},{"parentId":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_distributed-workloads","name":"Running a training job by using the Training Operator SDK","level":3,"index":1,"id":"running-a-training-job-by-using-the-kfto-sdk_distributed-workloads"},{"parentId":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_distributed-workloads","name":"TrainingClient API: Job-related methods","level":3,"index":2,"id":"ref-trainingclient-api-job-related-methods_distributed-workloads"},{"parentId":"running-kfto-based-distributed-training-workloads_distributed-workloads","name":"Fine-tuning a model by using Kubeflow Training","level":2,"index":2,"id":"fine-tuning-a-model-by-using-kubeflow-training_distributed-workloads"},{"parentId":"fine-tuning-a-model-by-using-kubeflow-training_distributed-workloads","name":"Configuring the fine-tuning job","level":3,"index":0,"id":"configuring-the-fine-tuning-job_distributed-workloads"},{"parentId":"fine-tuning-a-model-by-using-kubeflow-training_distributed-workloads","name":"Running the fine-tuning job","level":3,"index":1,"id":"running-the-fine-tuning-job_distributed-workloads"},{"parentId":"fine-tuning-a-model-by-using-kubeflow-training_distributed-workloads","name":"Deleting the fine-tuning job","level":3,"index":2,"id":"deleting-the-fine-tuning-job_distributed-workloads"},{"parentId":"running-kfto-based-distributed-training-workloads_distributed-workloads","name":"Creating a multi-node PyTorch training job with RDMA","level":2,"index":3,"id":"creating-a-multi-node-pytorch-training-job-with-rdma_distributed-workloads"},{"parentId":"running-kfto-based-distributed-training-workloads_distributed-workloads","name":"Example Training Operator PyTorchJob resource configured to run with RDMA","level":2,"index":4,"id":"ref-example-kfto-pytorchjob-resource-configured-to-run-with-rdma_distributed-workloads"},{"parentId":null,"name":"Monitoring distributed workloads","level":1,"index":4,"id":"monitoring-distributed-workloads_distributed-workloads"},{"parentId":"monitoring-distributed-workloads_distributed-workloads","name":"Viewing project metrics for distributed workloads","level":2,"index":0,"id":"viewing-project-metrics-for-distributed-workloads_distributed-workloads"},{"parentId":"monitoring-distributed-workloads_distributed-workloads","name":"Viewing the status of distributed workloads","level":2,"index":1,"id":"viewing-the-status-of-distributed-workloads_distributed-workloads"},{"parentId":"monitoring-distributed-workloads_distributed-workloads","name":"Viewing Kueue alerts for distributed workloads","level":2,"index":2,"id":"viewing-kueue-alerts-for-distributed-workloads_distributed-workloads"},{"parentId":null,"name":"Troubleshooting common problems with distributed workloads for users","level":1,"index":5,"id":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"My Ray cluster is in a suspended state","level":2,"index":0,"id":"_my_ray_cluster_is_in_a_suspended_state"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"My Ray cluster is in a failed state","level":2,"index":1,"id":"_my_ray_cluster_is_in_a_failed_state"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"I see a \"failed to call webhook\" error message for Kueue","level":2,"index":2,"id":"_i_see_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"My Ray cluster does not start","level":2,"index":3,"id":"_my_ray_cluster_does_not_start"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"I see a \"Default Local Queue not found\" error message","level":2,"index":4,"id":"_i_see_a_default_local_queue_not_found_error_message"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"I see a \"local_queue provided does not exist\" error message","level":2,"index":5,"id":"_i_see_a_local_queue_provided_does_not_exist_error_message"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"I cannot create a Ray cluster or submit jobs","level":2,"index":6,"id":"_i_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"My pod provisioned by Kueue is terminated before my image is pulled","level":2,"index":7,"id":"_my_pod_provisioned_by_kueue_is_terminated_before_my_image_is_pulled"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads","name":"Additional resources","level":2,"index":8,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-llama-stack/"},"sections":[{"parentId":null,"name":"Overview of Llama Stack","level":1,"index":0,"id":"overview-of-llama-stack_rag"},{"parentId":"overview-of-llama-stack_rag","name":"OpenAI compatibility for RAG APIs in Llama Stack","level":2,"index":0,"id":"openai-compatibility-for-rag-apis-in-llama-stack_rag"},{"parentId":"overview-of-llama-stack_rag","name":"OpenAI-compatible APIs in Llama Stack","level":2,"index":1,"id":"openai-compatible-apis-in-Llama-Stack_rag"},{"parentId":"openai-compatible-apis-in-Llama-Stack_rag","name":"Supported OpenAI-compatible APIs in Open Data Hub","level":3,"index":0,"id":"_supported_openai_compatible_apis_in_open_data_hub"},{"parentId":"_supported_openai_compatible_apis_in_open_data_hub","name":"Chat Completions API","level":4,"index":0,"id":"_chat_completions_api"},{"parentId":"_supported_openai_compatible_apis_in_open_data_hub","name":"Completions API","level":4,"index":1,"id":"_completions_api"},{"parentId":"_supported_openai_compatible_apis_in_open_data_hub","name":"Embeddings API","level":4,"index":2,"id":"_embeddings_api"},{"parentId":"_supported_openai_compatible_apis_in_open_data_hub","name":"Files API","level":4,"index":3,"id":"_files_api"},{"parentId":"_supported_openai_compatible_apis_in_open_data_hub","name":"Vector Stores API","level":4,"index":4,"id":"_vector_stores_api"},{"parentId":"_supported_openai_compatible_apis_in_open_data_hub","name":"Vector Store Files API","level":4,"index":5,"id":"_vector_store_files_api"},{"parentId":"_supported_openai_compatible_apis_in_open_data_hub","name":"Models API","level":4,"index":6,"id":"_models_api"},{"parentId":"_supported_openai_compatible_apis_in_open_data_hub","name":"Responses API","level":4,"index":7,"id":"_responses_api"},{"parentId":null,"name":"Activating the Llama Stack Operator","level":1,"index":1,"id":"activating-the-llama-stack-operator_rag"},{"parentId":null,"name":"Deploying a RAG stack in a project","level":1,"index":2,"id":"deploying-a-rag-stack-in-a-project_rag"},{"parentId":"deploying-a-rag-stack-in-a-project_rag","name":"Overview of RAG","level":2,"index":0,"id":"overview-of-rag_rag"},{"parentId":"overview-of-rag_rag","name":"Audience for RAG","level":3,"index":0,"id":"_audience_for_rag"},{"parentId":"deploying-a-rag-stack-in-a-project_rag","name":"Overview of vector databases","level":2,"index":1,"id":"overview-of-vector-databases_rag"},{"parentId":"overview-of-vector-databases_rag","name":"Overview of Milvus vector databases","level":3,"index":0,"id":"overview-of-milvus-vector-databases_rag"},{"parentId":"overview-of-vector-databases_rag","name":"Overview of FAISS vector databases","level":3,"index":1,"id":"overview-of-faiss-vector-databases_rag"},{"parentId":"deploying-a-rag-stack-in-a-project_rag","name":"Deploying a Llama model with KServe","level":2,"index":2,"id":"Deploying-a-llama-model-with-kserve_rag"},{"parentId":"deploying-a-rag-stack-in-a-project_rag","name":"Testing your vLLM model endpoints","level":2,"index":3,"id":"testing-your-vllm-model-endpoints_rag"},{"parentId":"deploying-a-rag-stack-in-a-project_rag","name":"Deploying a remote Milvus vector database","level":2,"index":4,"id":"deploying-a-remote-milvus-vector-database_rag"},{"parentId":"deploying-a-rag-stack-in-a-project_rag","name":"Deploying a LlamaStackDistribution instance","level":2,"index":5,"id":"deploying-a-llamastackdistribution-instance_rag"},{"parentId":"deploying-a-llamastackdistribution-instance_rag","name":"Example A: LlamaStackDistribution with <strong>Inline Milvus</strong>","level":3,"index":0,"id":"_example_a_llamastackdistribution_with_inline_milvus"},{"parentId":"deploying-a-llamastackdistribution-instance_rag","name":"Example B: LlamaStackDistribution with <strong>Remote Milvus</strong>","level":3,"index":1,"id":"_example_b_llamastackdistribution_with_remote_milvus"},{"parentId":"deploying-a-llamastackdistribution-instance_rag","name":"Example C: LlamaStackDistribution with <strong>Inline FAISS</strong>","level":3,"index":2,"id":"_example_c_llamastackdistribution_with_inline_faiss"},{"parentId":"deploying-a-rag-stack-in-a-project_rag","name":"Ingesting content into a Llama model","level":2,"index":6,"id":"ingesting-content-into-a-llama-model_rag"},{"parentId":"deploying-a-rag-stack-in-a-project_rag","name":"Querying ingested content in a Llama model","level":2,"index":7,"id":"querying-ingested-content-in-a-llama-model_rag"},{"parentId":"deploying-a-rag-stack-in-a-project_rag","name":"Preparing documents with Docling for Llama Stack retrieval","level":2,"index":8,"id":"preparing-documents-with-docling-for-llama-stack-retrieval_rag"},{"parentId":"deploying-a-rag-stack-in-a-project_rag","name":"About Llama stack search types","level":2,"index":9,"id":"about-llama-stack-search-types_rag"},{"parentId":"about-llama-stack-search-types_rag","name":"Supported search modes","level":3,"index":0,"id":"_supported_search_modes"},{"parentId":"_supported_search_modes","name":"Keyword search","level":4,"index":0,"id":"_keyword_search"},{"parentId":"_supported_search_modes","name":"Vector search","level":4,"index":1,"id":"_vector_search"},{"parentId":"_supported_search_modes","name":"Hybrid search","level":4,"index":2,"id":"_hybrid_search"},{"parentId":"about-llama-stack-search-types_rag","name":"Retrieval database support","level":3,"index":1,"id":"_retrieval_database_support"},{"parentId":null,"name":"Configuring Llama Stack with OAuth Authentication","level":1,"index":3,"id":"auth-on-llama-stack_rag"},{"parentId":null,"name":"Evaluating RAG systems with Llama Stack","level":1,"index":4,"id":"evaluating-rag-systems-with-llama-stack_rag"},{"parentId":"evaluating-rag-systems-with-llama-stack_rag","name":"Understanding RAG evaluation providers","level":2,"index":0,"id":"understanding-rag-evaluation-providers_rag"},{"parentId":"evaluating-rag-systems-with-llama-stack_rag","name":"Using Ragas with Llama Stack","level":2,"index":1,"id":"using-ragas-with-llama-stack_rag"},{"parentId":"evaluating-rag-systems-with-llama-stack_rag","name":"Benchmarking embedding models with BEIR datasets and Llama Stack","level":2,"index":2,"id":"benchmarking-embedding-models-with-BEIR-datasets-and-Llama-Stack_rag"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-machine-learning-features/"},"sections":[{"parentId":null,"name":"Overview of machine learning features and Feature Store","level":1,"index":0,"id":"overview-of-ml-features-and-feature-store.adoc_featurestore"},{"parentId":"overview-of-ml-features-and-feature-store.adoc_featurestore","name":"Audience for Feature Store","level":2,"index":0,"id":"audience-for-feature-store_featurestore"},{"parentId":"overview-of-ml-features-and-feature-store.adoc_featurestore","name":"Overview of machine learning features","level":2,"index":1,"id":"overview-of-machine-learning-features_featurestore"},{"parentId":"overview-of-ml-features-and-feature-store.adoc_featurestore","name":"Overview of Feature Store","level":2,"index":2,"id":"overview-of-feature-store_featurestore"},{"parentId":"overview-of-ml-features-and-feature-store.adoc_featurestore","name":"Feature Store workflow","level":2,"index":3,"id":"feature-store-workflow_featurestore"},{"parentId":"overview-of-ml-features-and-feature-store.adoc_featurestore","name":"Setting up the Feature Store user interface for initial use","level":2,"index":4,"id":"setting-up-feature-store-UI_featurestore"},{"parentId":"overview-of-ml-features-and-feature-store.adoc_featurestore","name":"Additional resources","level":2,"index":5,"id":"_additional_resources"},{"parentId":null,"name":"Configuring Feature Store","level":1,"index":1,"id":"_configuring_feature_store"},{"parentId":"_configuring_feature_store","name":"Setting up Feature Store","level":2,"index":0,"id":"setting-up-feature-store_featurestore"},{"parentId":"setting-up-feature-store_featurestore","name":"Before you begin","level":3,"index":0,"id":"before-you-begin_featurestore"},{"parentId":"setting-up-feature-store_featurestore","name":"Enabling the Feature Store component","level":3,"index":1,"id":"enabling-the-feature-store-component_featurestore"},{"parentId":"setting-up-feature-store_featurestore","name":"Creating a Feature Store instance in a project","level":3,"index":2,"id":"creating-a-feature-store-instance-in-a-project_featurestore"},{"parentId":"setting-up-feature-store_featurestore","name":"Configuring and managing Role Based Access Control","level":3,"index":3,"id":"configuring-and-managing-role-based-access-control_featurestore"},{"parentId":"setting-up-feature-store_featurestore","name":"Adding feature definitions and initializing your Feature Store instance","level":3,"index":4,"id":"adding-feature-definitions-and-initializing-your-feature-store-instance_featurestore"},{"parentId":"adding-feature-definitions-and-initializing-your-feature-store-instance_featurestore","name":"Specifying files to ignore","level":4,"index":0,"id":"specifying-files-to-ignore_featurestore"},{"parentId":"setting-up-feature-store_featurestore","name":"Viewing Feature Store objects in the web-based UI","level":3,"index":5,"id":"viewing-feature-store-objects-in-the-web-based-ui_featurestore"},{"parentId":"_configuring_feature_store","name":"Customizing your Feature Store configuration","level":2,"index":1,"id":"customizing-your-feature-store-configuration_featurestore"},{"parentId":"customizing-your-feature-store-configuration_featurestore","name":"Configuring an offline store","level":3,"index":0,"id":"configuring-an-offline-store_featurestore"},{"parentId":"customizing-your-feature-store-configuration_featurestore","name":"Configuring an online store","level":3,"index":1,"id":"configuring-an-online-store_featurestore"},{"parentId":"customizing-your-feature-store-configuration_featurestore","name":"Configuring the feature registry","level":3,"index":2,"id":"configuring-the-feature-registry_featurestore"},{"parentId":"customizing-your-feature-store-configuration_featurestore","name":"Example PVC configuration","level":3,"index":3,"id":"ref-example-pvc-configuration_featurestore"},{"parentId":"customizing-your-feature-store-configuration_featurestore","name":"Editing an existing Feature Store instance","level":3,"index":4,"id":"editing-an-existing-feature-store-instance_featurestore"},{"parentId":null,"name":"Defining machine learning features","level":1,"index":2,"id":"defining-ml-features_featurestore"},{"parentId":"defining-ml-features_featurestore","name":"Setting up your working environment","level":2,"index":0,"id":"setting-up-your-working-environment_featurestore"},{"parentId":"defining-ml-features_featurestore","name":"Enabling automatic authentication and publishing features","level":2,"index":1,"id":"enabling-automatic-authentication-and-publishing-features_featurestore"},{"parentId":"defining-ml-features_featurestore","name":"About feature definitions","level":2,"index":2,"id":"about-feature-definitions_featurestore"},{"parentId":"defining-ml-features_featurestore","name":"Specifying the data source for features","level":2,"index":3,"id":"specifying-the-data-source-for-features_featurestore"},{"parentId":"defining-ml-features_featurestore","name":"About organizing features by using entities","level":2,"index":4,"id":"about-organizing-features-by-using-entities_featurestore"},{"parentId":"defining-ml-features_featurestore","name":"Creating feature views","level":2,"index":5,"id":"creating-feature-views_featurestore"},{"parentId":null,"name":"Retrieving features for model training","level":1,"index":3,"id":"retrieving-features-for-model-training_featurestore"},{"parentId":"retrieving-features-for-model-training_featurestore","name":"Retrieving data science features","level":2,"index":0,"id":"retrieving-data-science-features_featurestore"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/working-with-model-registries/"},"sections":[{"parentId":null,"name":"Overview of the model catalog and model registries","level":1,"index":0,"id":"overview-of-model-registries_model-registry"},{"parentId":"overview-of-model-registries_model-registry","name":"Model catalog","level":2,"index":0,"id":"_model_catalog"},{"parentId":"overview-of-model-registries_model-registry","name":"Model registry","level":2,"index":1,"id":"_model_registry"},{"parentId":null,"name":"Enabling the model registry component","level":0,"index":1,"id":"_enabling_the_model_registry_component"},{"parentId":"_enabling_the_model_registry_component","name":"Enabling the model registry component","level":1,"index":0,"id":"enabling-the-model-registry-component_model-registry"},{"parentId":null,"name":"Managing model registries","level":0,"index":2,"id":"_managing_model_registries"},{"parentId":"_managing_model_registries","name":"Creating a model registry","level":1,"index":0,"id":"creating-a-model-registry_model-registry"},{"parentId":"_managing_model_registries","name":"Editing a model registry","level":1,"index":1,"id":"editing-a-model-registry_model-registry"},{"parentId":"_managing_model_registries","name":"Managing model registry permissions","level":1,"index":2,"id":"managing-model-registry-permissions_model-registry"},{"parentId":"_managing_model_registries","name":"Deleting a model registry","level":1,"index":3,"id":"deleting-a-model-registry_model-registry"},{"parentId":null,"name":"Working with model registries","level":0,"index":3,"id":"_working_with_model_registries"},{"parentId":"_working_with_model_registries","name":"Working with model registries","level":1,"index":0,"id":"working-with-model-registries_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Registering a model from the dashboard","level":2,"index":0,"id":"registering-a-model_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Registering a model version","level":2,"index":1,"id":"registering-a-model-version_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Viewing registered models","level":2,"index":2,"id":"viewing-registered-models_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Viewing registered model versions","level":2,"index":3,"id":"viewing-registered-model-versions_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Editing model metadata in a model registry","level":2,"index":4,"id":"editing-model-metadata-in-a-model-registry_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Editing model version metadata in a model registry","level":2,"index":5,"id":"editing-model-version-metadata-in-a-model-registry_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Deploying a model version from a model registry","level":2,"index":6,"id":"deploying-a-model-version-from-a-model-registry_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Editing the deployment properties of a deployed model version from a model registry","level":2,"index":7,"id":"_editing_the_deployment_properties_of_a_deployed_model_version_from_a_model_registry"},{"parentId":"_editing_the_deployment_properties_of_a_deployed_model_version_from_a_model_registry","name":"Editing the deployment properties of a model deployed by using the model serving platform","level":3,"index":0,"id":"editing-the-deployment-properties-of-a-model-deployed-by-using-the-model-serving-platform_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Deleting a deployed model version from a model registry","level":2,"index":8,"id":"deleting-a-deployed-model-version-from-a-model-registry_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Archiving a model","level":2,"index":9,"id":"archiving-a-model_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Archiving a model version","level":2,"index":10,"id":"archiving-a-model-version_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Restoring a model","level":2,"index":11,"id":"restoring-a-model_model-registry"},{"parentId":"working-with-model-registries_model-registry","name":"Restoring a model version","level":2,"index":12,"id":"restoring-a-model-version_model-registry"},{"parentId":null,"name":"Working with the model catalog","level":0,"index":4,"id":"_working_with_the_model_catalog"},{"parentId":"_working_with_the_model_catalog","name":"Working with the model catalog","level":1,"index":0,"id":"working-with-the-model-catalog_model-registry"},{"parentId":"working-with-the-model-catalog_model-registry","name":"Discovering and evaluating models in the model catalog","level":2,"index":0,"id":"viewing-models-in-the-catalog_model-registry"},{"parentId":"working-with-the-model-catalog_model-registry","name":"Registering a model from the model catalog","level":2,"index":1,"id":"registering-a-model-from-the-model-catalog_model-registry"},{"parentId":"working-with-the-model-catalog_model-registry","name":"Deploying a model from the model catalog","level":2,"index":2,"id":"deploying-a-model-from-the-model-catalog_model-registry"},{"parentId":"working-with-the-model-catalog_model-registry","name":"Configuring model catalog sources in OpenShift","level":2,"index":3,"id":"configuring-model-catalog-sources-in-openshift_model-registry"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/_artifacts/document-attributes-global/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/backing-up-data/"},"sections":[{"parentId":null,"name":"Backing up storage data","level":1,"index":0,"id":"backing-up-storage-data_data-mgmt"},{"parentId":null,"name":"Backing up your cluster","level":1,"index":1,"id":"backing-up-your-cluster_data-mgmt"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/bias-monitoring-tutorial/"},"sections":[{"parentId":null,"name":"Introduction","level":1,"index":0,"id":"t-bias-introduction_bias-tutorial"},{"parentId":"t-bias-introduction_bias-tutorial","name":"About the example models","level":2,"index":0,"id":"_about_the_example_models"},{"parentId":null,"name":"Setting up your environment","level":1,"index":1,"id":"t-bias-setting-up-your-environment_bias-tutorial"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Downloading the tutorial files","level":2,"index":0,"id":"_downloading_the_tutorial_files"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Logging in to the OpenShift cluster from the command line","level":2,"index":1,"id":"_logging_in_to_the_openshift_cluster_from_the_command_line"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Configuring monitoring for the model serving platform","level":2,"index":2,"id":"_configuring_monitoring_for_the_model_serving_platform"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Enabling the TrustyAI component","level":2,"index":3,"id":"enabling-trustyai-component_bias-tutorial"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Setting up a project","level":2,"index":4,"id":"_setting_up_a_project"},{"parentId":"t-bias-setting-up-your-environment_bias-tutorial","name":"Authenticating the TrustyAI service","level":2,"index":5,"id":"_authenticating_the_trustyai_service"},{"parentId":null,"name":"Deploying models","level":1,"index":2,"id":"t-bias-deploying-models_bias-tutorial"},{"parentId":null,"name":"Sending training data to the models","level":1,"index":3,"id":"t-bias-sending-training-data-to-the-models_bias-tutorial"},{"parentId":null,"name":"Labeling data fields","level":1,"index":4,"id":"t-bias-labeling-data-fields_bias-tutorial"},{"parentId":null,"name":"Checking model fairness","level":1,"index":5,"id":"t-bias-checking-model-fairness_bias-tutorial"},{"parentId":null,"name":"Scheduling a fairness metric request","level":1,"index":6,"id":"t-bias-scheduling-a-fairness-metric-request_bias-tutorial"},{"parentId":null,"name":"Scheduling an identity metric request","level":1,"index":7,"id":"t-bias-scheduling-an-identity-metric-request_bias-tutorial"},{"parentId":null,"name":"Simulating real world data","level":1,"index":8,"id":"t-bias-simulating-real-world-data_bias-tutorial"},{"parentId":null,"name":"Reviewing the results","level":1,"index":9,"id":"t-bias-reviewing-the-results_bias-tutorial"},{"parentId":"t-bias-reviewing-the-results_bias-tutorial","name":"Are the models biased?","level":2,"index":0,"id":"_are_the_models_biased"},{"parentId":"t-bias-reviewing-the-results_bias-tutorial","name":"How does the production data compare to the training data?","level":2,"index":1,"id":"_how_does_the_production_data_compare_to_the_training_data"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/collaborating-on-jupyter-notebooks-by-using-git/"},"sections":[{"parentId":null,"name":"Uploading an existing notebook file from a Git repository by using JupyterLab","level":1,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab_{context}"},{"parentId":null,"name":"Uploading an existing notebook file to JupyterLab from a Git repository by using the CLI","level":1,"index":1,"id":"uploading-an-existing-notebook-file-to-jupyterlab-from-a-git-repository-using-cli_{context}"},{"parentId":null,"name":"Updating your project with changes from a remote Git repository","level":1,"index":2,"id":"updating-your-project-with-changes-from-a-remote-git-repository_{context}"},{"parentId":null,"name":"Pushing project changes to a Git repository","level":1,"index":3,"id":"pushing-project-changes-to-a-git-repository_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/collaborating-on-workbenches-in-code-server-by-using-git/"},"sections":[{"parentId":null,"name":"Uploading an existing notebook file from a Git repository by using code-server","level":1,"index":0,"id":"uploading-an-existing-notebook-file-from-a-git-repository-using-code-server_{context}"},{"parentId":null,"name":"Uploading an existing notebook file to code-server from a Git repository by using the CLI","level":1,"index":1,"id":"uploading-an-existing-notebook-file-to-code-server-from-a-git-repository-using-cli_{context}"},{"parentId":null,"name":"Updating your project in code-server with changes from a remote Git repository","level":1,"index":2,"id":"updating-your-project-in-code-server-with-changes-from-a-remote-git-repository_{context}"},{"parentId":null,"name":"Pushing project changes in code-server to a Git repository","level":1,"index":3,"id":"pushing-project-changes-in-code-server-to-a-git-repository_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/configuring-cluster-storage/"},"sections":[{"parentId":null,"name":"About persistent storage","level":1,"index":0,"id":"about-persistent-storage_{context}"},{"parentId":"about-persistent-storage_{context}","name":"Storage classes in {productname-short}","level":2,"index":0,"id":"_storage_classes_in_productname_short"},{"parentId":"about-persistent-storage_{context}","name":"Access modes","level":2,"index":1,"id":"_access_modes"},{"parentId":"_access_modes","name":"Using shared storage (RWX)","level":3,"index":0,"id":"_using_shared_storage_rwx"},{"parentId":null,"name":"Adding cluster storage to your project","level":1,"index":1,"id":"adding-cluster-storage-to-your-project_{context}"},{"parentId":null,"name":"Updating cluster storage","level":1,"index":2,"id":"updating-cluster-storage_{context}"},{"parentId":null,"name":"Changing the storage class for an existing cluster storage instance","level":1,"index":3,"id":"changing-the-storage-class-for-an-existing-cluster-storage-instance_{context}"},{"parentId":null,"name":"Deleting cluster storage from a project","level":1,"index":4,"id":"deleting-cluster-storage-from-a-project_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/configuring-external-oidc-provider/"},"sections":[{"parentId":null,"name":"About centralized authentication Gateway API","level":1,"index":0,"id":"about-centralized-auth-oidc_{context}"},{"parentId":null,"name":"Configuring OpenID Connect (OIDC) authentication for Gateway API","level":1,"index":1,"id":"configuring-oidc-auth-gateway-api_{context}"},{"parentId":"configuring-oidc-auth-gateway-api_{context}","name":"Security considerations","level":2,"index":0,"id":"_security_considerations"},{"parentId":null,"name":"Troubleshooting common problems with Gateway API configuration","level":1,"index":2,"id":"troubleshooting-common-problems-gateway-api_{context}"},{"parentId":"troubleshooting-common-problems-gateway-api_{context}","name":"The <code>GatewayConfig</code> status shows as not ready","level":2,"index":0,"id":"_the_gatewayconfig_status_shows_as_not_ready"},{"parentId":"troubleshooting-common-problems-gateway-api_{context}","name":"Authentication proxy fails to start","level":2,"index":1,"id":"_authentication_proxy_fails_to_start"},{"parentId":"troubleshooting-common-problems-gateway-api_{context}","name":"The Gateway is inaccessible","level":2,"index":2,"id":"_the_gateway_is_inaccessible"},{"parentId":"troubleshooting-common-problems-gateway-api_{context}","name":"The OIDC authentication fails","level":2,"index":3,"id":"_the_oidc_authentication_fails"},{"parentId":"troubleshooting-common-problems-gateway-api_{context}","name":"The dashboard is not accessible after authentication","level":2,"index":4,"id":"_the_dashboard_is_not_accessible_after_authentication"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/configuring-feature-store-role-based-access-control/"},"sections":[{"parentId":null,"name":"Configuring role-based access control","level":1,"index":0,"id":"configuring-role-based-access-control_{context}"},{"parentId":null,"name":"Default authorization configuration","level":1,"index":1,"id":"ref-default-authorization-configuration_{context}"},{"parentId":null,"name":"Example OIDC Authorization configuration","level":1,"index":2,"id":"ref-example-oidc-authorization-configuration_{context}"},{"parentId":null,"name":"Example Kubernetes Authorization configuration","level":1,"index":3,"id":"ref-example-kubernetes-authorization-configuration_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/configuring-trustyai/"},"sections":[{"parentId":null,"name":"Configuring monitoring for your model serving platform","level":1,"index":0,"id":"configuring-monitoring-for-your-model-serving-platform_{context}"},{"parentId":null,"name":"Enabling the TrustyAI component","level":1,"index":1,"id":"enabling-trustyai-component_{context}"},{"parentId":null,"name":"Configuring TrustyAI with a database","level":1,"index":2,"id":"configuring-trustyai-with-a-database_{context}"},{"parentId":null,"name":"Installing the TrustyAI service for a project","level":1,"index":3,"id":"installing-trustyai-service_{context}"},{"parentId":"installing-trustyai-service_{context}","name":"Installing the TrustyAI service by using the dashboard","level":2,"index":0,"id":"installing-trustyai-service-using-dashboard_{context}"},{"parentId":"installing-trustyai-service_{context}","name":"Installing the TrustyAI service by using the CLI","level":2,"index":1,"id":"installing-trustyai-service-using-cli_{context}"},{"parentId":null,"name":"Enabling TrustyAI Integration with KServe RawDeployment","level":1,"index":4,"id":"enabling-trustyai-kserve-integration_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/configuring-your-model-serving-platform/"},"sections":[{"parentId":null,"name":"About model serving","level":1,"index":0,"id":"about-model-serving_odh-admin"},{"parentId":"about-model-serving_odh-admin","name":"Model serving platform","level":2,"index":0,"id":"_model_serving_platform"},{"parentId":"about-model-serving_odh-admin","name":"NVIDIA NIM model serving platform","level":2,"index":1,"id":"_nvidia_nim_model_serving_platform"},{"parentId":null,"name":"Model-serving runtimes","level":1,"index":1,"id":"model-serving-runtimes_odh-admin"},{"parentId":"model-serving-runtimes_odh-admin","name":"ServingRuntime","level":2,"index":0,"id":"_servingruntime"},{"parentId":"model-serving-runtimes_odh-admin","name":"InferenceService","level":2,"index":1,"id":"_inferenceservice"},{"parentId":null,"name":"Model-serving runtimes for accelerators","level":1,"index":2,"id":"model-serving-runtimes-for-accelerators_odh-admin"},{"parentId":"model-serving-runtimes-for-accelerators_odh-admin","name":"NVIDIA GPUs","level":2,"index":0,"id":"_nvidia_gpus"},{"parentId":"model-serving-runtimes-for-accelerators_odh-admin","name":"Intel Gaudi accelerators","level":2,"index":1,"id":"_intel_gaudi_accelerators"},{"parentId":"model-serving-runtimes-for-accelerators_odh-admin","name":"AMD GPUs","level":2,"index":2,"id":"_amd_gpus"},{"parentId":"model-serving-runtimes-for-accelerators_odh-admin","name":"IBM Spyre AI accelerators on x86 and IBM Z","level":2,"index":3,"id":"_ibm_spyre_ai_accelerators_on_x86_and_ibm_z"},{"parentId":"model-serving-runtimes-for-accelerators_odh-admin","name":"Supported model-serving runtimes","level":2,"index":4,"id":"supported-model-serving-runtimes_odh-admin"},{"parentId":"model-serving-runtimes-for-accelerators_odh-admin","name":"Tested and verified model-serving runtimes","level":2,"index":5,"id":"tested-verified-runtimes_odh-admin"},{"parentId":null,"name":"Configuring model servers","level":0,"index":3,"id":"_configuring_model_servers"},{"parentId":"_configuring_model_servers","name":"Enabling the model serving platform","level":1,"index":0,"id":"enabling-the-model-serving-platform_odh-admin"},{"parentId":"_configuring_model_servers","name":"Enabling speculative decoding and multi-modal inferencing","level":1,"index":1,"id":"enabling-speculative-decoding-and-multi-modal-inferencing_odh-admin"},{"parentId":"_configuring_model_servers","name":"Adding a custom model-serving runtime","level":1,"index":2,"id":"adding-a-custom-model-serving-runtime_odh-admin"},{"parentId":"_configuring_model_servers","name":"Adding a tested and verified runtime","level":1,"index":3,"id":"adding-a-tested-and-verified-runtime_odh-admin"},{"parentId":null,"name":"Configuring model servers on the NVIDIA NIM model serving platform","level":0,"index":4,"id":"_configuring_model_servers_on_the_nvidia_nim_model_serving_platform"},{"parentId":"_configuring_model_servers_on_the_nvidia_nim_model_serving_platform","name":"Enabling the NVIDIA NIM model serving platform","level":1,"index":0,"id":"enabling-the-nvidia-nim-model-serving-platform_odh-admin"},{"parentId":null,"name":"Customizing model deployments","level":0,"index":5,"id":"_customizing_model_deployments"},{"parentId":"_customizing_model_deployments","name":"Customizing the parameters of a deployed model-serving runtime","level":1,"index":0,"id":"customizing-parameters-serving-runtime_odh-admin"},{"parentId":"_customizing_model_deployments","name":"Customizable model serving runtime parameters","level":1,"index":1,"id":"customizable-model-serving-runtime-parameters_odh-admin"},{"parentId":"_customizing_model_deployments","name":"Customizing the vLLM model-serving runtime","level":1,"index":2,"id":"Customizing-the-vllm-runtime_odh-admin"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/creating-and-importing-jupyter-notebooks/"},"sections":[{"parentId":null,"name":"Creating a Jupyter notebook","level":1,"index":0,"id":"creating-a-jupyter-notebook_{context}"},{"parentId":null,"name":"Uploading an existing notebook file to JupyterLab from local storage","level":1,"index":1,"id":"uploading-an-existing-notebook-file-to-jupyterlab-from-local-storage_{context}"},{"parentId":null,"name":"Deleting files into the trash directory of your workbench in Jupyter notebooks","level":1,"index":2,"id":"deleting-files-in-trash-directory_{context}"},{"parentId":"deleting-files-in-trash-directory_{context}","name":"Emptying the trash directory of your workbench in Jupyter notebooks","level":2,"index":0,"id":"emptying-trash-directory_{context}"},{"parentId":null,"name":"Additional resources","level":1,"index":3,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/creating-code-server-workbenches/"},"sections":[{"parentId":null,"name":"Creating a workbench","level":1,"index":0,"id":"creating-a-project-workbench_{context}"},{"parentId":null,"name":"Uploading an existing notebook file to code-server from local storage","level":1,"index":1,"id":"uploading-an-existing-notebook-file-to-code-server-from-local-storage_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/creating-custom-workbench-images/"},"sections":[{"parentId":null,"name":"Creating a custom image from a default {productname-short} image","level":1,"index":0,"id":"creating-a-custom-image-from-default-image_custom-images"},{"parentId":null,"name":"Creating a custom image from your own image","level":1,"index":1,"id":"creating-a-custom-image-from-your-own-image_custom-images"},{"parentId":"creating-a-custom-image-from-your-own-image_custom-images","name":"Basic guidelines for creating your own workbench image","level":2,"index":0,"id":"_basic_guidelines_for_creating_your_own_workbench_image"},{"parentId":"creating-a-custom-image-from-your-own-image_custom-images","name":"Advanced guidelines for creating your own workbench image","level":2,"index":1,"id":"_advanced_guidelines_for_creating_your_own_workbench_image"},{"parentId":null,"name":"Enabling custom images in {productname-short}","level":1,"index":2,"id":"enabling-custom-images_custom-images"},{"parentId":null,"name":"Importing a custom workbench image","level":1,"index":3,"id":"importing-a-custom-workbench-image_custom-images"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/customizing-the-dashboard/"},"sections":[{"parentId":null,"name":"Editing the dashboard configuration","level":1,"index":0,"id":"editing-the-dashboard-configuration_dashboard"},{"parentId":null,"name":"Dashboard configuration options","level":1,"index":1,"id":"ref-dashboard-configuration-options_dashboard"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/customizing-component-deployment-resources/"},"sections":[{"parentId":null,"name":"Overview of component resource customization","level":1,"index":0,"id":"overview-of-component-resource-customization_managing-resources"},{"parentId":null,"name":"Customizing component resources","level":1,"index":1,"id":"customizing-component-resources_managing-resources"},{"parentId":null,"name":"Disabling component resource customization","level":1,"index":2,"id":"disabling-component-resource-customization_managing-resources"},{"parentId":null,"name":"Re-enabling component resource customization","level":1,"index":3,"id":"reenabling-component-resource-customization_managing-resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/customizing-your-feature-store-configuration/"},"sections":[{"parentId":null,"name":"Configuring an offline store","level":1,"index":0,"id":"configuring-an-offline-store_{context}"},{"parentId":null,"name":"Configuring an online store","level":1,"index":1,"id":"configuring-an-online-store_{context}"},{"parentId":null,"name":"Configuring the feature registry","level":1,"index":2,"id":"configuring-the-feature-registry_{context}"},{"parentId":null,"name":"Example PVC configuration","level":1,"index":3,"id":"ref-example-pvc-configuration_{context}"},{"parentId":null,"name":"Editing an existing Feature Store instance","level":1,"index":4,"id":"editing-an-existing-feature-store-instance_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/defining-ml-features/"},"sections":[{"parentId":null,"name":"Setting up your working environment","level":1,"index":0,"id":"setting-up-your-working-environment_{context}"},{"parentId":null,"name":"Enabling automatic authentication and publishing features","level":1,"index":1,"id":"enabling-automatic-authentication-and-publishing-features_{context}"},{"parentId":null,"name":"About feature definitions","level":1,"index":2,"id":"about-feature-definitions_{context}"},{"parentId":null,"name":"Specifying the data source for features","level":1,"index":3,"id":"specifying-the-data-source-for-features_{context}"},{"parentId":null,"name":"About organizing features by using entities","level":1,"index":4,"id":"about-organizing-features-by-using-entities_{context}"},{"parentId":null,"name":"Creating feature views","level":1,"index":5,"id":"creating-feature-views_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/deploying-a-rag-stack-in-a-project/"},"sections":[{"parentId":null,"name":"Overview of RAG","level":1,"index":0,"id":"overview-of-rag_{context}"},{"parentId":"overview-of-rag_{context}","name":"Audience for RAG","level":2,"index":0,"id":"_audience_for_rag"},{"parentId":null,"name":"Overview of vector databases","level":1,"index":1,"id":"overview-of-vector-databases_{context}"},{"parentId":"overview-of-vector-databases_{context}","name":"Overview of Milvus vector databases","level":2,"index":0,"id":"overview-of-milvus-vector-databases_{context}"},{"parentId":"overview-of-vector-databases_{context}","name":"Overview of FAISS vector databases","level":2,"index":1,"id":"overview-of-faiss-vector-databases_{context}"},{"parentId":null,"name":"Deploying a Llama model with KServe","level":1,"index":2,"id":"Deploying-a-llama-model-with-kserve_{context}"},{"parentId":null,"name":"Testing your vLLM model endpoints","level":1,"index":3,"id":"testing-your-vllm-model-endpoints_{context}"},{"parentId":null,"name":"Deploying a remote Milvus vector database","level":1,"index":4,"id":"deploying-a-remote-milvus-vector-database_{context}"},{"parentId":null,"name":"Deploying a LlamaStackDistribution instance","level":1,"index":5,"id":"deploying-a-llamastackdistribution-instance_{context}"},{"parentId":"deploying-a-llamastackdistribution-instance_{context}","name":"Example A: LlamaStackDistribution with <strong>Inline Milvus</strong>","level":2,"index":0,"id":"_example_a_llamastackdistribution_with_inline_milvus"},{"parentId":"deploying-a-llamastackdistribution-instance_{context}","name":"Example B: LlamaStackDistribution with <strong>Remote Milvus</strong>","level":2,"index":1,"id":"_example_b_llamastackdistribution_with_remote_milvus"},{"parentId":"deploying-a-llamastackdistribution-instance_{context}","name":"Example C: LlamaStackDistribution with <strong>Inline FAISS</strong>","level":2,"index":2,"id":"_example_c_llamastackdistribution_with_inline_faiss"},{"parentId":null,"name":"Ingesting content into a Llama model","level":1,"index":6,"id":"ingesting-content-into-a-llama-model_{context}"},{"parentId":null,"name":"Querying ingested content in a Llama model","level":1,"index":7,"id":"querying-ingested-content-in-a-llama-model_{context}"},{"parentId":null,"name":"Preparing documents with Docling for Llama Stack retrieval","level":1,"index":8,"id":"preparing-documents-with-docling-for-llama-stack-retrieval_{context}"},{"parentId":null,"name":"About Llama stack search types","level":1,"index":9,"id":"about-llama-stack-search-types_{context}"},{"parentId":"about-llama-stack-search-types_{context}","name":"Supported search modes","level":2,"index":0,"id":"_supported_search_modes"},{"parentId":"_supported_search_modes","name":"Keyword search","level":3,"index":0,"id":"_keyword_search"},{"parentId":"_supported_search_modes","name":"Vector search","level":3,"index":1,"id":"_vector_search"},{"parentId":"_supported_search_modes","name":"Hybrid search","level":3,"index":2,"id":"_hybrid_search"},{"parentId":"about-llama-stack-search-types_{context}","name":"Retrieval database support","level":2,"index":1,"id":"_retrieval_database_support"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/deploying-models/"},"sections":[{"parentId":null,"name":"Using OCI containers for model storage","level":1,"index":0,"id":"using-oci-containers-for-model-storage_odh-user"},{"parentId":null,"name":"Storing a model in an OCI image","level":1,"index":1,"id":"storing-a-model-in-oci-image_odh-user"},{"parentId":null,"name":"Uploading model files to a Persistent Volume Claim (PVC)","level":1,"index":2,"id":"uploading-model-files-to-pvc_odh-user"},{"parentId":null,"name":"Deploying models","level":0,"index":3,"id":"_deploying_models"},{"parentId":"_deploying_models","name":"Deploying models on the model serving platform","level":1,"index":0,"id":"deploying-models-on-the-model-serving-platform_odh-user"},{"parentId":"_deploying_models","name":"Deploying a model stored in an OCI image by using the CLI","level":1,"index":1,"id":"deploying-model-stored-in-oci-image_odh-user"},{"parentId":"_deploying_models","name":"Deploying models by using {llmd}","level":1,"index":2,"id":"deploying-models-using-distributed-inference_odh-user"},{"parentId":"deploying-models-using-distributed-inference_odh-user","name":"Configuring authentication for {llmd} using {org-name} Connectivity Link","level":2,"index":0,"id":"configuring-authentication-for-llmd_odh-user"},{"parentId":"deploying-models-using-distributed-inference_odh-user","name":"Enabling {llmd}","level":2,"index":1,"id":"enabling-distributed-inference_odh-user"},{"parentId":"deploying-models-using-distributed-inference_odh-user","name":"Example usage for {llmd}","level":2,"index":2,"id":"ref-example-distributed-inference_odh-user"},{"parentId":"ref-example-distributed-inference_odh-user","name":"Single-node GPU deployment","level":3,"index":0,"id":"_single_node_gpu_deployment"},{"parentId":"ref-example-distributed-inference_odh-user","name":"Multi-node deployment","level":3,"index":1,"id":"_multi_node_deployment"},{"parentId":"ref-example-distributed-inference_odh-user","name":"Intelligent inference scheduler with KV cache routing","level":3,"index":2,"id":"_intelligent_inference_scheduler_with_kv_cache_routing"},{"parentId":"deploying-models-using-distributed-inference_odh-user","name":"Configuring authentication for {llmd} using {org-name} Connectivity Link","level":2,"index":3,"id":"configuring-authentication-for-llmd_odh-user"},{"parentId":"_deploying_models","name":"Monitoring models","level":1,"index":3,"id":"_monitoring_models"},{"parentId":"_monitoring_models","name":"Viewing performance metrics for a deployed model","level":2,"index":0,"id":"viewing-performance-metrics-for-deployed-model_odh-user"},{"parentId":"_monitoring_models","name":"Viewing model-serving runtime metrics for the model serving platform","level":2,"index":1,"id":"viewing-metrics-for-the-model-serving-platform_odh-user"},{"parentId":null,"name":"Deploying models on the NVIDIA NIM model serving platform","level":0,"index":4,"id":"_deploying_models_on_the_nvidia_nim_model_serving_platform"},{"parentId":"_deploying_models_on_the_nvidia_nim_model_serving_platform","name":"Deploying models on the NVIDIA NIM model serving platform","level":1,"index":0,"id":"deploying-models-on-the-NVIDIA-NIM-model-serving-platform_odh-user"},{"parentId":"_deploying_models_on_the_nvidia_nim_model_serving_platform","name":"Viewing NVIDIA NIM metrics for a NIM model","level":1,"index":1,"id":"viewing-nvidia-nim-metrics-for-a-nim-model_odh-user"},{"parentId":"_deploying_models_on_the_nvidia_nim_model_serving_platform","name":"Viewing performance metrics for a NIM model","level":1,"index":2,"id":"viewing-performance-metrics-for-a-nim-model_odh-user"},{"parentId":null,"name":"Making inference requests to deployed models","level":0,"index":5,"id":"_making_inference_requests_to_deployed_models"},{"parentId":"_making_inference_requests_to_deployed_models","name":"Accessing the authentication token for a deployed model","level":1,"index":0,"id":"accessing-authentication-token-for-deployed-model_odh-user"},{"parentId":"_making_inference_requests_to_deployed_models","name":"Accessing the inference endpoint for a deployed model","level":1,"index":1,"id":"accessing-inference-endpoint-for-model_odh-user"},{"parentId":"_making_inference_requests_to_deployed_models","name":"Making inference requests to models deployed on the model serving platform","level":1,"index":2,"id":"making-inference-requests-to-models-deployed-on-model-serving-platform_odh-user"},{"parentId":"_making_inference_requests_to_deployed_models","name":"Inference endpoints","level":1,"index":3,"id":"inference-endpoints_odh-user"},{"parentId":"inference-endpoints_odh-user","name":"Caikit TGIS ServingRuntime for KServe","level":2,"index":0,"id":"_caikit_tgis_servingruntime_for_kserve"},{"parentId":"inference-endpoints_odh-user","name":"OpenVINO Model Server","level":2,"index":1,"id":"_openvino_model_server"},{"parentId":"inference-endpoints_odh-user","name":"vLLM NVIDIA GPU ServingRuntime for KServe","level":2,"index":2,"id":"_vllm_nvidia_gpu_servingruntime_for_kserve"},{"parentId":"inference-endpoints_odh-user","name":"vLLM Intel Gaudi Accelerator ServingRuntime for KServe","level":2,"index":3,"id":"_vllm_intel_gaudi_accelerator_servingruntime_for_kserve"},{"parentId":"inference-endpoints_odh-user","name":"vLLM AMD GPU ServingRuntime for KServe","level":2,"index":4,"id":"_vllm_amd_gpu_servingruntime_for_kserve"},{"parentId":"inference-endpoints_odh-user","name":"vLLM Spyre AI Accelerator ServingRuntime for KServe","level":2,"index":5,"id":"_vllm_spyre_ai_accelerator_servingruntime_for_kserve"},{"parentId":"inference-endpoints_odh-user","name":"vLLM Spyre s390x ServingRuntime for KServe","level":2,"index":6,"id":"_vllm_spyre_s390x_servingruntime_for_kserve"},{"parentId":"inference-endpoints_odh-user","name":"NVIDIA Triton Inference Server","level":2,"index":7,"id":"_nvidia_triton_inference_server"},{"parentId":"inference-endpoints_odh-user","name":"Seldon MLServer","level":2,"index":8,"id":"_seldon_mlserver"},{"parentId":"inference-endpoints_odh-user","name":"Additional resources","level":2,"index":9,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/enabling-ai-safety-with-guardrails/"},"sections":[{"parentId":null,"name":"Understanding detectors","level":1,"index":0,"id":"guardrails-detectors_{context}"},{"parentId":"guardrails-detectors_{context}","name":"Built-in Detector","level":2,"index":0,"id":"_built_in_detector"},{"parentId":"guardrails-detectors_{context}","name":"The Hugging Face Detector serving runtime","level":2,"index":1,"id":"guardrails-configuring-the-hugging-face-detector-serving-runtime_{context}"},{"parentId":"guardrails-configuring-the-hugging-face-detector-serving-runtime_{context}","name":"Guardrails Detector Hugging Face serving runtime configuration values","level":3,"index":0,"id":"_guardrails_detector_hugging_face_serving_runtime_configuration_values"},{"parentId":null,"name":"Orchestrator Configuration Parameters","level":1,"index":1,"id":"guardrails-orchestrator-config-parameters_{context}"},{"parentId":null,"name":"Guardrails Gateway Config Parameters","level":1,"index":2,"id":"guardrails-gateway-config-parameters_{context}"},{"parentId":null,"name":"Deploying the Guardrails Orchestrator","level":1,"index":3,"id":"deploying-the-guardrails-orchestrator-service_{context}"},{"parentId":null,"name":"Auto-configuring Guardrails","level":1,"index":4,"id":"guardrails-auto-config_{context}"},{"parentId":null,"name":"Configuring the OpenTelemetry exporter","level":1,"index":5,"id":"configuring-the-opentelemetry-exporter_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/enabling-accelerators/"},"sections":[{"parentId":null,"name":"Enabling NVIDIA GPUs","level":1,"index":0,"id":"enabling-nvidia-gpus_managing-odh"},{"parentId":null,"name":"Intel Gaudi AI Accelerator integration","level":1,"index":1,"id":"intel-gaudi-ai-accelerator-integration_managing-odh"},{"parentId":"intel-gaudi-ai-accelerator-integration_managing-odh","name":"Enabling Intel Gaudi AI accelerators","level":2,"index":0,"id":"enabling-intel-gaudi-ai-accelerators_managing-odh"},{"parentId":null,"name":"AMD GPU Integration","level":1,"index":2,"id":"amd-gpu-integration_managing-odh"},{"parentId":"amd-gpu-integration_managing-odh","name":"Verifying AMD GPU availability on your cluster","level":2,"index":0,"id":"verifying-amd-gpu-availability-on-your-cluster_managing-odh"},{"parentId":"amd-gpu-integration_managing-odh","name":"Enabling AMD GPUs","level":2,"index":1,"id":"enabling-amd-gpus_managing-odh"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/enforcing-local-queues/"},"sections":[{"parentId":null,"name":"Enforcing the local-queue labeling policy for all projects","level":1,"index":0,"id":"enforcing-lqlabel-all_{context}"},{"parentId":null,"name":"Disabling the local-queue labeling policy for all projects","level":1,"index":1,"id":"disabling-lqlabel-all_{context}"},{"parentId":null,"name":"Enforcing the local-queue labeling policy for some projects only","level":1,"index":2,"id":"enforcing-lqlabel-some_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/enabling-external-resource-access-for-lmeval-jobs/"},"sections":[{"parentId":null,"name":"Enabling online access and remote code execution for LMEval Jobs using the CLI","level":1,"index":0,"id":"enabling-online-access-and-remote-code-execution-LMEvalJob-using-the-cli_{context}"},{"parentId":null,"name":"Updating LMEval job configuration using the web console","level":1,"index":1,"id":"updating-lmeval-job-configuration-using-the-web-console_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/evaluating-large-language-models/"},"sections":[{"parentId":null,"name":"Setting up LM-Eval","level":1,"index":0,"id":"setting-up-lmeval_{context}"},{"parentId":null,"name":"Enabling external resource access for LMEval jobs","level":1,"index":1,"id":"enabling-external-resource-access-for-lmeval-jobs_{context}"},{"parentId":"enabling-external-resource-access-for-lmeval-jobs_{context}","name":"Enabling online access and remote code execution for LMEval Jobs using the CLI","level":2,"index":0,"id":"enabling-online-access-and-remote-code-execution-LMEvalJob-using-the-cli_{context}"},{"parentId":"enabling-external-resource-access-for-lmeval-jobs_{context}","name":"Updating LMEval job configuration using the web console","level":2,"index":1,"id":"updating-lmeval-job-configuration-using-the-web-console_{context}"},{"parentId":null,"name":"LM-Eval evaluation job","level":1,"index":2,"id":"lmeval-evaluation-job_{context}"},{"parentId":null,"name":"LM-Eval evaluation job properties","level":1,"index":3,"id":"lmeval-evaluation-job-properties_{context}"},{"parentId":"lmeval-evaluation-job-properties_{context}","name":"Properties for setting up custom Unitxt cards, templates, or system prompts","level":2,"index":0,"id":"_properties_for_setting_up_custom_unitxt_cards_templates_or_system_prompts"},{"parentId":null,"name":"Performing model evaluations in the dashboard","level":1,"index":4,"id":"performing-model-evaluations-in-the-dashboard_{context}"},{"parentId":null,"name":"LM-Eval scenarios","level":1,"index":5,"id":"lmeval-scenarios_{context}"},{"parentId":"lmeval-scenarios_{context}","name":"Accessing Hugging Face models with an environment variable token","level":2,"index":0,"id":"accessing-hugging-face-models-with-an-environment-variable-token_{context}"},{"parentId":"lmeval-scenarios_{context}","name":"Using a custom Unitxt card","level":2,"index":1,"id":"using-a-custom-unitxt-card_{context}"},{"parentId":"lmeval-scenarios_{context}","name":"Using PVCs as storage","level":2,"index":2,"id":"using-pvcs-as-storage_{context}"},{"parentId":"using-pvcs-as-storage_{context}","name":"Managed PVCs","level":3,"index":0,"id":"_managed_pvcs"},{"parentId":"using-pvcs-as-storage_{context}","name":"Existing PVCs","level":3,"index":1,"id":"_existing_pvcs"},{"parentId":"lmeval-scenarios_{context}","name":"Using a KServe Inference Service","level":2,"index":3,"id":"using-a-kserve-inference-service_{context}"},{"parentId":"lmeval-scenarios_{context}","name":"Setting up LM-Eval S3 Support","level":2,"index":4,"id":"setting-up-lmeval-s3-support_{context}"},{"parentId":"lmeval-scenarios_{context}","name":"Using LLM-as-a-Judge metrics with LM-Eval","level":2,"index":5,"id":"using-llm-as-a-judge-metrics-with-lmeval_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/evaluating-rag-systems-with-llama-stack/"},"sections":[{"parentId":null,"name":"Understanding RAG evaluation providers","level":1,"index":0,"id":"understanding-rag-evaluation-providers_{context}"},{"parentId":null,"name":"Using Ragas with Llama Stack","level":1,"index":1,"id":"using-ragas-with-llama-stack_{context}"},{"parentId":null,"name":"Benchmarking embedding models with BEIR datasets and Llama Stack","level":1,"index":2,"id":"benchmarking-embedding-models-with-BEIR-datasets-and-Llama-Stack_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/example-kfto-pytorch-training-scripts/"},"sections":[{"parentId":null,"name":"Example Training Operator PyTorch training script: NCCL","level":1,"index":0,"id":"ref-example-kfto-pytorch-training-script-nccl{context}"},{"parentId":null,"name":"Example Training Operator PyTorch training script: DDP","level":1,"index":1,"id":"ref-example-kfto-pytorch-training-script-ddp_{context}"},{"parentId":null,"name":"Example Training Operator PyTorch training script: FSDP","level":1,"index":2,"id":"ref-example-kfto-pytorch-training-script-fsdp_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/evaluating-rag-systems/"},"sections":[{"parentId":null,"name":"About Ragas evaluation","level":1,"index":0,"id":"_about_ragas_evaluation"},{"parentId":"_about_ragas_evaluation","name":"Key Ragas metrics","level":2,"index":0,"id":"_key_ragas_metrics"},{"parentId":"_about_ragas_evaluation","name":"Use cases for Ragas in AI engineering workflows","level":2,"index":1,"id":"_use_cases_for_ragas_in_ai_engineering_workflows"},{"parentId":"_about_ragas_evaluation","name":"Ragas provider deployment modes","level":2,"index":2,"id":"_ragas_provider_deployment_modes"},{"parentId":null,"name":"Setting up the Ragas inline provider for development","level":1,"index":1,"id":"setting-up-ragas-inline-provider_{context}"},{"parentId":null,"name":"Configuring the Ragas remote provider for production","level":1,"index":2,"id":"configuring-ragas-remote-provider-for-production_{context}"},{"parentId":null,"name":"Evaluating RAG system quality with Ragas metrics","level":1,"index":3,"id":"evaluating-rag-system-quality-with-ragas_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/experimenting-with-models-in-the-gen-ai-playground/"},"sections":[{"parentId":null,"name":"Playground overview","level":1,"index":0,"id":"playground-overview_rhoai-user"},{"parentId":"playground-overview_rhoai-user","name":"Core capabilities","level":2,"index":0,"id":"_core_capabilities"},{"parentId":null,"name":"Playground prerequisites","level":1,"index":1,"id":"playground-prerequisites_rhoai-user"},{"parentId":"playground-prerequisites_rhoai-user","name":"Cluster administrator prerequisites","level":2,"index":0,"id":"_cluster_administrator_prerequisites"},{"parentId":"playground-prerequisites_rhoai-user","name":"User prerequisites","level":2,"index":1,"id":"_user_prerequisites"},{"parentId":"playground-prerequisites_rhoai-user","name":"Model and runtime requirements for the playground","level":2,"index":2,"id":"_model_and_runtime_requirements_for_the_playground"},{"parentId":"_model_and_runtime_requirements_for_the_playground","name":"Key model selection factors","level":3,"index":0,"id":"_key_model_selection_factors"},{"parentId":"_model_and_runtime_requirements_for_the_playground","name":"Example model configuration","level":3,"index":1,"id":"_example_model_configuration"},{"parentId":"playground-prerequisites_rhoai-user","name":"Configuring Model Control Protocol (MCP) servers","level":2,"index":3,"id":"configuring-model-control-protocol-servers_rhoai-user"},{"parentId":null,"name":"About the AI assets endpoint page","level":1,"index":2,"id":"About-the-ai-assets-endpoint-page_rhoai-user"},{"parentId":null,"name":"Configuring a playground for your project","level":1,"index":3,"id":"configuring-a-playground-for-your-project_rhoai-user"},{"parentId":null,"name":"Testing baseline model responses","level":1,"index":4,"id":"testing-baseline-model-responses_rhoai-user"},{"parentId":null,"name":"Testing your model with retrieval augmented generation (RAG)","level":1,"index":5,"id":"testing-your-model-with-rag_rhoai-user"},{"parentId":"testing-your-model-with-rag_rhoai-user","name":"Understanding RAG settings","level":2,"index":0,"id":"understanding-rag-settings_rhoai-user"},{"parentId":null,"name":"Testing with model control protocol (MCP) servers","level":1,"index":6,"id":"testing-with-model-control-protocol-servers_rhoai-user"},{"parentId":null,"name":"Exporting your playground configuration","level":1,"index":7,"id":"exporting-your-playground-configuration_rhoai-user"},{"parentId":null,"name":"Updating your playground configuration","level":1,"index":8,"id":"updating-your-playground-configuration_rhoai-user"},{"parentId":null,"name":"Deleting a playground from your project","level":1,"index":9,"id":"Deleting-a-playground-from-your-project_rhoai-user"},{"parentId":null,"name":"Next steps","level":1,"index":10,"id":"next-steps_rhoai-user"},{"parentId":null,"name":"Troubleshooting playground issues","level":1,"index":11,"id":"troubleshooting-playground-issues_rhoai-user"},{"parentId":"troubleshooting-playground-issues_rhoai-user","name":"The chatbot thinks indefinitely","level":2,"index":0,"id":"_the_chatbot_thinks_indefinitely"},{"parentId":"troubleshooting-playground-issues_rhoai-user","name":"The model does not use RAG data","level":2,"index":1,"id":"_the_model_does_not_use_rag_data"},{"parentId":"troubleshooting-playground-issues_rhoai-user","name":"MCP servers are missing from the UI","level":2,"index":2,"id":"_mcp_servers_are_missing_from_the_ui"},{"parentId":"troubleshooting-playground-issues_rhoai-user","name":"The model fails to call MCP tools","level":2,"index":3,"id":"_the_model_fails_to_call_mcp_tools"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/fine-tuning-a-model-by-using-kubeflow-training/"},"sections":[{"parentId":null,"name":"Configuring the fine-tuning job","level":1,"index":0,"id":"configuring-the-fine-tuning-job_{context}"},{"parentId":null,"name":"Running the fine-tuning job","level":1,"index":1,"id":"running-the-fine-tuning-job_{context}"},{"parentId":null,"name":"Deleting the fine-tuning job","level":1,"index":2,"id":"deleting-the-fine-tuning-job_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/generate-synthetic-data/"},"sections":[{"parentId":null,"name":"Explore the SDG Hub examples","level":1,"index":0,"id":"explore-the-sdg-hub-examples_{context}"},{"parentId":null,"name":"Guided example - Build a KFP pipeline for SDG","level":1,"index":1,"id":"guided-example-build-a-kfp-pipeline-for-sdg_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/installing-odh-v1/"},"sections":[{"parentId":null,"name":"Installing the Open Data Hub Operator version 1","level":1,"index":0,"id":"installing-the-odh-operator-v1_installv1"},{"parentId":null,"name":"Creating a new project for your Open Data Hub instance","level":1,"index":1,"id":"creating-a-new-project-for-your-odh-instance_installv1"},{"parentId":null,"name":"Adding an Open Data Hub instance","level":1,"index":2,"id":"adding-an-odh-instance_installv1"},{"parentId":null,"name":"Accessing the dashboard","level":1,"index":3,"id":"accessing-the-dashboard_installv1"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/installing-odh-v2/"},"sections":[{"parentId":null,"name":"Configuring custom namespaces","level":1,"index":0,"id":"configuring-custom-namespaces"},{"parentId":null,"name":"Installing the Open Data Hub Operator version 2","level":1,"index":1,"id":"installing-the-odh-operator-v2_installv2"},{"parentId":null,"name":"Installing Open Data Hub components","level":1,"index":2,"id":"installing-odh-components_installv2"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/lmeval-scenarios/"},"sections":[{"parentId":null,"name":"Accessing Hugging Face models with an environment variable token","level":1,"index":0,"id":"accessing-hugging-face-models-with-an-environment-variable-token_{context}"},{"parentId":null,"name":"Using a custom Unitxt card","level":1,"index":1,"id":"using-a-custom-unitxt-card_{context}"},{"parentId":null,"name":"Using PVCs as storage","level":1,"index":2,"id":"using-pvcs-as-storage_{context}"},{"parentId":"using-pvcs-as-storage_{context}","name":"Managed PVCs","level":2,"index":0,"id":"_managed_pvcs"},{"parentId":"using-pvcs-as-storage_{context}","name":"Existing PVCs","level":2,"index":1,"id":"_existing_pvcs"},{"parentId":null,"name":"Using a KServe Inference Service","level":1,"index":3,"id":"using-a-kserve-inference-service_{context}"},{"parentId":null,"name":"Setting up LM-Eval S3 Support","level":1,"index":4,"id":"setting-up-lmeval-s3-support_{context}"},{"parentId":null,"name":"Using LLM-as-a-Judge metrics with LM-Eval","level":1,"index":5,"id":"using-llm-as-a-judge-metrics-with-lmeval_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-access-to-projects/"},"sections":[{"parentId":null,"name":"Granting access to a project","level":1,"index":0,"id":"granting-access-to-a-project_{context}"},{"parentId":null,"name":"Updating access to a project","level":1,"index":1,"id":"updating-access-to-a-project_{context}"},{"parentId":null,"name":"Removing access to a project","level":1,"index":2,"id":"removing-access-to-a-project_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-ai-pipelines/"},"sections":[{"parentId":null,"name":"Configuring a pipeline server","level":1,"index":0,"id":"configuring-a-pipeline-server_{context}"},{"parentId":"configuring-a-pipeline-server_{context}","name":"Configuring a pipeline server with an external Amazon RDS database","level":2,"index":0,"id":"configuring-a-pipeline-server-with-an-external-amazon-rds-db_{context}"},{"parentId":null,"name":"Defining a pipeline","level":1,"index":1,"id":"defining-a-pipeline_{context}"},{"parentId":"defining-a-pipeline_{context}","name":"Compiling the pipeline YAML with the Kubeflow Pipelines SDK","level":2,"index":0,"id":"compiling-the-pipeline-yaml-with-kfp-sdk_{context}"},{"parentId":"defining-a-pipeline_{context}","name":"Compiling Kubernetes-native manifests with the Kubeflow Pipelines SDK","level":2,"index":1,"id":"compiling-kubernetes-native-manifests-with-kfp-sdk_{context}"},{"parentId":"defining-a-pipeline_{context}","name":"Authenticating the Kubeflow Pipelines SDK with a pipeline server","level":2,"index":2,"id":"authenticating-kfp-sdk-with-pipeline-server_{context}"},{"parentId":"defining-a-pipeline_{context}","name":"Defining a pipeline by using the Kubernetes API","level":2,"index":3,"id":"defining-a-pipeline-by-using-the-kubernetes-api_{context}"},{"parentId":"defining-a-pipeline_{context}","name":"Migrating pipelines from database to Kubernetes API storage","level":2,"index":4,"id":"migrating-pipelines-from-database-to-kubernetes-api_{context}"},{"parentId":null,"name":"Importing a pipeline","level":1,"index":2,"id":"importing-a-pipeline_{context}"},{"parentId":null,"name":"Deleting a pipeline","level":1,"index":3,"id":"deleting-a-pipeline_{context}"},{"parentId":null,"name":"Deleting a pipeline server","level":1,"index":4,"id":"deleting-a-pipeline-server_{context}"},{"parentId":null,"name":"Viewing the details of a pipeline server","level":1,"index":5,"id":"viewing-the-details-of-a-pipeline-server_{context}"},{"parentId":null,"name":"Viewing existing pipelines","level":1,"index":6,"id":"viewing-existing-pipelines_{context}"},{"parentId":null,"name":"Overview of pipeline versions","level":1,"index":7,"id":"overview-of-pipeline-versions_{context}"},{"parentId":null,"name":"Uploading a pipeline version","level":1,"index":8,"id":"uploading-a-pipeline-version_{context}"},{"parentId":null,"name":"Deleting a pipeline version","level":1,"index":9,"id":"deleting-a-pipeline-version_{context}"},{"parentId":null,"name":"Viewing the details of a pipeline version","level":1,"index":10,"id":"viewing-the-details-of-a-pipeline-version_{context}"},{"parentId":null,"name":"Downloading a pipeline version","level":1,"index":11,"id":"downloading-a-pipeline-version_{context}"},{"parentId":null,"name":"Overview of pipelines caching","level":1,"index":12,"id":"overview-of-pipelines-caching_{context}"},{"parentId":"overview-of-pipelines-caching_{context}","name":"Caching criteria","level":2,"index":0,"id":"_caching_criteria"},{"parentId":"overview-of-pipelines-caching_{context}","name":"Viewing cached steps in the {productname-short} user interface","level":2,"index":1,"id":"_viewing_cached_steps_in_the_productname_short_user_interface"},{"parentId":"overview-of-pipelines-caching_{context}","name":"Controlling caching in pipelines","level":2,"index":2,"id":"controlling-caching-in-pipelines_{context}"},{"parentId":"controlling-caching-in-pipelines_{context}","name":"Disabling caching for individual tasks","level":3,"index":0,"id":"_disabling_caching_for_individual_tasks"},{"parentId":"controlling-caching-in-pipelines_{context}","name":"Disabling caching for a pipeline at submit time","level":3,"index":1,"id":"_disabling_caching_for_a_pipeline_at_submit_time"},{"parentId":"controlling-caching-in-pipelines_{context}","name":"Disabling caching for a pipeline at compile time","level":3,"index":2,"id":"_disabling_caching_for_a_pipeline_at_compile_time"},{"parentId":"controlling-caching-in-pipelines_{context}","name":"Disabling caching for all pipelines (pipeline server)","level":3,"index":3,"id":"_disabling_caching_for_all_pipelines_pipeline_server"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-applications-that-show-in-the-dashboard/"},"sections":[{"parentId":null,"name":"Adding an application to the dashboard","level":1,"index":0,"id":"adding-an-application-to-the-dashboard_dashboard"},{"parentId":null,"name":"Preventing users from adding applications to the dashboard","level":1,"index":1,"id":"preventing-users-from-adding-applications-to-the-dashboard_dashboard"},{"parentId":null,"name":"Disabling applications connected to {productname-short}","level":1,"index":2,"id":"disabling-applications-connected_dashboard"},{"parentId":null,"name":"Showing or hiding information about available applications","level":1,"index":3,"id":"showing-hiding-information-about-available-applications_dashboard"},{"parentId":null,"name":"Hiding the default basic workbench application","level":1,"index":4,"id":"hiding-the-default-basic-workbench-application_dashboard"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-and-monitoring-models/"},"sections":[{"parentId":null,"name":"Adding a custom model-serving runtime","level":1,"index":0,"id":"adding-a-custom-model-serving-runtime_cluster-admin"},{"parentId":null,"name":"Managing and monitoring models","level":0,"index":1,"id":"_managing_and_monitoring_models"},{"parentId":"_managing_and_monitoring_models","name":"Setting a timeout for KServe","level":1,"index":0,"id":"setting-timeout-for-kserve_cluster-admin"},{"parentId":"_managing_and_monitoring_models","name":"Deploying models by using multiple GPU nodes","level":1,"index":1,"id":"deploying-models-using-multiple-gpu-nodes_cluster-admin"},{"parentId":"_managing_and_monitoring_models","name":"Configuring an inference service for Kueue","level":1,"index":2,"id":"configuring-an-inference-service-for-kueue_cluster-admin"},{"parentId":"_managing_and_monitoring_models","name":"Configuring an inference service for Spyre","level":1,"index":3,"id":"configuring-inference-service-for-spyre_cluster-admin"},{"parentId":"_managing_and_monitoring_models","name":"Optimizing performance and tuning","level":1,"index":4,"id":"_optimizing_performance_and_tuning"},{"parentId":"_optimizing_performance_and_tuning","name":"Determining GPU requirements for LLM-powered applications","level":2,"index":0,"id":"determining-gpu-requirements-for-llm-powered-applications_cluster-admin"},{"parentId":"_optimizing_performance_and_tuning","name":"Performance considerations for text-summarization and retrieval-augmented generation (RAG) applications","level":2,"index":1,"id":"performance-considerations-for-document-based-apps_cluster-admin"},{"parentId":"_optimizing_performance_and_tuning","name":"Inference performance metrics","level":2,"index":2,"id":"inference-performance-metrics_cluster-admin"},{"parentId":"inference-performance-metrics_cluster-admin","name":"Latency","level":3,"index":0,"id":"_latency"},{"parentId":"inference-performance-metrics_cluster-admin","name":"Throughput","level":3,"index":1,"id":"_throughput"},{"parentId":"inference-performance-metrics_cluster-admin","name":"Cost per million tokens","level":3,"index":2,"id":"_cost_per_million_tokens"},{"parentId":"_optimizing_performance_and_tuning","name":"Configuring metrics-based autoscaling","level":2,"index":3,"id":"configuring-metrics-based-autoscaling_cluster-admin"},{"parentId":"_optimizing_performance_and_tuning","name":"Guidelines for metrics-based autoscaling","level":2,"index":4,"id":"guidelines-for-metrics-based-autoscaling_cluster-admin"},{"parentId":"guidelines-for-metrics-based-autoscaling_cluster-admin","name":"Choosing metrics for latency and throughput-optimized scaling","level":3,"index":0,"id":"_choosing_metrics_for_latency_and_throughput_optimized_scaling"},{"parentId":"guidelines-for-metrics-based-autoscaling_cluster-admin","name":"Choosing the right sliding window","level":3,"index":1,"id":"_choosing_the_right_sliding_window"},{"parentId":"guidelines-for-metrics-based-autoscaling_cluster-admin","name":"Optimizing HPA scale-down configuration","level":3,"index":2,"id":"_optimizing_hpa_scale_down_configuration"},{"parentId":"guidelines-for-metrics-based-autoscaling_cluster-admin","name":"Considering model size for optimal scaling","level":3,"index":3,"id":"_considering_model_size_for_optimal_scaling"},{"parentId":"_managing_and_monitoring_models","name":"Monitoring models","level":1,"index":5,"id":"_monitoring_models"},{"parentId":"_monitoring_models","name":"Configuring monitoring for the model serving platform","level":2,"index":0,"id":"configuring-monitoring-for-the-model-serving-platform_cluster-admin"},{"parentId":"_managing_and_monitoring_models","name":"Using Grafana to monitor model performance","level":1,"index":6,"id":"_using_grafana_to_monitor_model_performance"},{"parentId":"_using_grafana_to_monitor_model_performance","name":"Deploying a Grafana metrics dashboard","level":2,"index":0,"id":"deploying-a-grafana-metrics-dashboard_cluster-admin"},{"parentId":"_using_grafana_to_monitor_model_performance","name":"Deploying a vLLM/GPU metrics dashboard on a Grafana instance","level":2,"index":1,"id":"deploying-vllm-gpu-metrics-dashboard-grafana_cluster-admin"},{"parentId":"_using_grafana_to_monitor_model_performance","name":"Grafana metrics","level":2,"index":2,"id":"ref-grafana-metrics_cluster-admin"},{"parentId":"ref-grafana-metrics_cluster-admin","name":"Accelerator metrics","level":3,"index":0,"id":"ref-accelerator-metrics_cluster-admin"},{"parentId":"ref-grafana-metrics_cluster-admin","name":"CPU metrics","level":3,"index":1,"id":"ref-cpu-metrics_cluster-admin"},{"parentId":"ref-grafana-metrics_cluster-admin","name":"vLLM metrics","level":3,"index":2,"id":"ref-vllm-metrics_cluster-admin"},{"parentId":null,"name":"Managing and monitoring models on the NVIDIA NIM model serving platform","level":0,"index":2,"id":"_managing_and_monitoring_models_on_the_nvidia_nim_model_serving_platform"},{"parentId":"_managing_and_monitoring_models_on_the_nvidia_nim_model_serving_platform","name":"Customizing model selection options for the NVIDIA NIM model serving platform","level":1,"index":0,"id":"Customizing-model-selection-options_cluster-admin"},{"parentId":"_managing_and_monitoring_models_on_the_nvidia_nim_model_serving_platform","name":"Enabling NVIDIA NIM metrics for an existing NIM deployment","level":1,"index":1,"id":"enabling-nim-metrics-for-an-existing-nim-deployment_cluster-admin"},{"parentId":"enabling-nim-metrics-for-an-existing-nim-deployment_cluster-admin","name":"Enabling graph generation for an existing NIM deployment","level":2,"index":0,"id":"_enabling_graph_generation_for_an_existing_nim_deployment"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-basic-workbenches/"},"sections":[{"parentId":null,"name":"Accessing the administration interface for basic workbenches","level":1,"index":0,"id":"accessing-the-administration-interface-for-basic-workbenches_{context}"},{"parentId":null,"name":"Starting basic workbenches owned by other users","level":1,"index":1,"id":"starting-basic-workbenches-owned-by-other-users_{context}"},{"parentId":null,"name":"Accessing basic workbenches owned by other users","level":1,"index":2,"id":"accessing-basic-workbenches-owned-by-other-users_{context}"},{"parentId":null,"name":"Stopping basic workbenches owned by other users","level":1,"index":3,"id":"stopping-basic-workbenches-owned-by-other-users_{context}"},{"parentId":null,"name":"Stopping idle workbenches","level":1,"index":4,"id":"stopping-idle-workbenches_{context}"},{"parentId":null,"name":"Adding workbench pod tolerations","level":1,"index":5,"id":"adding-workbench-pod-tolerations_{context}"},{"parentId":null,"name":"Troubleshooting common problems in workbenches for administrators","level":1,"index":6,"id":"troubleshooting-common-problems-in-workbenches-for-administrators_{context}"},{"parentId":"troubleshooting-common-problems-in-workbenches-for-administrators_{context}","name":"A user receives a <strong>404: Page not found</strong> error when logging in to Jupyter","level":2,"index":0,"id":"_a_user_receives_a_404_page_not_found_error_when_logging_in_to_jupyter"},{"parentId":"troubleshooting-common-problems-in-workbenches-for-administrators_{context}","name":"A user&#8217;s workbench does not start","level":2,"index":1,"id":"_a_users_workbench_does_not_start"},{"parentId":"troubleshooting-common-problems-in-workbenches-for-administrators_{context}","name":"The user receives a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when they run notebook cells","level":2,"index":2,"id":"_the_user_receives_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_they_run_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-cluster-pvc-size/"},"sections":[{"parentId":null,"name":"Configuring the default PVC size for your cluster","level":1,"index":0,"id":"configuring-the-default-pvc-size-for-your-cluster_{context}"},{"parentId":null,"name":"Restoring the default PVC size for your cluster","level":1,"index":1,"id":"restoring-the-default-pvc-size-for-your-cluster_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-connection-types/"},"sections":[{"parentId":null,"name":"Viewing connection types","level":1,"index":0,"id":"viewing-connection-types_{context}"},{"parentId":null,"name":"Creating a connection type","level":1,"index":1,"id":"creating-a-connection-type_{context}"},{"parentId":null,"name":"Duplicating a connection type","level":1,"index":2,"id":"duplicating-a-connection-type_{context}"},{"parentId":null,"name":"Editing a connection type","level":1,"index":3,"id":"editing-a-connection-type_{context}"},{"parentId":null,"name":"Enabling a connection type","level":1,"index":4,"id":"enabling-a-connection-type_{context}"},{"parentId":null,"name":"Deleting a connection type","level":1,"index":5,"id":"deleting-a-connection-type_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-custom-training-images/"},"sections":[{"parentId":null,"name":"About base training images","level":1,"index":0,"id":"about-base-training-images_{context}"},{"parentId":null,"name":"Creating a custom training image","level":1,"index":1,"id":"creating-a-custom-training-image_{context}"},{"parentId":null,"name":"Pushing an image to the integrated OpenShift image registry","level":1,"index":2,"id":"pushing-an-image-to-the-integrated-openshift-image-registry_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-distributed-workloads/"},"sections":[{"parentId":null,"name":"Configuring quota management for distributed workloads","level":1,"index":0,"id":"configuring-quota-management-for-distributed-workloads_{context}"},{"parentId":null,"name":"Example Kueue resource configurations for distributed workloads","level":1,"index":1,"id":"ref-example-kueue-resource-configurations_{context}"},{"parentId":"ref-example-kueue-resource-configurations_{context}","name":"NVIDIA GPUs without shared cohort","level":2,"index":0,"id":"_nvidia_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU resource flavor","level":3,"index":0,"id":"_nvidia_rtx_a400_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU resource flavor","level":3,"index":1,"id":"_nvidia_rtx_a1000_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU cluster queue","level":3,"index":2,"id":"_nvidia_rtx_a400_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU cluster queue","level":3,"index":3,"id":"_nvidia_rtx_a1000_gpu_cluster_queue"},{"parentId":"ref-example-kueue-resource-configurations_{context}","name":"NVIDIA GPUs and AMD GPUs without shared cohort","level":2,"index":1,"id":"_nvidia_gpus_and_amd_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU resource flavor","level":3,"index":0,"id":"_amd_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU resource flavor","level":3,"index":1,"id":"_nvidia_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU cluster queue","level":3,"index":2,"id":"_amd_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU cluster queue","level":3,"index":3,"id":"_nvidia_gpu_cluster_queue"},{"parentId":null,"name":"Configuring a cluster for RDMA","level":1,"index":2,"id":"configuring-a-cluster-for-rdma_{context}"},{"parentId":null,"name":"Troubleshooting common problems with distributed workloads for administrators","level":1,"index":3,"id":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"A user&#8217;s Ray cluster is in a suspended state","level":2,"index":0,"id":"_a_users_ray_cluster_is_in_a_suspended_state"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"A user&#8217;s Ray cluster is in a failed state","level":2,"index":1,"id":"_a_users_ray_cluster_is_in_a_failed_state"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"A user&#8217;s Ray cluster does not start","level":2,"index":2,"id":"_a_users_ray_cluster_does_not_start"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"A user cannot create a Ray cluster or submit jobs","level":2,"index":3,"id":"_a_user_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":"troubleshooting-common-problems-with-distributed-workloads-for-administrators_{context}","name":"Additional resources","level":2,"index":4,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-observability/"},"sections":[{"parentId":null,"name":"Enabling the observability stack","level":1,"index":0,"id":"enabling-the-observability-stack_{context}"},{"parentId":null,"name":"Collecting metrics from user workloads","level":1,"index":1,"id":"collecting-metrics-from-user-workloads_{context}"},{"parentId":null,"name":"Exporting metrics to external observability tools","level":1,"index":2,"id":"exporting-metrics-to-external-observability-tools_{context}"},{"parentId":null,"name":"Viewing traces in external tracing platforms","level":1,"index":3,"id":"viewing-traces-in-external-tracing-platforms_{context}"},{"parentId":null,"name":"Accessing built-in alerts","level":1,"index":4,"id":"accessing-built-in-alerts_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-pipeline-experiments/"},"sections":[{"parentId":null,"name":"Overview of pipeline experiments","level":1,"index":0,"id":"overview-of-pipeline-experiments_{context}"},{"parentId":null,"name":"Creating a pipeline experiment","level":1,"index":1,"id":"creating-a-pipeline-experiment_{context}"},{"parentId":null,"name":"Archiving a pipeline experiment","level":1,"index":2,"id":"archiving-a-pipeline-experiment_{context}"},{"parentId":null,"name":"Deleting an archived pipeline experiment","level":1,"index":3,"id":"deleting-an-archived-pipeline-experiment_{context}"},{"parentId":null,"name":"Restoring an archived pipeline experiment","level":1,"index":4,"id":"restoring-an-archived-pipeline-experiment_{context}"},{"parentId":null,"name":"Viewing pipeline task executions","level":1,"index":5,"id":"viewing-pipeline-task-executions_{context}"},{"parentId":null,"name":"Viewing pipeline artifacts","level":1,"index":6,"id":"viewing-pipeline-artifacts_{context}"},{"parentId":null,"name":"Comparing runs in an experiment","level":1,"index":7,"id":"comparing-runs-in-an-experiment_{context}"},{"parentId":null,"name":"Comparing runs in different experiments","level":1,"index":8,"id":"comparing-runs-in-different-experiments_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-pipeline-runs/"},"sections":[{"parentId":null,"name":"Overview of pipeline runs","level":1,"index":0,"id":"overview-of-pipeline-runs_{context}"},{"parentId":null,"name":"Storing data with pipelines","level":1,"index":1,"id":"storing-data-with-pipelines_{context}"},{"parentId":null,"name":"Understanding pipeline run workspaces","level":1,"index":2,"id":"configuring-pipeline-run-workspaces_{context}"},{"parentId":"configuring-pipeline-run-workspaces_{context}","name":"Configuring default workspace PVC settings in DSPA","level":2,"index":0,"id":"configuring-default-workspace-pvc-settings-in-dspa_{context}"},{"parentId":"configuring-pipeline-run-workspaces_{context}","name":"Adding external artifacts to pipeline run workspaces","level":2,"index":1,"id":"adding-external-artifacts-to-pipeline-run-workspaces_{context}"},{"parentId":null,"name":"Viewing active pipeline runs","level":1,"index":3,"id":"viewing-active-pipeline-runs_{context}"},{"parentId":null,"name":"Executing a pipeline run","level":1,"index":4,"id":"executing-a-pipeline-run_{context}"},{"parentId":null,"name":"Stopping an active pipeline run","level":1,"index":5,"id":"stopping-an-active-pipeline-run_{context}"},{"parentId":null,"name":"Duplicating an active pipeline run","level":1,"index":6,"id":"duplicating-an-active-pipeline-run_{context}"},{"parentId":null,"name":"Viewing scheduled pipeline runs","level":1,"index":7,"id":"viewing-scheduled-pipeline-runs_{context}"},{"parentId":null,"name":"Scheduling a pipeline run using a cron job","level":1,"index":8,"id":"scheduling-a-pipeline-run-using-a-cron-job_{context}"},{"parentId":null,"name":"Scheduling a pipeline run","level":1,"index":9,"id":"scheduling-a-pipeline-run_{context}"},{"parentId":null,"name":"Duplicating a scheduled pipeline run","level":1,"index":10,"id":"duplicating-a-scheduled-pipeline-run_{context}"},{"parentId":null,"name":"Deleting a scheduled pipeline run","level":1,"index":11,"id":"deleting-a-scheduled-pipeline-run_{context}"},{"parentId":null,"name":"Viewing the details of a pipeline run","level":1,"index":12,"id":"viewing-the-details-of-a-pipeline-run_{context}"},{"parentId":null,"name":"Viewing archived pipeline runs","level":1,"index":13,"id":"viewing-archived-pipeline-runs_{context}"},{"parentId":null,"name":"Archiving a pipeline run","level":1,"index":14,"id":"archiving-a-pipeline-run_{context}"},{"parentId":null,"name":"Restoring an archived pipeline run","level":1,"index":15,"id":"restoring-an-archived-pipeline-run_{context}"},{"parentId":null,"name":"Deleting an archived pipeline run","level":1,"index":16,"id":"deleting-an-archived-pipeline-run_{context}"},{"parentId":null,"name":"Duplicating an archived pipeline run","level":1,"index":17,"id":"duplicating-an-archived-pipeline-run_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-python-packages-in-code-server/"},"sections":[{"parentId":null,"name":"Viewing Python packages installed on your code-server workbench","level":1,"index":0,"id":"viewing-python-packages-installed-on-your-code-server-workbench_{context}"},{"parentId":null,"name":"Installing Python packages on your code-server workbench","level":1,"index":1,"id":"installing-python-packages-on-your-code-server-workbench_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-python-packages/"},"sections":[{"parentId":null,"name":"Viewing Python packages installed on your workbench","level":1,"index":0,"id":"viewing-python-packages-installed-on-your-workbench_{context}"},{"parentId":null,"name":"Installing Python packages on your workbench","level":1,"index":1,"id":"installing-python-packages-on-your-workbench_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-storage-classes/"},"sections":[{"parentId":null,"name":"About persistent storage","level":1,"index":0,"id":"about-persistent-storage_{context}"},{"parentId":"about-persistent-storage_{context}","name":"Storage classes in {productname-short}","level":2,"index":0,"id":"_storage_classes_in_productname_short"},{"parentId":"about-persistent-storage_{context}","name":"Access modes","level":2,"index":1,"id":"_access_modes"},{"parentId":"_access_modes","name":"Using shared storage (RWX)","level":3,"index":0,"id":"_using_shared_storage_rwx"},{"parentId":null,"name":"Configuring storage class settings","level":1,"index":1,"id":"configuring-storage-class-settings_{context}"},{"parentId":null,"name":"Configuring the default storage class for your cluster","level":1,"index":2,"id":"configuring-the-default-storage-class-for-your-cluster_{context}"},{"parentId":null,"name":"Overview of object storage endpoints","level":1,"index":3,"id":"overview-of-object-storage-endpoints_{context}"},{"parentId":"overview-of-object-storage-endpoints_{context}","name":"MinIO (On-Cluster)","level":2,"index":0,"id":"_minio_on_cluster"},{"parentId":"overview-of-object-storage-endpoints_{context}","name":"Amazon S3","level":2,"index":1,"id":"_amazon_s3"},{"parentId":"overview-of-object-storage-endpoints_{context}","name":"Other S3-Compatible Object Stores","level":2,"index":2,"id":"_other_s3_compatible_object_stores"},{"parentId":"overview-of-object-storage-endpoints_{context}","name":"Verification and Troubleshooting","level":2,"index":3,"id":"_verification_and_troubleshooting"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-users-and-groups/"},"sections":[{"parentId":null,"name":"Overview of user types and permissions","level":1,"index":0,"id":"overview-of-user-types-and-permissions_{context}"},{"parentId":null,"name":"Viewing {productname-short} users","level":1,"index":1,"id":"viewing-data-science-users_{context}"},{"parentId":null,"name":"Adding users to {productname-short} user groups","level":1,"index":2,"id":"adding-users-to-user-groups_{context}"},{"parentId":null,"name":"Selecting {productname-short} administrator and user groups","level":1,"index":3,"id":"selecting-admin-and-user-groups_{context}"},{"parentId":null,"name":"Deleting users","level":1,"index":4,"id":"_deleting_users"},{"parentId":"_deleting_users","name":"About deleting users and their resources","level":2,"index":0,"id":"about-deleting-users-and-resources_{context}"},{"parentId":"_deleting_users","name":"Stopping basic workbenches owned by other users","level":2,"index":1,"id":"stopping-basic-workbenches-owned-by-other-users_{context}"},{"parentId":"_deleting_users","name":"Revoking user access to basic workbenches","level":2,"index":2,"id":"revoking-user-access-to-basic-workbenches_{context}"},{"parentId":"_deleting_users","name":"Backing up storage data","level":2,"index":3,"id":"backing-up-storage-data_{context}"},{"parentId":"_deleting_users","name":"Cleaning up after deleting users","level":2,"index":4,"id":"cleaning-up-after-deleting-users_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/managing-workloads-with-kueue/"},"sections":[{"parentId":null,"name":"Overview of managing workloads with Kueue","level":1,"index":0,"id":"overview-of-managing-workloads-with-kueue_kueue"},{"parentId":"overview-of-managing-workloads-with-kueue_kueue","name":"Kueue management states","level":2,"index":0,"id":"_kueue_management_states"},{"parentId":"overview-of-managing-workloads-with-kueue_kueue","name":"Queue enforcement for projects","level":2,"index":1,"id":"_queue_enforcement_for_projects"},{"parentId":"overview-of-managing-workloads-with-kueue_kueue","name":"Restrictions for managing workloads with Kueue","level":2,"index":2,"id":"_restrictions_for_managing_workloads_with_kueue"},{"parentId":"overview-of-managing-workloads-with-kueue_kueue","name":"Kueue workflow","level":2,"index":3,"id":"kueue-workflow_kueue"},{"parentId":null,"name":"Configuring workload management with Kueue","level":1,"index":1,"id":"configuring-workload-management-with-kueue_kueue"},{"parentId":"configuring-workload-management-with-kueue_kueue","name":"Enabling Kueue in the dashboard","level":2,"index":0,"id":"enabling-kueue-in-the-dashboard_kueue"},{"parentId":null,"name":"Troubleshooting common problems with Kueue","level":1,"index":2,"id":"troubleshooting-common-problems-with-Kueue_kueue"},{"parentId":"troubleshooting-common-problems-with-Kueue_kueue","name":"A user receives a \"failed to call webhook\" error message for Kueue","level":2,"index":0,"id":"_a_user_receives_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":"troubleshooting-common-problems-with-Kueue_kueue","name":"A user receives a \"Default Local Queue &#8230;&#8203; not found\" error message","level":2,"index":1,"id":"_a_user_receives_a_default_local_queue_not_found_error_message"},{"parentId":"troubleshooting-common-problems-with-Kueue_kueue","name":"A user receives a \"local_queue provided does not exist\" error message","level":2,"index":2,"id":"_a_user_receives_a_local_queue_provided_does_not_exist_error_message"},{"parentId":"troubleshooting-common-problems-with-Kueue_kueue","name":"The pod provisioned by Kueue is terminated before the image is pulled","level":2,"index":3,"id":"_the_pod_provisioned_by_kueue_is_terminated_before_the_image_is_pulled"},{"parentId":"troubleshooting-common-problems-with-Kueue_kueue","name":"Additional resources","level":2,"index":4,"id":"_additional_resources"},{"parentId":null,"name":"Migrating to the {rhbok-productname} Operator","level":1,"index":3,"id":"migrating-to-the-rhbok-operator_kueue"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/monitoring-data-drift/"},"sections":[{"parentId":null,"name":"Creating a drift metric","level":1,"index":0,"id":"creating-a-drift-metric_drift-monitoring"},{"parentId":"creating-a-drift-metric_drift-monitoring","name":"Creating a drift metric by using the CLI","level":2,"index":0,"id":"creating-a-drift-metric-using-cli_drift-monitoring"},{"parentId":null,"name":"Deleting a drift metric by using the CLI","level":1,"index":1,"id":"deleting-a-drift-metric-by-using-cli_drift-monitoring"},{"parentId":null,"name":"Viewing drift metrics for a model","level":1,"index":2,"id":"viewing-drift-metrics_drift-monitoring"},{"parentId":null,"name":"Using drift metrics","level":1,"index":3,"id":"using-drift-metrics_drift-monitoring"},{"parentId":null,"name":"Using a drift metric in a credit card scenario","level":1,"index":4,"id":"using-a-drift-metric-in-a-credit-card-scenario_drift-monitoring"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/monitoring-distributed-workloads/"},"sections":[{"parentId":null,"name":"Viewing project metrics for distributed workloads","level":1,"index":0,"id":"viewing-project-metrics-for-distributed-workloads_{context}"},{"parentId":null,"name":"Viewing the status of distributed workloads","level":1,"index":1,"id":"viewing-the-status-of-distributed-workloads_{context}"},{"parentId":null,"name":"Viewing Kueue alerts for distributed workloads","level":1,"index":2,"id":"viewing-kueue-alerts-for-distributed-workloads_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/monitoring-model-bias/"},"sections":[{"parentId":null,"name":"Creating a bias metric","level":1,"index":0,"id":"creating-a-bias-metric_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the dashboard","level":2,"index":0,"id":"creating-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Creating a bias metric by using the CLI","level":2,"index":1,"id":"creating-a-bias-metric-using-cli_bias-monitoring"},{"parentId":"creating-a-bias-metric_bias-monitoring","name":"Duplicating a bias metric","level":2,"index":2,"id":"duplicating-a-bias-metric_bias-monitoring"},{"parentId":null,"name":"Deleting a bias metric","level":1,"index":1,"id":"deleting-a-bias-metric_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the dashboard","level":2,"index":0,"id":"deleting-a-bias-metric-using-dashboard_bias-monitoring"},{"parentId":"deleting-a-bias-metric_bias-monitoring","name":"Deleting a bias metric by using the CLI","level":2,"index":1,"id":"deleting-a-bias-metric-using-cli_bias-monitoring"},{"parentId":null,"name":"Viewing bias metrics for a model","level":1,"index":2,"id":"viewing-bias-metrics_bias-monitoring"},{"parentId":null,"name":"Using bias metrics","level":1,"index":3,"id":"using-bias-metrics_bias-monitoring"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/monitoring-model-performance/"},"sections":[{"parentId":null,"name":"Viewing performance metrics for all models on a model server","level":1,"index":0,"id":"viewing-performance-metrics-for-model-server_monitoring-model-performance"},{"parentId":null,"name":"Viewing HTTP request metrics for a deployed model","level":1,"index":1,"id":"viewing-http-request-metrics-for-a-deployed-model_monitoring-model-performance"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/overview-of-ml-features-and-feature-store/"},"sections":[{"parentId":null,"name":"Audience for Feature Store","level":1,"index":0,"id":"audience-for-feature-store_{context}"},{"parentId":null,"name":"Overview of machine learning features","level":1,"index":1,"id":"overview-of-machine-learning-features_{context}"},{"parentId":null,"name":"Overview of Feature Store","level":1,"index":2,"id":"overview-of-feature-store_{context}"},{"parentId":null,"name":"Feature Store workflow","level":1,"index":3,"id":"feature-store-workflow_{context}"},{"parentId":null,"name":"Setting up the Feature Store user interface for initial use","level":1,"index":4,"id":"setting-up-feature-store-UI_{context}"},{"parentId":null,"name":"Additional resources","level":1,"index":5,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/prepare-your-data-for-ai-consumption/"},"sections":[{"parentId":null,"name":"Process data by using Docling","level":1,"index":0,"id":"_process_data_by_using_docling"},{"parentId":null,"name":"Explore the data processing examples","level":1,"index":1,"id":"explore-the-data-processing-examples_{context}"},{"parentId":null,"name":"Automate data processing steps by building AI pipelines","level":1,"index":2,"id":"_automate_data_processing_steps_by_building_ai_pipelines"},{"parentId":null,"name":"Explore the kubeflow pipeline examples","level":1,"index":3,"id":"explore-the-kubeflow-pipeline-examples_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/preparing-the-distributed-training-environment/"},"sections":[{"parentId":null,"name":"Creating a workbench for distributed training","level":1,"index":0,"id":"creating-a-workbench-for-distributed-training_{context}"},{"parentId":null,"name":"Using the cluster server and token to authenticate","level":1,"index":1,"id":"using-the-cluster-server-and-token-to-authenticate_{context}"},{"parentId":null,"name":"Managing custom training images","level":1,"index":2,"id":"managing-custom-training-images_{context}"},{"parentId":"managing-custom-training-images_{context}","name":"About base training images","level":2,"index":0,"id":"about-base-training-images_{context}"},{"parentId":"managing-custom-training-images_{context}","name":"Creating a custom training image","level":2,"index":1,"id":"creating-a-custom-training-image_{context}"},{"parentId":"managing-custom-training-images_{context}","name":"Pushing an image to the integrated OpenShift image registry","level":2,"index":2,"id":"pushing-an-image-to-the-integrated-openshift-image-registry_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/retrieving-features-for-model-training/"},"sections":[{"parentId":null,"name":"Retrieving data science features","level":1,"index":0,"id":"retrieving-data-science-features_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/running-kfto-based-distributed-training-workloads/"},"sections":[{"parentId":null,"name":"Using the Kubeflow Training Operator to run distributed training workloads","level":1,"index":0,"id":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}","name":"Creating a Training Operator PyTorch training script ConfigMap resource","level":2,"index":0,"id":"creating-a-kfto-pytorch-training-script-configmap-resource_{context}"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}","name":"Creating a Training Operator PyTorchJob resource","level":2,"index":1,"id":"creating-a-kfto-pytorchjob-resource_{context}"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}","name":"Creating a Training Operator PyTorchJob resource by using the CLI","level":2,"index":2,"id":"creating-a-kfto-pytorchjob-resource-by-using-the-cli_{context}"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}","name":"Example Training Operator PyTorch training scripts","level":2,"index":3,"id":"example-kfto-pytorch-training-scripts_{context}"},{"parentId":"example-kfto-pytorch-training-scripts_{context}","name":"Example Training Operator PyTorch training script: NCCL","level":3,"index":0,"id":"ref-example-kfto-pytorch-training-script-nccl{context}"},{"parentId":"example-kfto-pytorch-training-scripts_{context}","name":"Example Training Operator PyTorch training script: DDP","level":3,"index":1,"id":"ref-example-kfto-pytorch-training-script-ddp_{context}"},{"parentId":"example-kfto-pytorch-training-scripts_{context}","name":"Example Training Operator PyTorch training script: FSDP","level":3,"index":2,"id":"ref-example-kfto-pytorch-training-script-fsdp_{context}"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}","name":"Example Dockerfile for a Training Operator PyTorch training script","level":2,"index":4,"id":"ref-example-dockerfile-for-a-kfto-pytorch-training-script_{context}"},{"parentId":"using-the-kubeflow-training-operator-to-run-distributed-training-workloads_{context}","name":"Example Training Operator PyTorchJob resource for multi-node training","level":2,"index":5,"id":"ref-example-kfto-pytorchjob-resource-for-multi-node-training_{context}"},{"parentId":null,"name":"Using the Training Operator SDK to run distributed training workloads","level":1,"index":1,"id":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_{context}"},{"parentId":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_{context}","name":"Configuring a training job by using the Training Operator SDK","level":2,"index":0,"id":"configuring-a-training-job-by-using-the-kfto-sdk_{context}"},{"parentId":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_{context}","name":"Running a training job by using the Training Operator SDK","level":2,"index":1,"id":"running-a-training-job-by-using-the-kfto-sdk_{context}"},{"parentId":"using-the-kubeflow-sdk-to-run-distributed-training-workloads_{context}","name":"TrainingClient API: Job-related methods","level":2,"index":2,"id":"ref-trainingclient-api-job-related-methods_{context}"},{"parentId":null,"name":"Fine-tuning a model by using Kubeflow Training","level":1,"index":2,"id":"fine-tuning-a-model-by-using-kubeflow-training_{context}"},{"parentId":"fine-tuning-a-model-by-using-kubeflow-training_{context}","name":"Configuring the fine-tuning job","level":2,"index":0,"id":"configuring-the-fine-tuning-job_{context}"},{"parentId":"fine-tuning-a-model-by-using-kubeflow-training_{context}","name":"Running the fine-tuning job","level":2,"index":1,"id":"running-the-fine-tuning-job_{context}"},{"parentId":"fine-tuning-a-model-by-using-kubeflow-training_{context}","name":"Deleting the fine-tuning job","level":2,"index":2,"id":"deleting-the-fine-tuning-job_{context}"},{"parentId":null,"name":"Creating a multi-node PyTorch training job with RDMA","level":1,"index":3,"id":"creating-a-multi-node-pytorch-training-job-with-rdma_{context}"},{"parentId":null,"name":"Example Training Operator PyTorchJob resource configured to run with RDMA","level":1,"index":4,"id":"ref-example-kfto-pytorchjob-resource-configured-to-run-with-rdma_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/running-ray-based-distributed-workloads/"},"sections":[{"parentId":null,"name":"Running distributed data science workloads from Jupyter notebooks","level":1,"index":0,"id":"running-distributed-data-science-workloads-from-jupyter-notebooks_{context}"},{"parentId":"running-distributed-data-science-workloads-from-jupyter-notebooks_{context}","name":"Downloading the demo Jupyter notebooks from the CodeFlare SDK","level":2,"index":0,"id":"downloading-the-demo-jupyter-notebooks-from-the-codeflare-sdk_{context}"},{"parentId":"running-distributed-data-science-workloads-from-jupyter-notebooks_{context}","name":"Running the demo Jupyter notebooks from the CodeFlare SDK","level":2,"index":1,"id":"running-the-demo-jupyter-notebooks-from-the-codeflare-sdk_{context}"},{"parentId":"running-distributed-data-science-workloads-from-jupyter-notebooks_{context}","name":"Managing Ray clusters from within a Jupyter notebook","level":2,"index":2,"id":"managing-ray-clusters-from-within-a-jupyter-notebook_{context}"},{"parentId":null,"name":"Running distributed data science workloads from AI pipelines","level":1,"index":1,"id":"running-distributed-data-science-workloads-from-ai-pipelines_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/set-up-your-working-environment/"},"sections":[{"parentId":null,"name":"About the {org-name} Python Index","level":1,"index":0,"id":"about-the-python-index_{context}"},{"parentId":null,"name":"Mirror the Python Index for your disconnected environment","level":1,"index":1,"id":"mirror-the-python-index_{context}"},{"parentId":null,"name":"Install packages","level":1,"index":2,"id":"install-packages_{context}"},{"parentId":null,"name":"Import example notebooks","level":1,"index":3,"id":"import-example-notebooks_{context}"},{"parentId":"import-example-notebooks_{context}","name":"Clone an example Git repository","level":2,"index":0,"id":"clone-an-example-git-repository_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/setting-up-feature-store/"},"sections":[{"parentId":null,"name":"Before you begin","level":1,"index":0,"id":"before-you-begin_{context}"},{"parentId":null,"name":"Enabling the Feature Store component","level":1,"index":1,"id":"enabling-the-feature-store-component_{context}"},{"parentId":null,"name":"Creating a Feature Store instance in a project","level":1,"index":2,"id":"creating-a-feature-store-instance-in-a-project_{context}"},{"parentId":null,"name":"Configuring and managing Role Based Access Control","level":1,"index":3,"id":"configuring-and-managing-role-based-access-control_{context}"},{"parentId":null,"name":"Adding feature definitions and initializing your Feature Store instance","level":1,"index":4,"id":"adding-feature-definitions-and-initializing-your-feature-store-instance_{context}"},{"parentId":"adding-feature-definitions-and-initializing-your-feature-store-instance_{context}","name":"Specifying files to ignore","level":2,"index":0,"id":"specifying-files-to-ignore_{context}"},{"parentId":null,"name":"Viewing Feature Store objects in the web-based UI","level":1,"index":5,"id":"viewing-feature-store-objects-in-the-web-based-ui_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/setting-up-trustyai-for-your-project/"},"sections":[{"parentId":null,"name":"Authenticating the TrustyAI service","level":1,"index":0,"id":"authenticating-trustyai-service_{context}"},{"parentId":null,"name":"Uploading training data to TrustyAI","level":1,"index":1,"id":"uploading-training-data-to-trustyai_{context}"},{"parentId":null,"name":"Sending training data to TrustyAI","level":1,"index":2,"id":"sending-training-data-to-trustyai_{context}"},{"parentId":null,"name":"Labeling data fields","level":1,"index":3,"id":"labeling-data-fields_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/train-the-model-by-using-your-prepared-data/"},"sections":[{"parentId":null,"name":"Explore the Training Hub examples","level":1,"index":0,"id":"explore-the-training-hub-examples_{context}"},{"parentId":null,"name":"Estimate memory usage","level":1,"index":1,"id":"estimate-memory-usage_{context}"},{"parentId":null,"name":"Compare the performance of OSFT and SFT training algorithms","level":1,"index":2,"id":"compare-the-performance-of-osft-and-sft_{context}"},{"parentId":null,"name":"Distribute training jobs by using the KubeFlow Trainer Operator","level":1,"index":3,"id":"_distribute_training_jobs_by_using_the_kubeflow_trainer_operator"},{"parentId":null,"name":"Distributed fine-tuning with Training Hub and Kubeflow Trainer","level":1,"index":4,"id":"_distributed_fine_tuning_with_training_hub_and_kubeflow_trainer"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/upgrading-odh-v1-to-v2/"},"sections":[{"parentId":null,"name":"Requirements for upgrading {productname-short} version 1","level":1,"index":0,"id":"requirements-for-upgrading-odh-v1_upgradev1"},{"parentId":null,"name":"Upgrading the Open Data Hub Operator","level":1,"index":1,"id":"upgrading-the-odh-operator_upgradev1"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/upgrading-odh-v2/"},"sections":[{"parentId":null,"name":"Requirements for upgrading {productname-short} version 2","level":1,"index":0,"id":"requirements-for-upgrading-odh-v2_upgradev2"},{"parentId":null,"name":"Upgrading the Open Data Hub Operator","level":1,"index":1,"id":"upgrading-the-odh-operator_upgradev2"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-basic-workbenches/"},"sections":[{"parentId":null,"name":"Starting a basic workbench","level":1,"index":0,"id":"starting-a-basic-workbench_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-connections/"},"sections":[{"parentId":null,"name":"Adding a connection to your project","level":1,"index":0,"id":"adding-a-connection-to-your-project_{context}"},{"parentId":null,"name":"Updating a connection","level":1,"index":1,"id":"updating-a-connection_{context}"},{"parentId":null,"name":"Deleting a connection","level":1,"index":2,"id":"deleting-a-connection_{context}"},{"parentId":null,"name":"Using the connections API","level":1,"index":3,"id":"using-connections-api_{context}"},{"parentId":"using-connections-api_{context}","name":"Namespace isolation in connections API","level":2,"index":0,"id":"_namespace_isolation_in_connections_api"},{"parentId":"using-connections-api_{context}","name":"Role-based access control (RBAC) requirements in connections API","level":2,"index":1,"id":"_role_based_access_control_rbac_requirements_in_connections_api"},{"parentId":"using-connections-api_{context}","name":"Validation scope","level":2,"index":2,"id":"_validation_scope"},{"parentId":"using-connections-api_{context}","name":"Using connection annotations based on workload type","level":2,"index":3,"id":"_using_connection_annotations_based_on_workload_type"},{"parentId":"using-connections-api_{context}","name":"Creating an Amazon S3-compatible connection type using the connections API","level":2,"index":4,"id":"creating-s3-compatible-connection-type-api_{context}"},{"parentId":"creating-s3-compatible-connection-type-api_{context}","name":"Using an Amazon S3 connection with <code>InferenceService</code> custom resource","level":3,"index":0,"id":"_using_an_amazon_s3_connection_with_inferenceservice_custom_resource"},{"parentId":"creating-s3-compatible-connection-type-api_{context}","name":"Using an Amazon S3 connection with <code>LLMInferenceService</code> custom resource","level":3,"index":1,"id":"_using_an_amazon_s3_connection_with_llminferenceservice_custom_resource"},{"parentId":"using-connections-api_{context}","name":"Creating a URI-compatible connection type using the connections API","level":2,"index":5,"id":"creating-uri-compatible-connection-type-api_{context}"},{"parentId":"creating-uri-compatible-connection-type-api_{context}","name":"Using a URI connection with <code>InferenceService</code> custom resource","level":3,"index":0,"id":"_using_a_uri_connection_with_inferenceservice_custom_resource"},{"parentId":"creating-uri-compatible-connection-type-api_{context}","name":"Using a URI connection with <code>LLMInferenceService</code> custom resource","level":3,"index":1,"id":"_using_a_uri_connection_with_llminferenceservice_custom_resource"},{"parentId":"using-connections-api_{context}","name":"Creating an OCI-compatible connection type using the connections API","level":2,"index":6,"id":"creating-oci-compatible-connection-type-api_{context}"},{"parentId":"creating-oci-compatible-connection-type-api_{context}","name":"Using an OCI connection with <code>InferenceService</code> custom resource","level":3,"index":0,"id":"_using_an_oci_connection_with_inferenceservice_custom_resource"},{"parentId":"creating-oci-compatible-connection-type-api_{context}","name":"Using an OCI connection with <code>LLMInferenceService</code> custom resource","level":3,"index":1,"id":"_using_an_oci_connection_with_llminferenceservice_custom_resource"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-explainability/"},"sections":[{"parentId":null,"name":"Requesting a LIME explanation","level":1,"index":0,"id":"requesting-a-lime-explanation_explainers"},{"parentId":"requesting-a-lime-explanation_explainers","name":"Requesting a LIME explanation by using the CLI","level":2,"index":0,"id":"requesting-a-lime-explanation-using-CLI_explainers"},{"parentId":null,"name":"Requesting a SHAP explanation","level":1,"index":1,"id":"requesting-a-shap-explanation_explainers"},{"parentId":"requesting-a-shap-explanation_explainers","name":"Requesting a SHAP explanation by using the CLI","level":2,"index":0,"id":"requesting-a-shap-explanation-using-CLI_explainers"},{"parentId":null,"name":"Using explainers","level":1,"index":2,"id":"using-explainers_explainers"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-guardrails-for-ai-safety/"},"sections":[{"parentId":null,"name":"Detecting PII and sensitive data","level":1,"index":0,"id":"_detecting_pii_and_sensitive_data"},{"parentId":null,"name":"Detecting personally identifiable information (PII) by using Guardrails with Llama Stack","level":1,"index":1,"id":"detecting-pii-by-using-guardrails-with-llama-stack_{context}"},{"parentId":null,"name":"Filtering flagged content by sending requests to the regex detector","level":1,"index":2,"id":"filtering-flagged-content-by-sending-requests-to-the-regex-detector_{context}"},{"parentId":null,"name":"Securing prompts","level":1,"index":3,"id":"_securing_prompts"},{"parentId":null,"name":"Mitigating Prompt Injection by using a Hugging Face Prompt Injection detector","level":1,"index":4,"id":"mitigating-prompt-injection-by-using-a-hugging-face-prompt-injection-detector_{context}"},{"parentId":null,"name":"Moderating and safeguarding content","level":1,"index":5,"id":"_moderating_and_safeguarding_content"},{"parentId":null,"name":"Detecting hateful and profane language","level":1,"index":6,"id":"detecting-hateful-and-profane-language_{context}"},{"parentId":null,"name":"Enforcing configured safety pipelines for LLM inference by using Guardrails Gateway","level":1,"index":7,"id":"enforcing-configured-safety-pipelines-for-llm-inference-using-guardrails-gateway_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-llama-stack-with-trustyai/"},"sections":[{"parentId":null,"name":"Using Llama Stack external evaluation provider with lm-evaluation-harness in TrustyAI","level":1,"index":0,"id":"using-llama-stack-external-evaluation-provider-with-lm-evaluation-harness-in-TrustyAI_{context}"},{"parentId":null,"name":"Running custom evaluations with LM-Eval and Llama Stack","level":1,"index":1,"id":"running-custom-evaluations-with-LMEval-and-llama-stack_{context}"},{"parentId":null,"name":"Detecting personally identifiable information (PII) by using Guardrails with Llama Stack","level":1,"index":2,"id":"detecting-pii-by-using-guardrails-with-llama-stack_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-project-workbenches/"},"sections":[{"parentId":null,"name":"Creating a workbench and selecting an IDE","level":1,"index":0,"id":"creating-a-workbench-select-ide_{context}"},{"parentId":"creating-a-workbench-select-ide_{context}","name":"About workbench images","level":2,"index":0,"id":"about-workbench-images_{context}"},{"parentId":"creating-a-workbench-select-ide_{context}","name":"Creating a workbench","level":2,"index":1,"id":"creating-a-project-workbench_{context}"},{"parentId":null,"name":"Starting a workbench","level":1,"index":1,"id":"starting-a-workbench_{context}"},{"parentId":null,"name":"Updating a project workbench","level":1,"index":2,"id":"updating-a-project-workbench_{context}"},{"parentId":null,"name":"Deleting a workbench from a project","level":1,"index":3,"id":"deleting-a-workbench-from-a-project_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-projects/"},"sections":[{"parentId":null,"name":"Creating a project","level":1,"index":0,"id":"creating-a-project_{context}"},{"parentId":null,"name":"Updating a project","level":1,"index":1,"id":"updating-a-project_{context}"},{"parentId":null,"name":"Deleting a project","level":1,"index":2,"id":"deleting-a-project_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-the-kfto-sdk-to-run-distributed-training-workloads/"},"sections":[{"parentId":null,"name":"Configuring a training job by using the Training Operator SDK","level":1,"index":0,"id":"configuring-a-training-job-by-using-the-kfto-sdk_{context}"},{"parentId":null,"name":"Running a training job by using the Training Operator SDK","level":1,"index":1,"id":"running-a-training-job-by-using-the-kfto-sdk_{context}"},{"parentId":null,"name":"TrainingClient API: Job-related methods","level":1,"index":2,"id":"ref-trainingclient-api-job-related-methods_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/using-the-kubeflow-training-operator-to-run-distributed-training-workloads/"},"sections":[{"parentId":null,"name":"Creating a Training Operator PyTorch training script ConfigMap resource","level":1,"index":0,"id":"creating-a-kfto-pytorch-training-script-configmap-resource_{context}"},{"parentId":null,"name":"Creating a Training Operator PyTorchJob resource","level":1,"index":1,"id":"creating-a-kfto-pytorchjob-resource_{context}"},{"parentId":null,"name":"Creating a Training Operator PyTorchJob resource by using the CLI","level":1,"index":2,"id":"creating-a-kfto-pytorchjob-resource-by-using-the-cli_{context}"},{"parentId":null,"name":"Example Training Operator PyTorch training scripts","level":1,"index":3,"id":"example-kfto-pytorch-training-scripts_{context}"},{"parentId":"example-kfto-pytorch-training-scripts_{context}","name":"Example Training Operator PyTorch training script: NCCL","level":2,"index":0,"id":"ref-example-kfto-pytorch-training-script-nccl{context}"},{"parentId":"example-kfto-pytorch-training-scripts_{context}","name":"Example Training Operator PyTorch training script: DDP","level":2,"index":1,"id":"ref-example-kfto-pytorch-training-script-ddp_{context}"},{"parentId":"example-kfto-pytorch-training-scripts_{context}","name":"Example Training Operator PyTorch training script: FSDP","level":2,"index":2,"id":"ref-example-kfto-pytorch-training-script-fsdp_{context}"},{"parentId":null,"name":"Example Dockerfile for a Training Operator PyTorch training script","level":1,"index":4,"id":"ref-example-dockerfile-for-a-kfto-pytorch-training-script_{context}"},{"parentId":null,"name":"Example Training Operator PyTorchJob resource for multi-node training","level":1,"index":5,"id":"ref-example-kfto-pytorchjob-resource-for-multi-node-training_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/viewing-logs-and-audit-records/"},"sections":[{"parentId":null,"name":"Configuring the {productname-short} Operator logger","level":1,"index":0,"id":"configuring-the-operator-logger_{context}"},{"parentId":"configuring-the-operator-logger_{context}","name":"Viewing the {productname-short} Operator logs","level":2,"index":0,"id":"_viewing_the_productname_short_operator_logs"},{"parentId":null,"name":"Viewing audit records","level":1,"index":1,"id":"viewing-audit-records_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-certificates/"},"sections":[{"parentId":null,"name":"Understanding how {productname-short} handles certificates","level":1,"index":0,"id":"understanding-certificates_certs"},{"parentId":null,"name":"Adding certificates","level":1,"index":1,"id":"_adding_certificates"},{"parentId":null,"name":"Adding certificates to a cluster-wide CA bundle","level":1,"index":2,"id":"adding-certificates-to-a-cluster-ca-bundle_certs"},{"parentId":null,"name":"Adding certificates to a custom CA bundle","level":1,"index":3,"id":"adding-certificates-to-a-custom-ca-bundle_certs"},{"parentId":null,"name":"Using self-signed certificates with {productname-short} components","level":1,"index":4,"id":"_using_self_signed_certificates_with_productname_short_components"},{"parentId":"_using_self_signed_certificates_with_productname_short_components","name":"Accessing S3-compatible object storage with self-signed certificates","level":2,"index":0,"id":"accessing-s3-compatible-object-storage-with-self-signed-certificates_certs"},{"parentId":"_using_self_signed_certificates_with_productname_short_components","name":"Configuring a certificate for pipelines","level":2,"index":1,"id":"configuring-a-certificate-for-pipelines_certs"},{"parentId":"_using_self_signed_certificates_with_productname_short_components","name":"Configuring a certificate for workbenches","level":2,"index":2,"id":"configuring-a-certificate-for-workbenches_certs"},{"parentId":"_using_self_signed_certificates_with_productname_short_components","name":"Using the cluster-wide CA bundle for the model serving platform","level":2,"index":3,"id":"using-the-cluster-CA-bundle-for-model-serving_certs"},{"parentId":null,"name":"Managing certificates without the {productname-long} Operator","level":1,"index":5,"id":"managing-certificates-without-the-operator_certs"},{"parentId":null,"name":"Removing the CA bundle","level":1,"index":6,"id":"_removing_the_ca_bundle"},{"parentId":"_removing_the_ca_bundle","name":"Removing the CA bundle from all namespaces","level":2,"index":0,"id":"removing-the-ca-bundle-from-all-namespaces_certs"},{"parentId":"_removing_the_ca_bundle","name":"Removing the CA bundle from a single namespace","level":2,"index":1,"id":"removing-the-ca-bundle-from-a-single-namespace_certs"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-data-in-s3-compatible-object-store/"},"sections":[{"parentId":null,"name":"Prerequisites","level":1,"index":0,"id":"s3-prerequisites_s3"},{"parentId":null,"name":"Creating an S3 client","level":1,"index":1,"id":"creating-an-s3-client_s3"},{"parentId":null,"name":"Listing available buckets in your object store","level":1,"index":2,"id":"listing-available-amazon-buckets_s3"},{"parentId":null,"name":"Creating a bucket in your object store","level":1,"index":3,"id":"creating-an-s3-bucket_s3"},{"parentId":null,"name":"Listing files in your bucket","level":1,"index":4,"id":"listing-files-in-available-amazon-s3-buckets-using-notebook-cells_s3"},{"parentId":null,"name":"Downloading files from your bucket","level":1,"index":5,"id":"downloading-files-from-available-amazon-s3-buckets-using-notebook-cells_s3"},{"parentId":null,"name":"Uploading files to your bucket","level":1,"index":6,"id":"uploading-files-to-available-amazon-s3-buckets-using-notebook-cells_s3"},{"parentId":null,"name":"Copying files between buckets","level":1,"index":7,"id":"copying-files-to-between-buckets_s3"},{"parentId":null,"name":"Deleting files from your bucket","level":1,"index":8,"id":"Deleting-files-on-your-object-store_s3"},{"parentId":null,"name":"Deleting a bucket from your object store","level":1,"index":9,"id":"deleting-a-s3-bucket_s3"},{"parentId":null,"name":"Overview of object storage endpoints","level":1,"index":10,"id":"overview-of-object-storage-endpoints_s3"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"MinIO (On-Cluster)","level":2,"index":0,"id":"_minio_on_cluster"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"Amazon S3","level":2,"index":1,"id":"_amazon_s3"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"Other S3-Compatible Object Stores","level":2,"index":2,"id":"_other_s3_compatible_object_stores"},{"parentId":"overview-of-object-storage-endpoints_s3","name":"Verification and Troubleshooting","level":2,"index":3,"id":"_verification_and_troubleshooting"},{"parentId":null,"name":"Accessing S3-compatible object storage with self-signed certificates","level":1,"index":11,"id":"accessing-s3-compatible-object-storage-with-self-signed-certificates_s3"},{"parentId":null,"name":"Additional resources","level":0,"index":12,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-model-registries/"},"sections":[{"parentId":null,"name":"Registering a model from the dashboard","level":1,"index":0,"id":"registering-a-model_model-registry"},{"parentId":null,"name":"Registering a model version","level":1,"index":1,"id":"registering-a-model-version_model-registry"},{"parentId":null,"name":"Viewing registered models","level":1,"index":2,"id":"viewing-registered-models_model-registry"},{"parentId":null,"name":"Viewing registered model versions","level":1,"index":3,"id":"viewing-registered-model-versions_model-registry"},{"parentId":null,"name":"Editing model metadata in a model registry","level":1,"index":4,"id":"editing-model-metadata-in-a-model-registry_model-registry"},{"parentId":null,"name":"Editing model version metadata in a model registry","level":1,"index":5,"id":"editing-model-version-metadata-in-a-model-registry_model-registry"},{"parentId":null,"name":"Deploying a model version from a model registry","level":1,"index":6,"id":"deploying-a-model-version-from-a-model-registry_model-registry"},{"parentId":null,"name":"Editing the deployment properties of a deployed model version from a model registry","level":1,"index":7,"id":"_editing_the_deployment_properties_of_a_deployed_model_version_from_a_model_registry"},{"parentId":"_editing_the_deployment_properties_of_a_deployed_model_version_from_a_model_registry","name":"Editing the deployment properties of a model deployed by using the model serving platform","level":2,"index":0,"id":"editing-the-deployment-properties-of-a-model-deployed-by-using-the-model-serving-platform_model-registry"},{"parentId":null,"name":"Deleting a deployed model version from a model registry","level":1,"index":8,"id":"deleting-a-deployed-model-version-from-a-model-registry_model-registry"},{"parentId":null,"name":"Archiving a model","level":1,"index":9,"id":"archiving-a-model_model-registry"},{"parentId":null,"name":"Archiving a model version","level":1,"index":10,"id":"archiving-a-model-version_model-registry"},{"parentId":null,"name":"Restoring a model","level":1,"index":11,"id":"restoring-a-model_model-registry"},{"parentId":null,"name":"Restoring a model version","level":1,"index":12,"id":"restoring-a-model-version_model-registry"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-pipeline-logs/"},"sections":[{"parentId":null,"name":"About pipeline logs","level":1,"index":0,"id":"about-pipeline-logs_{context}"},{"parentId":null,"name":"Viewing pipeline step logs","level":1,"index":1,"id":"viewing-pipeline-step-logs_{context}"},{"parentId":null,"name":"Downloading pipeline step logs","level":1,"index":2,"id":"downloading-pipeline-step-logs_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-pipelines-in-jupyterlab/"},"sections":[{"parentId":null,"name":"Overview of pipelines in JupyterLab","level":1,"index":0,"id":"overview-of-pipelines-in-jupyterlab_{context}"},{"parentId":null,"name":"Accessing the pipeline editor","level":1,"index":1,"id":"accessing-the-pipeline-editor_{context}"},{"parentId":null,"name":"Disabling node caching in Elyra","level":1,"index":2,"id":"disabling-node-caching-in-elyra_{context}"},{"parentId":null,"name":"Creating a runtime configuration","level":1,"index":3,"id":"creating-a-runtime-configuration_{context}"},{"parentId":null,"name":"Updating a runtime configuration","level":1,"index":4,"id":"updating-a-runtime-configuration_{context}"},{"parentId":null,"name":"Deleting a runtime configuration","level":1,"index":5,"id":"deleting-a-runtime-configuration_{context}"},{"parentId":null,"name":"Duplicating a runtime configuration","level":1,"index":6,"id":"duplicating-a-runtime-configuration_{context}"},{"parentId":null,"name":"Running a pipeline in JupyterLab","level":1,"index":7,"id":"running-a-pipeline-in-jupyterlab_{context}"},{"parentId":null,"name":"Exporting a pipeline in JupyterLab","level":1,"index":8,"id":"exporting-a-pipeline-in-jupyterlab_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/working-with-the-model-catalog/"},"sections":[{"parentId":null,"name":"Discovering and evaluating models in the model catalog","level":1,"index":0,"id":"viewing-models-in-the-catalog_model-registry"},{"parentId":null,"name":"Registering a model from the model catalog","level":1,"index":1,"id":"registering-a-model-from-the-model-catalog_model-registry"},{"parentId":null,"name":"Deploying a model from the model catalog","level":1,"index":2,"id":"deploying-a-model-from-the-model-catalog_model-registry"},{"parentId":null,"name":"Configuring model catalog sources in OpenShift","level":1,"index":3,"id":"configuring-model-catalog-sources-in-openshift_model-registry"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-base-training-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-centralized-auth-oidc/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-deleting-users-and-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-feature-definitions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-gpu-time-slicing/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-kserve-deployment-modes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-llama-stack-search-types/"},"sections":[{"parentId":null,"name":"Supported search modes","level":1,"index":0,"id":"_supported_search_modes"},{"parentId":"_supported_search_modes","name":"Keyword search","level":2,"index":0,"id":"_keyword_search"},{"parentId":"_supported_search_modes","name":"Vector search","level":2,"index":1,"id":"_vector_search"},{"parentId":"_supported_search_modes","name":"Hybrid search","level":2,"index":2,"id":"_hybrid_search"},{"parentId":null,"name":"Retrieval database support","level":1,"index":1,"id":"_retrieval_database_support"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-model-serving/"},"sections":[{"parentId":null,"name":"Model serving platform","level":1,"index":0,"id":"_model_serving_platform"},{"parentId":null,"name":"NVIDIA NIM model serving platform","level":1,"index":1,"id":"_nvidia_nim_model_serving_platform"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-organizing-features-by-using-entities/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-persistent-storage/"},"sections":[{"parentId":null,"name":"Storage classes in {productname-short}","level":1,"index":0,"id":"_storage_classes_in_productname_short"},{"parentId":null,"name":"Access modes","level":1,"index":1,"id":"_access_modes"},{"parentId":"_access_modes","name":"Using shared storage (RWX)","level":2,"index":0,"id":"_using_shared_storage_rwx"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-pipeline-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-the-NVIDIA-NIM-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-the-ai-assets-endpoints-page/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-the-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-the-python-index/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/about-workbench-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-authentication-token-for-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-basic-workbenches-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-built-in-alerts/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-hugging-face-models-with-an-environment-variable-token/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-inference-endpoint-for-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-s3-compatible-object-storage-with-self-signed-certificates/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-the-administration-interface-for-basic-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-the-pipeline-editor/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/accessing-your-workbench-ide/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/activating-the-llama-stack-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-connection-to-your-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-custom-model-serving-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-a-tested-and-verified-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-an-application-to-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-an-odh-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-certificates-to-a-cluster-ca-bundle/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-certificates-to-a-custom-ca-bundle/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-cluster-storage-to-your-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-external-artifacts-to-pipeline-run-workspaces/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-feature-definitions-and-initializing-your-feature-store-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-users-to-user-groups/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/adding-workbench-pod-tolerations/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/allocating-additional-resources-to-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/amd-gpu-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/api-custom-image-creating/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/api-workbench-creating/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/api-workbench-overview/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/archiving-a-model-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/archiving-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/archiving-a-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/archiving-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/audience-for-feature-store/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/auth-on-llama-stack/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/authenticating-kfp-sdk-with-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/authenticating-trustyai-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/backing-up-storage-data/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/before-you-begin/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/benchmarking-embedding-models-with-beir-datasets-and-llama-stack/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/backing-up-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/changing-the-storage-class-for-an-existing-cluster-storage-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/cleaning-up-after-deleting-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/cleaning-up-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/clone-an-example-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/collecting-metrics-from-user-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/compare-the-performance-of-osft-and-sft/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/comparing-runs-in-an-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/comparing-runs-in-different-experiments/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/compiling-kubernetes-native-manifests-with-kfp-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/compiling-the-pipeline-yaml-with-kfp-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-certificate-for-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-certificate-for-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-cluster-for-rdma/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-pipeline-server-with-an-external-amazon-rds-db/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-playground-for-your-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-recommended-accelerator-for-serving-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-recommended-accelerator-for-workbench-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-an-offline-store/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-an-online-store/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-and-managing-role-based-access-control/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-authentication-for-llmd/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-custom-namespaces/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-default-workspace-pvc-settings-in-dspa/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-mcp-servers/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-metric-based-autoscaling/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-model-catalog-sources-in-openshift/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-monitoring-for-the-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-monitoring-for-your-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-oidc-auth-gateway-api/"},"sections":[{"parentId":null,"name":"Security considerations","level":1,"index":0,"id":"_security_considerations"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-pipelines-with-your-own-argo-workflows-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-quota-management-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-ragas-remote-provider-for-production/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-role-based-access-control/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-storage-class-settings/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-built-in-detector-and-guardrails-gateway/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-default-pvc-size-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-default-storage-class-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-feature-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-fine-tuning-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-the-operator-logger/"},"sections":[{"parentId":null,"name":"Viewing the {productname-short} Operator logs","level":1,"index":0,"id":"_viewing_the_productname_short_operator_logs"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-trustyai-with-a-database/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-workload-management-with-kueue/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/controlling-caching-in-pipelines/"},"sections":[{"parentId":null,"name":"Disabling caching for individual tasks","level":1,"index":0,"id":"_disabling_caching_for_individual_tasks"},{"parentId":null,"name":"Disabling caching for a pipeline at submit time","level":1,"index":1,"id":"_disabling_caching_for_a_pipeline_at_submit_time"},{"parentId":null,"name":"Disabling caching for a pipeline at compile time","level":1,"index":2,"id":"_disabling_caching_for_a_pipeline_at_compile_time"},{"parentId":null,"name":"Disabling caching for all pipelines (pipeline server)","level":1,"index":3,"id":"_disabling_caching_for_all_pipelines_pipeline_server"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/copying-files-between-buckets/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-bias-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-bias-metric-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-bias-metric/"},"sections":[{"parentId":null,"name":"Creating a bias metric by using the dashboard","level":1,"index":0,"id":"creating-a-bias-metric-using-dashboard_{context}"},{"parentId":null,"name":"Creating a bias metric by using the CLI","level":1,"index":1,"id":"creating-a-bias-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-custom-image-from-default-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-custom-image-from-your-own-image/"},"sections":[{"parentId":null,"name":"Basic guidelines for creating your own workbench image","level":1,"index":0,"id":"_basic_guidelines_for_creating_your_own_workbench_image"},{"parentId":null,"name":"Advanced guidelines for creating your own workbench image","level":1,"index":1,"id":"_advanced_guidelines_for_creating_your_own_workbench_image"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-custom-training-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-drift-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-drift-metric/"},"sections":[{"parentId":null,"name":"Creating a drift metric by using the CLI","level":1,"index":0,"id":"creating-a-drift-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-feature-store-instance-in-a-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-hardware-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-jupyter-notebook/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-kfto-pytorch-training-script-configmap-resource/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-kfto-pytorchjob-resource-by-using-the-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-kfto-pytorchjob-resource/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-multi-node-pytorch-training-job-with-rdma/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-new-project-for-your-odh-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-project-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-workbench-for-distributed-training/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-a-workbench-select-ide/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-an-s3-client/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-feature-views/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-oci-compatible-connection-types-api/"},"sections":[{"parentId":null,"name":"Using an OCI connection with <code>InferenceService</code> custom resource","level":1,"index":0,"id":"_using_an_oci_connection_with_inferenceservice_custom_resource"},{"parentId":null,"name":"Using an OCI connection with <code>LLMInferenceService</code> custom resource","level":1,"index":1,"id":"_using_an_oci_connection_with_llminferenceservice_custom_resource"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-project-scoped-resources-for-your-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-project-scoped-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-s3-compatible-connection-type-api/"},"sections":[{"parentId":null,"name":"Using an Amazon S3 connection with <code>InferenceService</code> custom resource","level":1,"index":0,"id":"_using_an_amazon_s3_connection_with_inferenceservice_custom_resource"},{"parentId":null,"name":"Using an Amazon S3 connection with <code>LLMInferenceService</code> custom resource","level":1,"index":1,"id":"_using_an_amazon_s3_connection_with_llminferenceservice_custom_resource"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/creating-uri-compatible-connection-type-api/"},"sections":[{"parentId":null,"name":"Using a URI connection with <code>InferenceService</code> custom resource","level":1,"index":0,"id":"_using_a_uri_connection_with_inferenceservice_custom_resource"},{"parentId":null,"name":"Using a URI connection with <code>LLMInferenceService</code> custom resource","level":1,"index":1,"id":"_using_a_uri_connection_with_llminferenceservice_custom_resource"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/customizable-model-serving-runtime-parameters/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/customizing-component-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/customizing-model-selection-options/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/customizing-parameters-serving-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/customizing-the-vllm-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/defining-a-pipeline-by-using-the-kubernetes-api/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/defining-a-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-bias-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-bias-metric-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-bias-metric/"},"sections":[{"parentId":null,"name":"Deleting a bias metric by using the dashboard","level":1,"index":0,"id":"deleting-a-bias-metric-using-dashboard_{context}"},{"parentId":null,"name":"Deleting a bias metric by using the CLI","level":1,"index":1,"id":"deleting-a-bias-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-connection/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-deployed-model-version-from-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-drift-metric-by-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-hardware-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-an-inference-service-for-spyre/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-an-inference-service-for-kueue/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/configuring-a-training-job-by-using-the-kfto-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-playground-from-your-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-scheduled-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-a-workbench-from-a-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-an-archived-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-cluster-storage-from-a-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-files-in-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-files-in-trash-directory/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deleting-the-fine-tuning-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-llama-model-with-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-grafana-metrics-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-llamastackdistribution-instance/"},"sections":[{"parentId":null,"name":"Example A: LlamaStackDistribution with <strong>Inline Milvus</strong>","level":1,"index":0,"id":"_example_a_llamastackdistribution_with_inline_milvus"},{"parentId":null,"name":"Example B: LlamaStackDistribution with <strong>Remote Milvus</strong>","level":1,"index":1,"id":"_example_b_llamastackdistribution_with_remote_milvus"},{"parentId":null,"name":"Example C: LlamaStackDistribution with <strong>Inline FAISS</strong>","level":1,"index":2,"id":"_example_c_llamastackdistribution_with_inline_faiss"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-model-from-the-model-catalog/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-model-version-from-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-a-remote-milvus-vector-database/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-model-stored-in-oci-image-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-models-on-the-NVIDIA-NIM-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-models-on-the-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-models-using-distributed-inference/"},"sections":[{"parentId":null,"name":"Configuring authentication for {llmd} using {org-name} Connectivity Link","level":1,"index":0,"id":"configuring-authentication-for-llmd_{context}"},{"parentId":null,"name":"Enabling {llmd}","level":1,"index":1,"id":"enabling-distributed-inference_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-models-using-multiple-gpu-nodes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-models-using-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-the-guardrails-orchestrator-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/deploying-vllm-gpu-metrics-dashboard-grafana/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/detecting-hateful-and-profane-language/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/determining-gpu-requirements-for-llm-powered-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/disabling-applications-connected/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/disabling-component-resource-customization/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/disabling-lqlabel-all/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/detecting-pii-by-using-guardrails-with-llama-stack/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/disabling-node-caching-in-elyra/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/downloading-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/downloading-files-from-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/downloading-pipeline-step-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/downloading-the-demo-jupyter-notebooks-from-the-codeflare-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-a-bias-metric/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-a-scheduled-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-an-active-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/duplicating-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-an-existing-feature-store-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-model-metadata-in-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-the-dashboard-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-model-version-metadata-in-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/editing-the-deployment-properties-of-a-model-deployed-by-using-the-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/emptying-trash-directory/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-amd-gpus/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-applications-connected/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-automatic-authentication-and-publishing-features/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-distributed-inference/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-gpu-time-slicing/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-custom-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-intel-gaudi-ai-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-kueue-in-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-metrics-for-existing-nim-deployment/"},"sections":[{"parentId":null,"name":"Enabling graph generation for an existing NIM deployment","level":1,"index":0,"id":"_enabling_graph_generation_for_an_existing_nim_deployment"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-nvidia-gpus/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-online-access-and-remote-code-execution-LMEvalJob-using-the-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-feature-store-component/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-model-registry-component/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-nvidia-nim-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-the-observability-stack/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-trustyai-component/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enabling-trustyai-kserve-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/end-to-end-model-customization-workflow/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enforcing-lqlabel-all/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/estimate-memory-usage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/enforcing-lqlabel-some/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/evaluating-rag-system-quality-with-ragas/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/executing-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/explore-the-data-processing-examples/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/explore-the-kubeflow-pipeline-examples/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/explore-the-sdg-hub-examples/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/explore-the-training-hub-examples/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/exporting-a-pipeline-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/exporting-metrics-to-external-observability-tools/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/exporting-your-playground-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/feature-store-workflow/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/glossary-of-common-terms/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/granting-access-to-a-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guardrails-auto-config/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guardrails-configuring-the-hugging-face-detector-serving-runtime/"},"sections":[{"parentId":null,"name":"Guardrails Detector Hugging Face serving runtime configuration values","level":1,"index":0,"id":"_guardrails_detector_hugging_face_serving_runtime_configuration_values"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guardrails-configuring-the-opentelemetry-exporter/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guardrails-deploying-the-guardrails-orchestrator-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guardrails-enforcing-configured-safety-pipelines-for-llm-inference-using-guardrails-gateway/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guardrails-filtering-flagged-content-by-sending-requests-to-the-regex-detector/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guardrails-gateway-config-parameters/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guardrails-orchestrator-configmap-parameters/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guardrails-orchestrator-detectors/"},"sections":[{"parentId":null,"name":"Built-in Detector","level":1,"index":0,"id":"_built_in_detector"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guardrails-orchestrator-parameters/"},"sections":[{"parentId":null,"name":"Gateway Pa","level":0,"index":0,"id":"_gateway_pa"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guided-example-build-a-kfp-pipeline-for-sdg/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/guidelines-for-metrics-based-autoscaling/"},"sections":[{"parentId":null,"name":"Choosing metrics for latency and throughput-optimized scaling","level":1,"index":0,"id":"_choosing_metrics_for_latency_and_throughput_optimized_scaling"},{"parentId":null,"name":"Choosing the right sliding window","level":1,"index":1,"id":"_choosing_the_right_sliding_window"},{"parentId":null,"name":"Optimizing HPA scale-down configuration","level":1,"index":2,"id":"_optimizing_hpa_scale_down_configuration"},{"parentId":null,"name":"Considering model size for optimal scaling","level":1,"index":3,"id":"_considering_model_size_for_optimal_scaling"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/hiding-the-default-basic-workbench-application/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ibm-spyre-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/import-example-notebooks/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/importing-a-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/importing-a-custom-workbench-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/inference-performance-metrics/"},"sections":[{"parentId":null,"name":"Latency","level":1,"index":0,"id":"_latency"},{"parentId":null,"name":"Throughput","level":1,"index":1,"id":"_throughput"},{"parentId":null,"name":"Cost per million tokens","level":1,"index":2,"id":"_cost_per_million_tokens"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ingesting-content-into-a-llama-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/install-packages/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-extensions-with-code-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-odh-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-python-packages-on-your-code-server-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-python-packages-on-your-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-the-distributed-workloads-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-the-odh-operator-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-the-odh-operator-v2/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-trustyai-service-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-trustyai-service-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/installing-trustyai-service/"},"sections":[{"parentId":null,"name":"Installing the TrustyAI service by using the dashboard","level":1,"index":0,"id":"installing-trustyai-service-using-dashboard_{context}"},{"parentId":null,"name":"Installing the TrustyAI service by using the CLI","level":1,"index":1,"id":"installing-trustyai-service-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/intel-gaudi-ai-accelerator-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/kueue-workflow/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/labeling-data-fields/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/listing-available-buckets/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/listing-files-in-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/llama-stack-apis/"},"sections":[{"parentId":null,"name":"Supported Llama Stack APIs in {productname-short}","level":1,"index":0,"id":"_supported_llama_stack_apis_in_productname_short"},{"parentId":"_supported_llama_stack_apis_in_productname_short","name":"Agents API","level":2,"index":0,"id":"_agents_api"},{"parentId":"_supported_llama_stack_apis_in_productname_short","name":"Datasets_IO API","level":2,"index":1,"id":"_datasets_io_api"},{"parentId":"_supported_llama_stack_apis_in_productname_short","name":"Evaluation API","level":2,"index":2,"id":"_evaluation_api"},{"parentId":"_supported_llama_stack_apis_in_productname_short","name":"Inference API","level":2,"index":3,"id":"_inference_api"},{"parentId":"_supported_llama_stack_apis_in_productname_short","name":"Safety API","level":2,"index":4,"id":"_safety_api"},{"parentId":"_supported_llama_stack_apis_in_productname_short","name":"Tool Runtime API","level":2,"index":5,"id":"_tool_runtime_api"},{"parentId":"_supported_llama_stack_apis_in_productname_short","name":"Vector_IO API","level":2,"index":6,"id":"_vector_io_api"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/llama-stack-providers-support/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/lmeval-evaluation-job-properties/"},"sections":[{"parentId":null,"name":"Properties for setting up custom Unitxt cards, templates, or system prompts","level":1,"index":0,"id":"_properties_for_setting_up_custom_unitxt_cards_templates_or_system_prompts"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/lmeval-evaluation-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/logging-in/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/making-features-available-for-real-time-inference/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/making-inference-requests-to-models-deployed-on-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/managing-certificates-without-the-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/managing-model-registry-permissions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/managing-ray-clusters-from-within-a-jupyter-notebook/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/migrating-pipelines-from-database-to-kubernetes-api/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/migrating-to-the-rhbok-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/mirror-the-python-index/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/mitigating-prompt-injection-by-using-a-hugging-face-prompt-injection-detector/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/model-serving-runtimes-for-accelerators/"},"sections":[{"parentId":null,"name":"NVIDIA GPUs","level":1,"index":0,"id":"_nvidia_gpus"},{"parentId":null,"name":"Intel Gaudi accelerators","level":1,"index":1,"id":"_intel_gaudi_accelerators"},{"parentId":null,"name":"AMD GPUs","level":1,"index":2,"id":"_amd_gpus"},{"parentId":null,"name":"IBM Spyre AI accelerators on x86 and IBM Z","level":1,"index":3,"id":"_ibm_spyre_ai_accelerators_on_x86_and_ibm_z"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/model-serving-runtimes/"},"sections":[{"parentId":null,"name":"ServingRuntime","level":1,"index":0,"id":"_servingruntime"},{"parentId":null,"name":"InferenceService","level":1,"index":1,"id":"_inferenceservice"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/next-steps-getting-started/"},"sections":[{"parentId":null,"name":"Additional resources","level":1,"index":0,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/next-steps-playground/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/nvidia-gpu-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/openai-compatibility-for-rag-apis-in-llama-stack/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/openai-compatible-apis-in-llama-stack/"},"sections":[{"parentId":null,"name":"Supported OpenAI-compatible APIs in {productname-short}","level":1,"index":0,"id":"_supported_openai_compatible_apis_in_productname_short"},{"parentId":"_supported_openai_compatible_apis_in_productname_short","name":"Chat Completions API","level":2,"index":0,"id":"_chat_completions_api"},{"parentId":"_supported_openai_compatible_apis_in_productname_short","name":"Completions API","level":2,"index":1,"id":"_completions_api"},{"parentId":"_supported_openai_compatible_apis_in_productname_short","name":"Embeddings API","level":2,"index":2,"id":"_embeddings_api"},{"parentId":"_supported_openai_compatible_apis_in_productname_short","name":"Files API","level":2,"index":3,"id":"_files_api"},{"parentId":"_supported_openai_compatible_apis_in_productname_short","name":"Vector Stores API","level":2,"index":4,"id":"_vector_stores_api"},{"parentId":"_supported_openai_compatible_apis_in_productname_short","name":"Vector Store Files API","level":2,"index":5,"id":"_vector_store_files_api"},{"parentId":"_supported_openai_compatible_apis_in_productname_short","name":"Models API","level":2,"index":6,"id":"_models_api"},{"parentId":"_supported_openai_compatible_apis_in_productname_short","name":"Responses API","level":2,"index":7,"id":"_responses_api"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/optimizing-the-vllm-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-for-getting-started/"},"sections":[{"parentId":null,"name":"Data science workflow","level":1,"index":0,"id":"_data_science_workflow"},{"parentId":null,"name":"About this guide","level":1,"index":1,"id":"_about_this_guide"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-component-resource-customization/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-distributed-workloads/"},"sections":[{"parentId":null,"name":"Distributed workloads infrastructure","level":1,"index":0,"id":"_distributed_workloads_infrastructure"},{"parentId":null,"name":"Types of distributed workloads","level":1,"index":1,"id":"_types_of_distributed_workloads"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-evaluating-ai-systems/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-faiss-vector-databases/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-feature-store/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-kueue-resources/"},"sections":[{"parentId":null,"name":"Resource flavor","level":1,"index":0,"id":"_resource_flavor"},{"parentId":null,"name":"Cluster queue","level":1,"index":1,"id":"_cluster_queue"},{"parentId":null,"name":"Local queue","level":1,"index":2,"id":"_local_queue"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-llama-stack/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-managing-workloads-with-kueue/"},"sections":[{"parentId":null,"name":"Kueue management states","level":1,"index":0,"id":"_kueue_management_states"},{"parentId":null,"name":"Queue enforcement for projects","level":1,"index":1,"id":"_queue_enforcement_for_projects"},{"parentId":null,"name":"Restrictions for managing workloads with Kueue","level":1,"index":2,"id":"_restrictions_for_managing_workloads_with_kueue"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-milvus-vector-databases/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-ml-features/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-model-monitoring/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-model-registries/"},"sections":[{"parentId":null,"name":"Model catalog","level":1,"index":0,"id":"_model_catalog"},{"parentId":null,"name":"Model registry","level":1,"index":1,"id":"_model_registry"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-monitoring-your-ai-systems/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-object-storage-endpoints/"},"sections":[{"parentId":null,"name":"MinIO (On-Cluster)","level":1,"index":0,"id":"_minio_on_cluster"},{"parentId":null,"name":"Amazon S3","level":1,"index":1,"id":"_amazon_s3"},{"parentId":null,"name":"Other S3-Compatible Object Stores","level":1,"index":2,"id":"_other_s3_compatible_object_stores"},{"parentId":null,"name":"Verification and Troubleshooting","level":1,"index":3,"id":"_verification_and_troubleshooting"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-pipeline-experiments/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-pipeline-versions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-pipelines-caching/"},"sections":[{"parentId":null,"name":"Caching criteria","level":1,"index":0,"id":"_caching_criteria"},{"parentId":null,"name":"Viewing cached steps in the {productname-short} user interface","level":1,"index":1,"id":"_viewing_cached_steps_in_the_productname_short_user_interface"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-pipelines-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-rag/"},"sections":[{"parentId":null,"name":"Audience for RAG","level":1,"index":0,"id":"_audience_for_rag"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-the-model-customization-workflow/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-upgrading-odh/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-vector-databases/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/overview-of-user-types-and-permissions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/performance-considerations-for-doc-apps/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/performing-model-evaluations-in-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/preventing-users-from-adding-applications-to-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/pushing-an-image-to-the-integrated-openshift-image-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/pushing-project-changes-in-code-server-to-a-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/pushing-project-changes-to-a-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/querying-ingested-content-in-a-llama-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/reenabling-component-resource-customization/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-accelerator-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-cpu-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-dashboard-configuration-options/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-default-authorization-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-distributed-inference/"},"sections":[{"parentId":null,"name":"Single-node GPU deployment","level":1,"index":0,"id":"_single_node_gpu_deployment"},{"parentId":null,"name":"Multi-node deployment","level":1,"index":1,"id":"_multi_node_deployment"},{"parentId":null,"name":"Intelligent inference scheduler with KV cache routing","level":1,"index":2,"id":"_intelligent_inference_scheduler_with_kv_cache_routing"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-dockerfile-for-a-kfto-pytorch-training-script/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kfto-pytorch-training-script-ddp/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kfto-pytorch-training-script-fsdp/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kfto-pytorch-training-script-nccl/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kfto-pytorchjob-resource-configured-to-run-with-rdma/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kfto-pytorchjob-resource-for-multi-node-training/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kubernetes-authorization-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-kueue-resource-configurations/"},"sections":[{"parentId":null,"name":"NVIDIA GPUs without shared cohort","level":1,"index":0,"id":"_nvidia_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU resource flavor","level":2,"index":0,"id":"_nvidia_rtx_a400_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU resource flavor","level":2,"index":1,"id":"_nvidia_rtx_a1000_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU cluster queue","level":2,"index":2,"id":"_nvidia_rtx_a400_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU cluster queue","level":2,"index":3,"id":"_nvidia_rtx_a1000_gpu_cluster_queue"},{"parentId":null,"name":"NVIDIA GPUs and AMD GPUs without shared cohort","level":1,"index":1,"id":"_nvidia_gpus_and_amd_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU resource flavor","level":2,"index":0,"id":"_amd_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU resource flavor","level":2,"index":1,"id":"_nvidia_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU cluster queue","level":2,"index":2,"id":"_amd_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU cluster queue","level":2,"index":3,"id":"_nvidia_gpu_cluster_queue"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-oidc-authorization-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-example-pvc-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-grafana-metrics/"},"sections":[{"parentId":null,"name":"Accelerator metrics","level":1,"index":0,"id":"ref-accelerator-metrics_{context}"},{"parentId":null,"name":"CPU metrics","level":1,"index":1,"id":"ref-cpu-metrics_{context}"},{"parentId":null,"name":"vLLM metrics","level":1,"index":2,"id":"ref-vllm-metrics_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-inference-endpoints/"},"sections":[{"parentId":null,"name":"Caikit TGIS ServingRuntime for KServe","level":1,"index":0,"id":"_caikit_tgis_servingruntime_for_kserve"},{"parentId":null,"name":"OpenVINO Model Server","level":1,"index":1,"id":"_openvino_model_server"},{"parentId":null,"name":"vLLM NVIDIA GPU ServingRuntime for KServe","level":1,"index":2,"id":"_vllm_nvidia_gpu_servingruntime_for_kserve"},{"parentId":null,"name":"vLLM Intel Gaudi Accelerator ServingRuntime for KServe","level":1,"index":3,"id":"_vllm_intel_gaudi_accelerator_servingruntime_for_kserve"},{"parentId":null,"name":"vLLM AMD GPU ServingRuntime for KServe","level":1,"index":4,"id":"_vllm_amd_gpu_servingruntime_for_kserve"},{"parentId":null,"name":"vLLM Spyre AI Accelerator ServingRuntime for KServe","level":1,"index":5,"id":"_vllm_spyre_ai_accelerator_servingruntime_for_kserve"},{"parentId":null,"name":"vLLM Spyre s390x ServingRuntime for KServe","level":1,"index":6,"id":"_vllm_spyre_s390x_servingruntime_for_kserve"},{"parentId":null,"name":"NVIDIA Triton Inference Server","level":1,"index":7,"id":"_nvidia_triton_inference_server"},{"parentId":null,"name":"Seldon MLServer","level":1,"index":8,"id":"_seldon_mlserver"},{"parentId":null,"name":"Additional resources","level":1,"index":9,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-supported-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-tested-verified-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-trainingclient-api-job-related-methods/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/ref-vllm-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/registering-a-model-from-the-model-catalog/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/registering-a-model-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/registering-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/removing-access-to-a-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/removing-disabled-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/removing-the-ca-bundle-from-a-single-namespace/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/removing-the-ca-bundle-from-all-namespaces/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/requesting-a-lime-explanation-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/requesting-a-lime-explanation/"},"sections":[{"parentId":null,"name":"Requesting a LIME explanation by using the CLI","level":1,"index":0,"id":"requesting-a-lime-explanation-using-CLI_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/requesting-a-shap-explanation-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/requesting-a-shap-explanation/"},"sections":[{"parentId":null,"name":"Requesting a SHAP explanation by using the CLI","level":1,"index":0,"id":"requesting-a-shap-explanation-using-CLI_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/requirements-for-upgrading-odh-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/requirements-for-upgrading-odh-v2/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/restoring-a-model-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/restoring-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/restoring-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/restoring-an-archived-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/restoring-the-default-pvc-size-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/retrieving-data-science-features/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/revoking-user-access-to-basic-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-a-pipeline-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-a-training-job-by-using-the-kfto-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-a-workload-with-a-kueue-hardware-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-custom-evaluations-with-LMEval-and-llama-stack/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-distributed-data-science-workloads-disconnected-env/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-distributed-data-science-workloads-from-ai-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-distributed-data-science-workloads-from-jupyter-notebooks/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-the-demo-jupyter-notebooks-from-the-codeflare-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/running-the-fine-tuning-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/s3-prerequisites/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/scheduling-a-pipeline-run-using-a-cron-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/scheduling-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/selecting-admin-and-user-groups/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/sending-training-data-to-trustyai/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/setting-timeout-for-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/setting-up-feature-store-UI/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/setting-up-lmeval-s3-support/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/setting-up-lmeval/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/setting-up-ragas-inline-provider/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/setting-up-your-working-environment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/preparing-documents-with-docling-for-llama-stack-retrieval/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/showing-hiding-information-about-available-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/specifying-files-to-ignore/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/specifying-the-data-source-for-features/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/starting-a-basic-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/starting-a-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/starting-basic-workbenches-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/stopping-an-active-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/stopping-idle-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/stopping-basic-workbenches-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/stopping-starting-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/storing-a-model-in-oci-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/storing-data-with-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/support-philosophy/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-checking-model-fairness/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-deploying-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-introduction/"},"sections":[{"parentId":null,"name":"About the example models","level":1,"index":0,"id":"_about_the_example_models"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-labeling-data-fields/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-reviewing-the-results/"},"sections":[{"parentId":null,"name":"Are the models biased?","level":1,"index":0,"id":"_are_the_models_biased"},{"parentId":null,"name":"How does the production data compare to the training data?","level":1,"index":1,"id":"_how_does_the_production_data_compare_to_the_training_data"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-scheduling-a-fairness-metric-request/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-scheduling-an-identity-metric-request/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-sending-training-data-to-the-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-setting-up-your-environment/"},"sections":[{"parentId":null,"name":"Downloading the tutorial files","level":1,"index":0,"id":"_downloading_the_tutorial_files"},{"parentId":null,"name":"Logging in to the OpenShift cluster from the command line","level":1,"index":1,"id":"_logging_in_to_the_openshift_cluster_from_the_command_line"},{"parentId":null,"name":"Configuring monitoring for the model serving platform","level":1,"index":2,"id":"_configuring_monitoring_for_the_model_serving_platform"},{"parentId":null,"name":"Enabling the TrustyAI component","level":1,"index":3,"id":"enabling-trustyai-component_{context}"},{"parentId":null,"name":"Setting up a project","level":1,"index":4,"id":"_setting_up_a_project"},{"parentId":null,"name":"Authenticating the TrustyAI service","level":1,"index":5,"id":"_authenticating_the_trustyai_service"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/t-bias-simulating-real-world-data/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/testing-baseline-model-responses/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/testing-with-model-control-protocol-servers/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/testing-your-model-with-rag/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/testing-your-vllm-model-endpoints/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-common-problems-gateway-api/"},"sections":[{"parentId":null,"name":"The <code>GatewayConfig</code> status shows as not ready","level":1,"index":0,"id":"_the_gatewayconfig_status_shows_as_not_ready"},{"parentId":null,"name":"Authentication proxy fails to start","level":1,"index":1,"id":"_authentication_proxy_fails_to_start"},{"parentId":null,"name":"The Gateway is inaccessible","level":1,"index":2,"id":"_the_gateway_is_inaccessible"},{"parentId":null,"name":"The OIDC authentication fails","level":1,"index":3,"id":"_the_oidc_authentication_fails"},{"parentId":null,"name":"The dashboard is not accessible after authentication","level":1,"index":4,"id":"_the_dashboard_is_not_accessible_after_authentication"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-common-problems-in-workbenches-for-administrators/"},"sections":[{"parentId":null,"name":"A user receives a <strong>404: Page not found</strong> error when logging in to Jupyter","level":1,"index":0,"id":"_a_user_receives_a_404_page_not_found_error_when_logging_in_to_jupyter"},{"parentId":null,"name":"A user&#8217;s workbench does not start","level":1,"index":1,"id":"_a_users_workbench_does_not_start"},{"parentId":null,"name":"The user receives a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when they run notebook cells","level":1,"index":2,"id":"_the_user_receives_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_they_run_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-common-problems-with-Kueue/"},"sections":[{"parentId":null,"name":"A user receives a \"failed to call webhook\" error message for Kueue","level":1,"index":0,"id":"_a_user_receives_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":null,"name":"A user receives a \"Default Local Queue &#8230;&#8203; not found\" error message","level":1,"index":1,"id":"_a_user_receives_a_default_local_queue_not_found_error_message"},{"parentId":null,"name":"A user receives a \"local_queue provided does not exist\" error message","level":1,"index":2,"id":"_a_user_receives_a_local_queue_provided_does_not_exist_error_message"},{"parentId":null,"name":"The pod provisioned by Kueue is terminated before the image is pulled","level":1,"index":3,"id":"_the_pod_provisioned_by_kueue_is_terminated_before_the_image_is_pulled"},{"parentId":null,"name":"Additional resources","level":1,"index":4,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-common-problems-in-workbenches-for-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-common-problems-with-distributed-workloads-for-users/"},"sections":[{"parentId":null,"name":"My Ray cluster is in a suspended state","level":1,"index":0,"id":"_my_ray_cluster_is_in_a_suspended_state"},{"parentId":null,"name":"My Ray cluster is in a failed state","level":1,"index":1,"id":"_my_ray_cluster_is_in_a_failed_state"},{"parentId":null,"name":"I see a \"failed to call webhook\" error message for Kueue","level":1,"index":2,"id":"_i_see_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":null,"name":"My Ray cluster does not start","level":1,"index":3,"id":"_my_ray_cluster_does_not_start"},{"parentId":null,"name":"I see a \"Default Local Queue not found\" error message","level":1,"index":4,"id":"_i_see_a_default_local_queue_not_found_error_message"},{"parentId":null,"name":"I see a \"local_queue provided does not exist\" error message","level":1,"index":5,"id":"_i_see_a_local_queue_provided_does_not_exist_error_message"},{"parentId":null,"name":"I cannot create a Ray cluster or submit jobs","level":1,"index":6,"id":"_i_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":null,"name":"My pod provisioned by Kueue is terminated before my image is pulled","level":1,"index":7,"id":"_my_pod_provisioned_by_kueue_is_terminated_before_my_image_is_pulled"},{"parentId":null,"name":"Additional resources","level":1,"index":8,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-common-problems-with-distributed-workloads-for-administrators/"},"sections":[{"parentId":null,"name":"A user&#8217;s Ray cluster is in a suspended state","level":1,"index":0,"id":"_a_users_ray_cluster_is_in_a_suspended_state"},{"parentId":null,"name":"A user&#8217;s Ray cluster is in a failed state","level":1,"index":1,"id":"_a_users_ray_cluster_is_in_a_failed_state"},{"parentId":null,"name":"A user&#8217;s Ray cluster does not start","level":1,"index":2,"id":"_a_users_ray_cluster_does_not_start"},{"parentId":null,"name":"A user cannot create a Ray cluster or submit jobs","level":1,"index":3,"id":"_a_user_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":null,"name":"Additional resources","level":1,"index":4,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-playground-issues/"},"sections":[{"parentId":null,"name":"The chatbot thinks indefinitely","level":1,"index":0,"id":"_the_chatbot_thinks_indefinitely"},{"parentId":null,"name":"The model does not use RAG data","level":1,"index":1,"id":"_the_model_does_not_use_rag_data"},{"parentId":null,"name":"MCP servers are missing from the UI","level":1,"index":2,"id":"_mcp_servers_are_missing_from_the_ui"},{"parentId":null,"name":"The model fails to call MCP tools","level":1,"index":3,"id":"_the_model_fails_to_call_mcp_tools"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/troubleshooting-dspa-component-errors/"},"sections":[{"parentId":null,"name":"Common errors across DSPA components","level":1,"index":0,"id":"_common_errors_across_dspa_components"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/understanding-certificates/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/understanding-pipeline-run-workspaces/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/understanding-rag-evaluation-providers/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/understanding-rag-settings/"},"sections":[{"parentId":null,"name":"Understanding RAG settings","level":1,"index":0,"id":"understanding-rag-settings_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-hardware-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-connection/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-project-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-a-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-access-to-a-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-cluster-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-lmeval-job-configuration-using-the-web-console/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-the-deployment-properties-of-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-workbench-settings-by-restarting-your-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-your-playground-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-your-project-in-code-server-with-changes-from-a-remote-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/updating-your-project-with-changes-from-a-remote-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/upgrading-the-odh-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-from-a-git-repository-using-code-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-to-code-server-from-a-git-repository-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-to-code-server-from-local-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-to-jupyterlab-from-local-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-an-existing-notebook-file-to-jupyterlab-from-a-git-repository-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-model-files-to-pvc/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-files-to-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/uploading-training-data-to-trustyai/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-a-custom-unitxt-card/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-a-kserve-inference-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-a-drift-metric-in-a-credit-card-scenario/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-bias-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-connections-api/"},"sections":[{"parentId":null,"name":"Namespace isolation in connections API","level":1,"index":0,"id":"_namespace_isolation_in_connections_api"},{"parentId":null,"name":"Role-based access control (RBAC) requirements in connections API","level":1,"index":1,"id":"_role_based_access_control_rbac_requirements_in_connections_api"},{"parentId":null,"name":"Validation scope","level":1,"index":2,"id":"_validation_scope"},{"parentId":null,"name":"Using connection annotations based on workload type","level":1,"index":3,"id":"_using_connection_annotations_based_on_workload_type"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-drift-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-explainers/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-llama-stack-external-evaluation-provider-with-lm-evaluation-harness-in-TrustyAI/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-llm-as-a-judge-metrics-with-lmeval/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-pvcs-as-storage/"},"sections":[{"parentId":null,"name":"Managed PVCs","level":1,"index":0,"id":"_managed_pvcs"},{"parentId":null,"name":"Existing PVCs","level":1,"index":1,"id":"_existing_pvcs"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-oci-containers-for-model-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-ragas-with-llama-stack/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-the-cluster-CA-bundle-for-model-serving/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/using-the-cluster-server-and-token-to-authenticate/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/verifying-amd-gpu-availability-on-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-active-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-archived-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-audit-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-bias-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-connected-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-connection-types/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-data-science-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-drift-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-existing-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-feature-store-objects-in-the-web-based-ui/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-http-request-metrics-for-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-installed-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-kueue-alerts-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-metrics-for-the-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-models-in-the-catalog/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-performance-metrics-for-a-nim-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-nvidia-nim-metrics-for-a-nim-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-performance-metrics-for-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-performance-metrics-for-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-pipeline-step-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-pipeline-artifacts/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-pipeline-task-executions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-project-metrics-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-python-packages-installed-on-your-code-server-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-registered-model-versions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-python-packages-installed-on-your-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-registered-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/playground-prerequisites/"},"sections":[{"parentId":null,"name":"Cluster administrator prerequisites","level":1,"index":0,"id":"_cluster_administrator_prerequisites"},{"parentId":null,"name":"User prerequisites","level":1,"index":1,"id":"_user_prerequisites"},{"parentId":null,"name":"Model and runtime requirements for the playground","level":1,"index":2,"id":"_model_and_runtime_requirements_for_the_playground"},{"parentId":"_model_and_runtime_requirements_for_the_playground","name":"Key model selection factors","level":2,"index":0,"id":"_key_model_selection_factors"},{"parentId":"_model_and_runtime_requirements_for_the_playground","name":"Example model configuration","level":2,"index":1,"id":"_example_model_configuration"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/playground-overview/"},"sections":[{"parentId":null,"name":"Core capabilities","level":1,"index":0,"id":"_core_capabilities"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-scheduled-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-the-details-of-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-the-details-of-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-the-details-of-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-the-status-of-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/viewing-traces-in-external-tracing-platforms/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/modules/working-with-hardware-profiles/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-base-training-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-centralized-auth-oidc/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-deleting-users-and-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-feature-definitions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-gpu-time-slicing/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-kserve-deployment-modes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-llama-stack-search-types/"},"sections":[{"parentId":null,"name":"Supported search modes","level":1,"index":0,"id":"_supported_search_modes"},{"parentId":"_supported_search_modes","name":"Keyword search","level":2,"index":0,"id":"_keyword_search"},{"parentId":"_supported_search_modes","name":"Vector search","level":2,"index":1,"id":"_vector_search"},{"parentId":"_supported_search_modes","name":"Hybrid search","level":2,"index":2,"id":"_hybrid_search"},{"parentId":null,"name":"Retrieval database support","level":1,"index":1,"id":"_retrieval_database_support"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-model-serving/"},"sections":[{"parentId":null,"name":"Model serving platform","level":1,"index":0,"id":"_model_serving_platform"},{"parentId":null,"name":"NVIDIA NIM model serving platform","level":1,"index":1,"id":"_nvidia_nim_model_serving_platform"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-organizing-features-by-using-entities/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-persistent-storage/"},"sections":[{"parentId":null,"name":"Storage classes in {productname-short}","level":1,"index":0,"id":"_storage_classes_in_productname_short"},{"parentId":null,"name":"Access modes","level":1,"index":1,"id":"_access_modes"},{"parentId":"_access_modes","name":"Using shared storage (RWX)","level":2,"index":0,"id":"_using_shared_storage_rwx"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-pipeline-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-the-NVIDIA-NIM-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-the-ai-assets-endpoints-page/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-the-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-the-python-index/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/about-workbench-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-authentication-token-for-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-basic-workbenches-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-built-in-alerts/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-hugging-face-models-with-an-environment-variable-token/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-inference-endpoint-for-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-s3-compatible-object-storage-with-self-signed-certificates/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-the-administration-interface-for-basic-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-the-pipeline-editor/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/accessing-your-workbench-ide/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/activating-the-llama-stack-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-connection-to-your-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-custom-model-serving-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-a-tested-and-verified-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-an-application-to-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-an-odh-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-certificates-to-a-cluster-ca-bundle/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-certificates-to-a-custom-ca-bundle/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-cluster-storage-to-your-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-external-artifacts-to-pipeline-run-workspaces/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-feature-definitions-and-initializing-your-feature-store-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-users-to-user-groups/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/adding-workbench-pod-tolerations/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/allocating-additional-resources-to-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/amd-gpu-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/api-custom-image-creating/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/api-workbench-creating/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/api-workbench-overview/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/archiving-a-model-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/archiving-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/archiving-a-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/archiving-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/audience-for-feature-store/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/authenticating-kfp-sdk-with-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/auth-on-llama-stack/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/authenticating-trustyai-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/backing-up-storage-data/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/backing-up-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/before-you-begin/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/benchmarking-embedding-models-with-beir-datasets-and-llama-stack/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/changing-the-storage-class-for-an-existing-cluster-storage-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/cleaning-up-after-deleting-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/cleaning-up-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/clone-an-example-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/collecting-metrics-from-user-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/compare-the-performance-of-osft-and-sft/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/comparing-runs-in-an-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/comparing-runs-in-different-experiments/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/compiling-kubernetes-native-manifests-with-kfp-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/compiling-the-pipeline-yaml-with-kfp-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-certificate-for-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-certificate-for-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-cluster-for-rdma/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-pipeline-server-with-an-external-amazon-rds-db/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-playground-for-your-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-recommended-accelerator-for-serving-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-recommended-accelerator-for-workbench-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-a-training-job-by-using-the-kfto-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-an-inference-service-for-kueue/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-an-inference-service-for-spyre/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-an-offline-store/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-an-online-store/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-and-managing-role-based-access-control/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-authentication-for-llmd/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-custom-namespaces/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-default-workspace-pvc-settings-in-dspa/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-mcp-servers/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-metric-based-autoscaling/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-model-catalog-sources-in-openshift/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-monitoring-for-the-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-monitoring-for-your-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-oidc-auth-gateway-api/"},"sections":[{"parentId":null,"name":"Security considerations","level":1,"index":0,"id":"_security_considerations"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-pipelines-with-your-own-argo-workflows-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-quota-management-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-ragas-remote-provider-for-production/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-role-based-access-control/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-storage-class-settings/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-built-in-detector-and-guardrails-gateway/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-default-pvc-size-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-default-storage-class-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-feature-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-fine-tuning-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-the-operator-logger/"},"sections":[{"parentId":null,"name":"Viewing the {productname-short} Operator logs","level":1,"index":0,"id":"_viewing_the_productname_short_operator_logs"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-trustyai-with-a-database/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/configuring-workload-management-with-kueue/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/controlling-caching-in-pipelines/"},"sections":[{"parentId":null,"name":"Disabling caching for individual tasks","level":1,"index":0,"id":"_disabling_caching_for_individual_tasks"},{"parentId":null,"name":"Disabling caching for a pipeline at submit time","level":1,"index":1,"id":"_disabling_caching_for_a_pipeline_at_submit_time"},{"parentId":null,"name":"Disabling caching for a pipeline at compile time","level":1,"index":2,"id":"_disabling_caching_for_a_pipeline_at_compile_time"},{"parentId":null,"name":"Disabling caching for all pipelines (pipeline server)","level":1,"index":3,"id":"_disabling_caching_for_all_pipelines_pipeline_server"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/copying-files-between-buckets/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-bias-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-bias-metric/"},"sections":[{"parentId":null,"name":"Creating a bias metric by using the dashboard","level":1,"index":0,"id":"creating-a-bias-metric-using-dashboard_{context}"},{"parentId":null,"name":"Creating a bias metric by using the CLI","level":1,"index":1,"id":"creating-a-bias-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-bias-metric-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-custom-image-from-default-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-custom-image-from-your-own-image/"},"sections":[{"parentId":null,"name":"Basic guidelines for creating your own workbench image","level":1,"index":0,"id":"_basic_guidelines_for_creating_your_own_workbench_image"},{"parentId":null,"name":"Advanced guidelines for creating your own workbench image","level":1,"index":1,"id":"_advanced_guidelines_for_creating_your_own_workbench_image"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-custom-training-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-drift-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-drift-metric/"},"sections":[{"parentId":null,"name":"Creating a drift metric by using the CLI","level":1,"index":0,"id":"creating-a-drift-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-feature-store-instance-in-a-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-hardware-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-jupyter-notebook/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-kfto-pytorch-training-script-configmap-resource/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-kfto-pytorchjob-resource-by-using-the-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-kfto-pytorchjob-resource/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-multi-node-pytorch-training-job-with-rdma/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-new-project-for-your-odh-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-project-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-workbench-for-distributed-training/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-a-workbench-select-ide/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-an-s3-client/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-feature-views/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-oci-compatible-connection-types-api/"},"sections":[{"parentId":null,"name":"Using an OCI connection with <code>InferenceService</code> custom resource","level":1,"index":0,"id":"_using_an_oci_connection_with_inferenceservice_custom_resource"},{"parentId":null,"name":"Using an OCI connection with <code>LLMInferenceService</code> custom resource","level":1,"index":1,"id":"_using_an_oci_connection_with_llminferenceservice_custom_resource"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-project-scoped-resources-for-your-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-project-scoped-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-s3-compatible-connection-type-api/"},"sections":[{"parentId":null,"name":"Using an Amazon S3 connection with <code>InferenceService</code> custom resource","level":1,"index":0,"id":"_using_an_amazon_s3_connection_with_inferenceservice_custom_resource"},{"parentId":null,"name":"Using an Amazon S3 connection with <code>LLMInferenceService</code> custom resource","level":1,"index":1,"id":"_using_an_amazon_s3_connection_with_llminferenceservice_custom_resource"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/creating-uri-compatible-connection-type-api/"},"sections":[{"parentId":null,"name":"Using a URI connection with <code>InferenceService</code> custom resource","level":1,"index":0,"id":"_using_a_uri_connection_with_inferenceservice_custom_resource"},{"parentId":null,"name":"Using a URI connection with <code>LLMInferenceService</code> custom resource","level":1,"index":1,"id":"_using_a_uri_connection_with_llminferenceservice_custom_resource"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/customizable-model-serving-runtime-parameters/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/customizing-component-resources/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/customizing-model-selection-options/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/customizing-parameters-serving-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/customizing-the-vllm-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/defining-a-pipeline-by-using-the-kubernetes-api/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/defining-a-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-bias-metric-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-bias-metric-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-bias-metric/"},"sections":[{"parentId":null,"name":"Deleting a bias metric by using the dashboard","level":1,"index":0,"id":"deleting-a-bias-metric-using-dashboard_{context}"},{"parentId":null,"name":"Deleting a bias metric by using the CLI","level":1,"index":1,"id":"deleting-a-bias-metric-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-connection/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-deployed-model-version-from-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-drift-metric-by-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-hardware-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-playground-from-your-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-scheduled-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-a-workbench-from-a-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-an-archived-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-cluster-storage-from-a-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-files-in-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-the-fine-tuning-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deleting-files-in-trash-directory/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-grafana-metrics-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-llama-model-with-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-llamastackdistribution-instance/"},"sections":[{"parentId":null,"name":"Example A: LlamaStackDistribution with <strong>Inline Milvus</strong>","level":1,"index":0,"id":"_example_a_llamastackdistribution_with_inline_milvus"},{"parentId":null,"name":"Example B: LlamaStackDistribution with <strong>Remote Milvus</strong>","level":1,"index":1,"id":"_example_b_llamastackdistribution_with_remote_milvus"},{"parentId":null,"name":"Example C: LlamaStackDistribution with <strong>Inline FAISS</strong>","level":1,"index":2,"id":"_example_c_llamastackdistribution_with_inline_faiss"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-model-from-the-model-catalog/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-model-version-from-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-a-remote-milvus-vector-database/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-model-stored-in-oci-image-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-models-on-the-NVIDIA-NIM-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-models-on-the-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-models-using-distributed-inference/"},"sections":[{"parentId":null,"name":"Configuring authentication for {llmd} using {org-name} Connectivity Link","level":1,"index":0,"id":"configuring-authentication-for-llmd_{context}"},{"parentId":null,"name":"Enabling {llmd}","level":1,"index":1,"id":"enabling-distributed-inference_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-models-using-multiple-gpu-nodes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-models-using-the-single-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-the-guardrails-orchestrator-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/deploying-vllm-gpu-metrics-dashboard-grafana/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/detecting-hateful-and-profane-language/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/detecting-pii-by-using-guardrails-with-llama-stack/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/determining-gpu-requirements-for-llm-powered-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/disabling-applications-connected/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/disabling-component-resource-customization/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/disabling-node-caching-in-elyra/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/disabling-lqlabel-all/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/downloading-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/downloading-files-from-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/downloading-pipeline-step-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-a-bias-metric/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-a-scheduled-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/downloading-the-demo-jupyter-notebooks-from-the-codeflare-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-an-active-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/duplicating-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-an-existing-feature-store-instance/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-model-metadata-in-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-model-version-metadata-in-a-model-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-the-dashboard-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/editing-the-deployment-properties-of-a-model-deployed-by-using-the-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/emptying-trash-directory/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-a-connection-type/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-amd-gpus/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-applications-connected/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-automatic-authentication-and-publishing-features/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-custom-images/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-distributed-inference/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-gpu-time-slicing/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-intel-gaudi-ai-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-kueue-in-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-metrics-for-existing-nim-deployment/"},"sections":[{"parentId":null,"name":"Enabling graph generation for an existing NIM deployment","level":1,"index":0,"id":"_enabling_graph_generation_for_an_existing_nim_deployment"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-nvidia-gpus/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-online-access-and-remote-code-execution-LMEvalJob-using-the-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-feature-store-component/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-model-registry-component/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-nvidia-nim-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-the-observability-stack/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-trustyai-component/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enabling-trustyai-kserve-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/end-to-end-model-customization-workflow/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enforcing-lqlabel-all/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/enforcing-lqlabel-some/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/estimate-memory-usage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/evaluating-rag-system-quality-with-ragas/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/executing-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/explore-the-data-processing-examples/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/explore-the-kubeflow-pipeline-examples/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/explore-the-sdg-hub-examples/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/explore-the-training-hub-examples/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/feature-store-workflow/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/granting-access-to-a-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/exporting-metrics-to-external-observability-tools/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guardrails-auto-config/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guardrails-configuring-the-hugging-face-detector-serving-runtime/"},"sections":[{"parentId":null,"name":"Guardrails Detector Hugging Face serving runtime configuration values","level":1,"index":0,"id":"_guardrails_detector_hugging_face_serving_runtime_configuration_values"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guardrails-configuring-the-opentelemetry-exporter/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guardrails-deploying-the-guardrails-orchestrator-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guardrails-enforcing-configured-safety-pipelines-for-llm-inference-using-guardrails-gateway/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guardrails-filtering-flagged-content-by-sending-requests-to-the-regex-detector/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guardrails-gateway-config-parameters/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guardrails-orchestrator-configmap-parameters/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guardrails-orchestrator-detectors/"},"sections":[{"parentId":null,"name":"Built-in Detector","level":1,"index":0,"id":"_built_in_detector"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guardrails-orchestrator-parameters/"},"sections":[{"parentId":null,"name":"Gateway Pa","level":0,"index":0,"id":"_gateway_pa"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guided-example-build-a-kfp-pipeline-for-sdg/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/guidelines-for-metrics-based-autoscaling/"},"sections":[{"parentId":null,"name":"Choosing metrics for latency and throughput-optimized scaling","level":1,"index":0,"id":"_choosing_metrics_for_latency_and_throughput_optimized_scaling"},{"parentId":null,"name":"Choosing the right sliding window","level":1,"index":1,"id":"_choosing_the_right_sliding_window"},{"parentId":null,"name":"Optimizing HPA scale-down configuration","level":1,"index":2,"id":"_optimizing_hpa_scale_down_configuration"},{"parentId":null,"name":"Considering model size for optimal scaling","level":1,"index":3,"id":"_considering_model_size_for_optimal_scaling"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/hiding-the-default-basic-workbench-application/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ibm-spyre-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/import-example-notebooks/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/importing-a-custom-workbench-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/importing-a-pipeline/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/inference-performance-metrics/"},"sections":[{"parentId":null,"name":"Latency","level":1,"index":0,"id":"_latency"},{"parentId":null,"name":"Throughput","level":1,"index":1,"id":"_throughput"},{"parentId":null,"name":"Cost per million tokens","level":1,"index":2,"id":"_cost_per_million_tokens"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ingesting-content-into-a-llama-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/install-packages/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-extensions-with-code-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-odh-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-python-packages-on-your-code-server-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-python-packages-on-your-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-the-distributed-workloads-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-the-odh-operator-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-the-odh-operator-v2/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-trustyai-service-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-trustyai-service-using-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/intel-gaudi-ai-accelerator-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/installing-trustyai-service/"},"sections":[{"parentId":null,"name":"Installing the TrustyAI service by using the dashboard","level":1,"index":0,"id":"installing-trustyai-service-using-dashboard_{context}"},{"parentId":null,"name":"Installing the TrustyAI service by using the CLI","level":1,"index":1,"id":"installing-trustyai-service-using-cli_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/kueue-workflow/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/labeling-data-fields/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/listing-available-buckets/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/listing-files-in-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/llama-stack-apis/"},"sections":[{"parentId":null,"name":"Supported Llama Stack APIs in {productname-short}","level":1,"index":0,"id":"_supported_llama_stack_apis_in_productname_short"},{"parentId":"_supported_llama_stack_apis_in_productname_short","name":"Agents API","level":2,"index":0,"id":"_agents_api"},{"parentId":"_supported_llama_stack_apis_in_productname_short","name":"Datasets_IO API","level":2,"index":1,"id":"_datasets_io_api"},{"parentId":"_supported_llama_stack_apis_in_productname_short","name":"Evaluation API","level":2,"index":2,"id":"_evaluation_api"},{"parentId":"_supported_llama_stack_apis_in_productname_short","name":"Inference API","level":2,"index":3,"id":"_inference_api"},{"parentId":"_supported_llama_stack_apis_in_productname_short","name":"Safety API","level":2,"index":4,"id":"_safety_api"},{"parentId":"_supported_llama_stack_apis_in_productname_short","name":"Tool Runtime API","level":2,"index":5,"id":"_tool_runtime_api"},{"parentId":"_supported_llama_stack_apis_in_productname_short","name":"Vector_IO API","level":2,"index":6,"id":"_vector_io_api"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/llama-stack-providers-support/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/lmeval-evaluation-job-properties/"},"sections":[{"parentId":null,"name":"Properties for setting up custom Unitxt cards, templates, or system prompts","level":1,"index":0,"id":"_properties_for_setting_up_custom_unitxt_cards_templates_or_system_prompts"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/lmeval-evaluation-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/logging-in/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/making-features-available-for-real-time-inference/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/making-inference-requests-to-models-deployed-on-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/managing-certificates-without-the-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/managing-model-registry-permissions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/managing-ray-clusters-from-within-a-jupyter-notebook/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/migrating-pipelines-from-database-to-kubernetes-api/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/migrating-to-the-rhbok-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/mirror-the-python-index/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/mitigating-prompt-injection-by-using-a-hugging-face-prompt-injection-detector/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/model-serving-runtimes-for-accelerators/"},"sections":[{"parentId":null,"name":"NVIDIA GPUs","level":1,"index":0,"id":"_nvidia_gpus"},{"parentId":null,"name":"Intel Gaudi accelerators","level":1,"index":1,"id":"_intel_gaudi_accelerators"},{"parentId":null,"name":"AMD GPUs","level":1,"index":2,"id":"_amd_gpus"},{"parentId":null,"name":"IBM Spyre AI accelerators on x86 and IBM Z","level":1,"index":3,"id":"_ibm_spyre_ai_accelerators_on_x86_and_ibm_z"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/model-serving-runtimes/"},"sections":[{"parentId":null,"name":"ServingRuntime","level":1,"index":0,"id":"_servingruntime"},{"parentId":null,"name":"InferenceService","level":1,"index":1,"id":"_inferenceservice"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/next-steps-getting-started/"},"sections":[{"parentId":null,"name":"Additional resources","level":1,"index":0,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/next-steps-playground/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/nvidia-gpu-integration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/openai-compatibility-for-rag-apis-in-llama-stack/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/openai-compatible-apis-in-llama-stack/"},"sections":[{"parentId":null,"name":"Supported OpenAI-compatible APIs in {productname-short}","level":1,"index":0,"id":"_supported_openai_compatible_apis_in_productname_short"},{"parentId":"_supported_openai_compatible_apis_in_productname_short","name":"Chat Completions API","level":2,"index":0,"id":"_chat_completions_api"},{"parentId":"_supported_openai_compatible_apis_in_productname_short","name":"Completions API","level":2,"index":1,"id":"_completions_api"},{"parentId":"_supported_openai_compatible_apis_in_productname_short","name":"Embeddings API","level":2,"index":2,"id":"_embeddings_api"},{"parentId":"_supported_openai_compatible_apis_in_productname_short","name":"Files API","level":2,"index":3,"id":"_files_api"},{"parentId":"_supported_openai_compatible_apis_in_productname_short","name":"Vector Stores API","level":2,"index":4,"id":"_vector_stores_api"},{"parentId":"_supported_openai_compatible_apis_in_productname_short","name":"Vector Store Files API","level":2,"index":5,"id":"_vector_store_files_api"},{"parentId":"_supported_openai_compatible_apis_in_productname_short","name":"Models API","level":2,"index":6,"id":"_models_api"},{"parentId":"_supported_openai_compatible_apis_in_productname_short","name":"Responses API","level":2,"index":7,"id":"_responses_api"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/optimizing-the-vllm-runtime/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-for-getting-started/"},"sections":[{"parentId":null,"name":"Data science workflow","level":1,"index":0,"id":"_data_science_workflow"},{"parentId":null,"name":"About this guide","level":1,"index":1,"id":"_about_this_guide"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-accelerators/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-component-resource-customization/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-distributed-workloads/"},"sections":[{"parentId":null,"name":"Distributed workloads infrastructure","level":1,"index":0,"id":"_distributed_workloads_infrastructure"},{"parentId":null,"name":"Types of distributed workloads","level":1,"index":1,"id":"_types_of_distributed_workloads"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-evaluating-ai-systems/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-faiss-vector-databases/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-feature-store/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-kueue-resources/"},"sections":[{"parentId":null,"name":"Resource flavor","level":1,"index":0,"id":"_resource_flavor"},{"parentId":null,"name":"Cluster queue","level":1,"index":1,"id":"_cluster_queue"},{"parentId":null,"name":"Local queue","level":1,"index":2,"id":"_local_queue"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-llama-stack/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-managing-workloads-with-kueue/"},"sections":[{"parentId":null,"name":"Kueue management states","level":1,"index":0,"id":"_kueue_management_states"},{"parentId":null,"name":"Queue enforcement for projects","level":1,"index":1,"id":"_queue_enforcement_for_projects"},{"parentId":null,"name":"Restrictions for managing workloads with Kueue","level":1,"index":2,"id":"_restrictions_for_managing_workloads_with_kueue"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-milvus-vector-databases/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-ml-features/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-model-monitoring/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-model-registries/"},"sections":[{"parentId":null,"name":"Model catalog","level":1,"index":0,"id":"_model_catalog"},{"parentId":null,"name":"Model registry","level":1,"index":1,"id":"_model_registry"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-monitoring-your-ai-systems/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-object-storage-endpoints/"},"sections":[{"parentId":null,"name":"MinIO (On-Cluster)","level":1,"index":0,"id":"_minio_on_cluster"},{"parentId":null,"name":"Amazon S3","level":1,"index":1,"id":"_amazon_s3"},{"parentId":null,"name":"Other S3-Compatible Object Stores","level":1,"index":2,"id":"_other_s3_compatible_object_stores"},{"parentId":null,"name":"Verification and Troubleshooting","level":1,"index":3,"id":"_verification_and_troubleshooting"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-pipeline-experiments/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-pipeline-versions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-pipelines-caching/"},"sections":[{"parentId":null,"name":"Caching criteria","level":1,"index":0,"id":"_caching_criteria"},{"parentId":null,"name":"Viewing cached steps in the {productname-short} user interface","level":1,"index":1,"id":"_viewing_cached_steps_in_the_productname_short_user_interface"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-pipelines-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-rag/"},"sections":[{"parentId":null,"name":"Audience for RAG","level":1,"index":0,"id":"_audience_for_rag"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-the-model-customization-workflow/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-upgrading-odh/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-user-types-and-permissions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/overview-of-vector-databases/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/performance-considerations-for-doc-apps/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/performing-model-evaluations-in-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/playground-overview/"},"sections":[{"parentId":null,"name":"Core capabilities","level":1,"index":0,"id":"_core_capabilities"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/playground-prerequisites/"},"sections":[{"parentId":null,"name":"Cluster administrator prerequisites","level":1,"index":0,"id":"_cluster_administrator_prerequisites"},{"parentId":null,"name":"User prerequisites","level":1,"index":1,"id":"_user_prerequisites"},{"parentId":null,"name":"Model and runtime requirements for the playground","level":1,"index":2,"id":"_model_and_runtime_requirements_for_the_playground"},{"parentId":"_model_and_runtime_requirements_for_the_playground","name":"Key model selection factors","level":2,"index":0,"id":"_key_model_selection_factors"},{"parentId":"_model_and_runtime_requirements_for_the_playground","name":"Example model configuration","level":2,"index":1,"id":"_example_model_configuration"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/preparing-documents-with-docling-for-llama-stack-retrieval/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/preventing-users-from-adding-applications-to-the-dashboard/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/pushing-project-changes-in-code-server-to-a-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/pushing-project-changes-to-a-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/querying-ingested-content-in-a-llama-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/pushing-an-image-to-the-integrated-openshift-image-registry/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/reenabling-component-resource-customization/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-accelerator-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-cpu-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-dashboard-configuration-options/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-default-authorization-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-distributed-inference/"},"sections":[{"parentId":null,"name":"Single-node GPU deployment","level":1,"index":0,"id":"_single_node_gpu_deployment"},{"parentId":null,"name":"Multi-node deployment","level":1,"index":1,"id":"_multi_node_deployment"},{"parentId":null,"name":"Intelligent inference scheduler with KV cache routing","level":1,"index":2,"id":"_intelligent_inference_scheduler_with_kv_cache_routing"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-dockerfile-for-a-kfto-pytorch-training-script/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kfto-pytorch-training-script-fsdp/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kfto-pytorch-training-script-ddp/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kfto-pytorch-training-script-nccl/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kfto-pytorchjob-resource-configured-to-run-with-rdma/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kfto-pytorchjob-resource-for-multi-node-training/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kubernetes-authorization-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-kueue-resource-configurations/"},"sections":[{"parentId":null,"name":"NVIDIA GPUs without shared cohort","level":1,"index":0,"id":"_nvidia_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU resource flavor","level":2,"index":0,"id":"_nvidia_rtx_a400_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU resource flavor","level":2,"index":1,"id":"_nvidia_rtx_a1000_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A400 GPU cluster queue","level":2,"index":2,"id":"_nvidia_rtx_a400_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_without_shared_cohort","name":"NVIDIA RTX A1000 GPU cluster queue","level":2,"index":3,"id":"_nvidia_rtx_a1000_gpu_cluster_queue"},{"parentId":null,"name":"NVIDIA GPUs and AMD GPUs without shared cohort","level":1,"index":1,"id":"_nvidia_gpus_and_amd_gpus_without_shared_cohort"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU resource flavor","level":2,"index":0,"id":"_amd_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU resource flavor","level":2,"index":1,"id":"_nvidia_gpu_resource_flavor"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"AMD GPU cluster queue","level":2,"index":2,"id":"_amd_gpu_cluster_queue"},{"parentId":"_nvidia_gpus_and_amd_gpus_without_shared_cohort","name":"NVIDIA GPU cluster queue","level":2,"index":3,"id":"_nvidia_gpu_cluster_queue"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-oidc-authorization-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-example-pvc-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-grafana-metrics/"},"sections":[{"parentId":null,"name":"Accelerator metrics","level":1,"index":0,"id":"ref-accelerator-metrics_{context}"},{"parentId":null,"name":"CPU metrics","level":1,"index":1,"id":"ref-cpu-metrics_{context}"},{"parentId":null,"name":"vLLM metrics","level":1,"index":2,"id":"ref-vllm-metrics_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-inference-endpoints/"},"sections":[{"parentId":null,"name":"Caikit TGIS ServingRuntime for KServe","level":1,"index":0,"id":"_caikit_tgis_servingruntime_for_kserve"},{"parentId":null,"name":"OpenVINO Model Server","level":1,"index":1,"id":"_openvino_model_server"},{"parentId":null,"name":"vLLM NVIDIA GPU ServingRuntime for KServe","level":1,"index":2,"id":"_vllm_nvidia_gpu_servingruntime_for_kserve"},{"parentId":null,"name":"vLLM Intel Gaudi Accelerator ServingRuntime for KServe","level":1,"index":3,"id":"_vllm_intel_gaudi_accelerator_servingruntime_for_kserve"},{"parentId":null,"name":"vLLM AMD GPU ServingRuntime for KServe","level":1,"index":4,"id":"_vllm_amd_gpu_servingruntime_for_kserve"},{"parentId":null,"name":"vLLM Spyre AI Accelerator ServingRuntime for KServe","level":1,"index":5,"id":"_vllm_spyre_ai_accelerator_servingruntime_for_kserve"},{"parentId":null,"name":"vLLM Spyre s390x ServingRuntime for KServe","level":1,"index":6,"id":"_vllm_spyre_s390x_servingruntime_for_kserve"},{"parentId":null,"name":"NVIDIA Triton Inference Server","level":1,"index":7,"id":"_nvidia_triton_inference_server"},{"parentId":null,"name":"Seldon MLServer","level":1,"index":8,"id":"_seldon_mlserver"},{"parentId":null,"name":"Additional resources","level":1,"index":9,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-supported-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-tested-verified-runtimes/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-trainingclient-api-job-related-methods/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/ref-vllm-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/registering-a-model-from-the-model-catalog/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/registering-a-model-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/registering-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/removing-access-to-a-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/removing-disabled-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/removing-the-ca-bundle-from-a-single-namespace/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/removing-the-ca-bundle-from-all-namespaces/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/requesting-a-lime-explanation-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/requesting-a-lime-explanation/"},"sections":[{"parentId":null,"name":"Requesting a LIME explanation by using the CLI","level":1,"index":0,"id":"requesting-a-lime-explanation-using-CLI_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/requesting-a-shap-explanation-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/requesting-a-shap-explanation/"},"sections":[{"parentId":null,"name":"Requesting a SHAP explanation by using the CLI","level":1,"index":0,"id":"requesting-a-shap-explanation-using-CLI_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/requirements-for-upgrading-odh-v1/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/requirements-for-upgrading-odh-v2/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/restoring-a-model-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/restoring-a-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/restoring-an-archived-pipeline-experiment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/restoring-an-archived-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/restoring-the-default-pvc-size-for-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/retrieving-data-science-features/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/revoking-user-access-to-basic-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-a-pipeline-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-a-training-job-by-using-the-kfto-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-a-workload-with-a-kueue-hardware-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-custom-evaluations-with-LMEval-and-llama-stack/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-distributed-data-science-workloads-disconnected-env/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-distributed-data-science-workloads-from-ai-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-distributed-data-science-workloads-from-jupyter-notebooks/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-the-demo-jupyter-notebooks-from-the-codeflare-sdk/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/running-the-fine-tuning-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/s3-prerequisites/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/scheduling-a-pipeline-run-using-a-cron-job/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/scheduling-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/selecting-admin-and-user-groups/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/sending-training-data-to-trustyai/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/setting-timeout-for-kserve/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/setting-up-feature-store-UI/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/setting-up-lmeval-s3-support/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/setting-up-lmeval/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/setting-up-ragas-inline-provider/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/glossary-of-common-terms/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/exporting-a-pipeline-in-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/setting-up-your-working-environment/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/exporting-your-playground-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/showing-hiding-information-about-available-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/specifying-files-to-ignore/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/specifying-the-data-source-for-features/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/starting-a-basic-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/starting-a-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/starting-basic-workbenches-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/stopping-an-active-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/stopping-basic-workbenches-owned-by-other-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/stopping-idle-workbenches/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/stopping-starting-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/storing-a-model-in-oci-image/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/storing-data-with-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/support-philosophy/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-checking-model-fairness/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-deploying-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-introduction/"},"sections":[{"parentId":null,"name":"About the example models","level":1,"index":0,"id":"_about_the_example_models"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-labeling-data-fields/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-reviewing-the-results/"},"sections":[{"parentId":null,"name":"Are the models biased?","level":1,"index":0,"id":"_are_the_models_biased"},{"parentId":null,"name":"How does the production data compare to the training data?","level":1,"index":1,"id":"_how_does_the_production_data_compare_to_the_training_data"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-scheduling-a-fairness-metric-request/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-scheduling-an-identity-metric-request/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-sending-training-data-to-the-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-setting-up-your-environment/"},"sections":[{"parentId":null,"name":"Downloading the tutorial files","level":1,"index":0,"id":"_downloading_the_tutorial_files"},{"parentId":null,"name":"Logging in to the OpenShift cluster from the command line","level":1,"index":1,"id":"_logging_in_to_the_openshift_cluster_from_the_command_line"},{"parentId":null,"name":"Configuring monitoring for the model serving platform","level":1,"index":2,"id":"_configuring_monitoring_for_the_model_serving_platform"},{"parentId":null,"name":"Enabling the TrustyAI component","level":1,"index":3,"id":"enabling-trustyai-component_{context}"},{"parentId":null,"name":"Setting up a project","level":1,"index":4,"id":"_setting_up_a_project"},{"parentId":null,"name":"Authenticating the TrustyAI service","level":1,"index":5,"id":"_authenticating_the_trustyai_service"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/t-bias-simulating-real-world-data/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/testing-baseline-model-responses/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/testing-with-model-control-protocol-servers/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/testing-your-model-with-rag/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/testing-your-vllm-model-endpoints/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-common-problems-gateway-api/"},"sections":[{"parentId":null,"name":"The <code>GatewayConfig</code> status shows as not ready","level":1,"index":0,"id":"_the_gatewayconfig_status_shows_as_not_ready"},{"parentId":null,"name":"Authentication proxy fails to start","level":1,"index":1,"id":"_authentication_proxy_fails_to_start"},{"parentId":null,"name":"The Gateway is inaccessible","level":1,"index":2,"id":"_the_gateway_is_inaccessible"},{"parentId":null,"name":"The OIDC authentication fails","level":1,"index":3,"id":"_the_oidc_authentication_fails"},{"parentId":null,"name":"The dashboard is not accessible after authentication","level":1,"index":4,"id":"_the_dashboard_is_not_accessible_after_authentication"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-common-problems-in-workbenches-for-administrators/"},"sections":[{"parentId":null,"name":"A user receives a <strong>404: Page not found</strong> error when logging in to Jupyter","level":1,"index":0,"id":"_a_user_receives_a_404_page_not_found_error_when_logging_in_to_jupyter"},{"parentId":null,"name":"A user&#8217;s workbench does not start","level":1,"index":1,"id":"_a_users_workbench_does_not_start"},{"parentId":null,"name":"The user receives a <strong>database or disk is full</strong> error or a <strong>no space left on device</strong> error when they run notebook cells","level":1,"index":2,"id":"_the_user_receives_a_database_or_disk_is_full_error_or_a_no_space_left_on_device_error_when_they_run_notebook_cells"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-common-problems-in-workbenches-for-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-common-problems-with-Kueue/"},"sections":[{"parentId":null,"name":"A user receives a \"failed to call webhook\" error message for Kueue","level":1,"index":0,"id":"_a_user_receives_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":null,"name":"A user receives a \"Default Local Queue &#8230;&#8203; not found\" error message","level":1,"index":1,"id":"_a_user_receives_a_default_local_queue_not_found_error_message"},{"parentId":null,"name":"A user receives a \"local_queue provided does not exist\" error message","level":1,"index":2,"id":"_a_user_receives_a_local_queue_provided_does_not_exist_error_message"},{"parentId":null,"name":"The pod provisioned by Kueue is terminated before the image is pulled","level":1,"index":3,"id":"_the_pod_provisioned_by_kueue_is_terminated_before_the_image_is_pulled"},{"parentId":null,"name":"Additional resources","level":1,"index":4,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-common-problems-with-distributed-workloads-for-administrators/"},"sections":[{"parentId":null,"name":"A user&#8217;s Ray cluster is in a suspended state","level":1,"index":0,"id":"_a_users_ray_cluster_is_in_a_suspended_state"},{"parentId":null,"name":"A user&#8217;s Ray cluster is in a failed state","level":1,"index":1,"id":"_a_users_ray_cluster_is_in_a_failed_state"},{"parentId":null,"name":"A user&#8217;s Ray cluster does not start","level":1,"index":2,"id":"_a_users_ray_cluster_does_not_start"},{"parentId":null,"name":"A user cannot create a Ray cluster or submit jobs","level":1,"index":3,"id":"_a_user_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":null,"name":"Additional resources","level":1,"index":4,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-common-problems-with-distributed-workloads-for-users/"},"sections":[{"parentId":null,"name":"My Ray cluster is in a suspended state","level":1,"index":0,"id":"_my_ray_cluster_is_in_a_suspended_state"},{"parentId":null,"name":"My Ray cluster is in a failed state","level":1,"index":1,"id":"_my_ray_cluster_is_in_a_failed_state"},{"parentId":null,"name":"I see a \"failed to call webhook\" error message for Kueue","level":1,"index":2,"id":"_i_see_a_failed_to_call_webhook_error_message_for_kueue"},{"parentId":null,"name":"My Ray cluster does not start","level":1,"index":3,"id":"_my_ray_cluster_does_not_start"},{"parentId":null,"name":"I see a \"Default Local Queue not found\" error message","level":1,"index":4,"id":"_i_see_a_default_local_queue_not_found_error_message"},{"parentId":null,"name":"I see a \"local_queue provided does not exist\" error message","level":1,"index":5,"id":"_i_see_a_local_queue_provided_does_not_exist_error_message"},{"parentId":null,"name":"I cannot create a Ray cluster or submit jobs","level":1,"index":6,"id":"_i_cannot_create_a_ray_cluster_or_submit_jobs"},{"parentId":null,"name":"My pod provisioned by Kueue is terminated before my image is pulled","level":1,"index":7,"id":"_my_pod_provisioned_by_kueue_is_terminated_before_my_image_is_pulled"},{"parentId":null,"name":"Additional resources","level":1,"index":8,"id":"_additional_resources"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-dspa-component-errors/"},"sections":[{"parentId":null,"name":"Common errors across DSPA components","level":1,"index":0,"id":"_common_errors_across_dspa_components"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/troubleshooting-playground-issues/"},"sections":[{"parentId":null,"name":"The chatbot thinks indefinitely","level":1,"index":0,"id":"_the_chatbot_thinks_indefinitely"},{"parentId":null,"name":"The model does not use RAG data","level":1,"index":1,"id":"_the_model_does_not_use_rag_data"},{"parentId":null,"name":"MCP servers are missing from the UI","level":1,"index":2,"id":"_mcp_servers_are_missing_from_the_ui"},{"parentId":null,"name":"The model fails to call MCP tools","level":1,"index":3,"id":"_the_model_fails_to_call_mcp_tools"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/understanding-certificates/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/understanding-pipeline-run-workspaces/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/understanding-rag-evaluation-providers/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/understanding-rag-settings/"},"sections":[{"parentId":null,"name":"Understanding RAG settings","level":1,"index":0,"id":"understanding-rag-settings_{context}"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-connection/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-hardware-profile/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-project-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-a-runtime-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-access-to-a-project/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-cluster-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-lmeval-job-configuration-using-the-web-console/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-the-deployment-properties-of-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-workbench-settings-by-restarting-your-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-your-playground-configuration/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-your-project-in-code-server-with-changes-from-a-remote-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/updating-your-project-with-changes-from-a-remote-git-repository/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/upgrading-the-odh-operator/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-from-a-git-repository-using-code-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-from-a-git-repository-using-jupyterlab/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-to-code-server-from-a-git-repository-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-to-code-server-from-local-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-to-jupyterlab-from-a-git-repository-using-cli/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-an-existing-notebook-file-to-jupyterlab-from-local-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-files-to-bucket/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-model-files-to-pvc/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/uploading-training-data-to-trustyai/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-a-custom-unitxt-card/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-a-drift-metric-in-a-credit-card-scenario/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-a-kserve-inference-service/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-bias-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-connections-api/"},"sections":[{"parentId":null,"name":"Namespace isolation in connections API","level":1,"index":0,"id":"_namespace_isolation_in_connections_api"},{"parentId":null,"name":"Role-based access control (RBAC) requirements in connections API","level":1,"index":1,"id":"_role_based_access_control_rbac_requirements_in_connections_api"},{"parentId":null,"name":"Validation scope","level":1,"index":2,"id":"_validation_scope"},{"parentId":null,"name":"Using connection annotations based on workload type","level":1,"index":3,"id":"_using_connection_annotations_based_on_workload_type"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-explainers/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-drift-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-llama-stack-external-evaluation-provider-with-lm-evaluation-harness-in-TrustyAI/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-llm-as-a-judge-metrics-with-lmeval/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-oci-containers-for-model-storage/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-pvcs-as-storage/"},"sections":[{"parentId":null,"name":"Managed PVCs","level":1,"index":0,"id":"_managed_pvcs"},{"parentId":null,"name":"Existing PVCs","level":1,"index":1,"id":"_existing_pvcs"}]}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-ragas-with-llama-stack/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-the-cluster-CA-bundle-for-model-serving/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/using-the-cluster-server-and-token-to-authenticate/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/verifying-amd-gpu-availability-on-your-cluster/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-active-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-archived-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-audit-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-bias-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-connected-applications/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-connection-types/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-data-science-users/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-drift-metrics/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-existing-pipelines/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-feature-store-objects-in-the-web-based-ui/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-http-request-metrics-for-a-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-kueue-alerts-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-installed-components/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-metrics-for-the-model-serving-platform/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-nvidia-nim-metrics-for-a-nim-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-models-in-the-catalog/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-performance-metrics-for-a-nim-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-performance-metrics-for-deployed-model/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-performance-metrics-for-model-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-pipeline-artifacts/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-pipeline-step-logs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-pipeline-task-executions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-project-metrics-for-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-python-packages-installed-on-your-code-server-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-python-packages-installed-on-your-workbench/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-registered-model-versions/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-registered-models/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-scheduled-pipeline-runs/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-the-details-of-a-pipeline-run/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-the-details-of-a-pipeline-server/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-the-details-of-a-pipeline-version/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-the-status-of-distributed-workloads/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/viewing-traces-in-external-tracing-platforms/"},"sections":null}}},{"node":{"childAsciidoc":{"fields":{"slug":"/docs/assemblies/modules/working-with-hardware-profiles/"},"sections":null}}}]},"asciidoc":{"html":"<div id=\"toc\" class=\"toc\">\n<div id=\"toctitle\">Table of Contents</div>\n<ul class=\"sectlevel1\">\n<li><a href=\"#managing-users-and-groups\">Managing users and groups</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#overview-of-user-types-and-permissions_managing-odh\">Overview of user types and permissions</a></li>\n<li><a href=\"#viewing-data-science-users_managing-odh\">Viewing Open Data Hub users</a></li>\n<li><a href=\"#adding-users-to-user-groups_managing-odh\">Adding users to Open Data Hub user groups</a></li>\n<li><a href=\"#selecting-admin-and-user-groups_managing-odh\">Selecting Open Data Hub administrator and user groups</a></li>\n<li><a href=\"#_deleting_users\">Deleting users</a></li>\n</ul>\n</li>\n<li><a href=\"#creating-custom-workbench-images\">Creating custom workbench images</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#creating-a-custom-image-from-default-image_custom-images\">Creating a custom image from a default Open Data Hub image</a></li>\n<li><a href=\"#creating-a-custom-image-from-your-own-image_custom-images\">Creating a custom image from your own image</a></li>\n<li><a href=\"#enabling-custom-images_custom-images\">Enabling custom images in Open Data Hub</a></li>\n<li><a href=\"#importing-a-custom-workbench-image_custom-images\">Importing a custom workbench image</a></li>\n</ul>\n</li>\n<li><a href=\"#managing-applications-that-show-in-the-dashboard\">Managing applications that show in the dashboard</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#adding-an-application-to-the-dashboard_dashboard\">Adding an application to the dashboard</a></li>\n<li><a href=\"#preventing-users-from-adding-applications-to-the-dashboard_dashboard\">Preventing users from adding applications to the dashboard</a></li>\n<li><a href=\"#disabling-applications-connected_dashboard\">Disabling applications connected to Open Data Hub</a></li>\n<li><a href=\"#showing-hiding-information-about-available-applications_dashboard\">Showing or hiding information about available applications</a></li>\n<li><a href=\"#hiding-the-default-basic-workbench-application_dashboard\">Hiding the default basic workbench application</a></li>\n</ul>\n</li>\n<li><a href=\"#creating-project-scoped-resources_managing-odh\">Creating project-scoped resources</a></li>\n<li><a href=\"#allocating-additional-resources-to-users_managing-odh\">Allocating additional resources to Open Data Hub users</a></li>\n<li><a href=\"#customizing-component-deployment-resources_managing-resources\">Customizing component deployment resources</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#overview-of-component-resource-customization_managing-resources\">Overview of component resource customization</a></li>\n<li><a href=\"#customizing-component-resources_managing-resources\">Customizing component resources</a></li>\n<li><a href=\"#disabling-component-resource-customization_managing-resources\">Disabling component resource customization</a></li>\n<li><a href=\"#reenabling-component-resource-customization_managing-resources\">Re-enabling component resource customization</a></li>\n</ul>\n</li>\n<li><a href=\"#enabling-accelerators\">Enabling accelerators</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#enabling-nvidia-gpus_managing-odh\">Enabling NVIDIA GPUs</a></li>\n<li><a href=\"#intel-gaudi-ai-accelerator-integration_managing-odh\">Intel Gaudi AI Accelerator integration</a></li>\n<li><a href=\"#amd-gpu-integration_managing-odh\">AMD GPU Integration</a></li>\n</ul>\n</li>\n<li><a href=\"#managing-workloads-with-kueue\">Managing workloads with Kueue</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#overview-of-managing-workloads-with-kueue_kueue\">Overview of managing workloads with Kueue</a></li>\n<li><a href=\"#configuring-workload-management-with-kueue_kueue\">Configuring workload management with Kueue</a></li>\n<li><a href=\"#troubleshooting-common-problems-with-Kueue_kueue\">Troubleshooting common problems with Kueue</a></li>\n<li><a href=\"#migrating-to-the-rhbok-operator_kueue\">Migrating to the Red Hat build of Kueue Operator</a></li>\n</ul>\n</li>\n<li><a href=\"#managing-distributed-workloads_managing-odh\">Managing distributed workloads</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#configuring-quota-management-for-distributed-workloads_managing-odh\">Configuring quota management for distributed workloads</a></li>\n<li><a href=\"#ref-example-kueue-resource-configurations_managing-odh\">Example Kueue resource configurations for distributed workloads</a></li>\n<li><a href=\"#configuring-a-cluster-for-rdma_managing-odh\">Configuring a cluster for RDMA</a></li>\n<li><a href=\"#troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh\">Troubleshooting common problems with distributed workloads for administrators</a></li>\n</ul>\n</li>\n<li><a href=\"#configuring-external-oidc-provider_managing-odh\">Configuring a central authentication service for an external OIDC identity provider</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#about-centralized-auth-oidc_managing-odh\">About centralized authentication Gateway API</a></li>\n<li><a href=\"#configuring-oidc-auth-gateway-api_managing-odh\">Configuring OpenID Connect (OIDC) authentication for Gateway API</a></li>\n<li><a href=\"#troubleshooting-common-problems-gateway-api_managing-odh\">Troubleshooting common problems with Gateway API configuration</a></li>\n</ul>\n</li>\n<li><a href=\"#backing-up-data_data-mgmt\">Backing up data</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#backing-up-storage-data_data-mgmt\">Backing up storage data</a></li>\n<li><a href=\"#backing-up-your-cluster_data-mgmt\">Backing up your cluster</a></li>\n</ul>\n</li>\n<li><a href=\"#managing-observability_managing-odh\">Managing observability</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#enabling-the-observability-stack_managing-odh\">Enabling the observability stack</a></li>\n<li><a href=\"#collecting-metrics-from-user-workloads_managing-odh\">Collecting metrics from user workloads</a></li>\n<li><a href=\"#exporting-metrics-to-external-observability-tools_managing-odh\">Exporting metrics to external observability tools</a></li>\n<li><a href=\"#viewing-traces-in-external-tracing-platforms_managing-odh\">Viewing traces in external tracing platforms</a></li>\n<li><a href=\"#accessing-built-in-alerts_managing-odh\">Accessing built-in alerts</a></li>\n</ul>\n</li>\n<li><a href=\"#viewing-logs-and-audit-records_managing-odh\">Viewing logs and audit records</a>\n<ul class=\"sectlevel2\">\n<li><a href=\"#configuring-the-operator-logger_managing-odh\">Configuring the Open Data Hub Operator logger</a></li>\n<li><a href=\"#viewing-audit-records_managing-odh\">Viewing audit records</a></li>\n</ul>\n</li>\n</ul>\n</div>\n<div id=\"preamble\">\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>As an OpenShift cluster administrator, you can manage the following Open Data Hub resources:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Users and groups</p>\n</li>\n<li>\n<p>Custom workbench images</p>\n</li>\n<li>\n<p>Applications that show in the dashboard</p>\n</li>\n<li>\n<p>Custom deployment resources that are related to the Open Data Hub Operator, for example, CPU and memory limits and requests</p>\n</li>\n<li>\n<p>Accelerators</p>\n</li>\n<li>\n<p>Workload resources with Kueue</p>\n</li>\n<li>\n<p>Workload metrics</p>\n</li>\n<li>\n<p>Configure external OIDC identity providers</p>\n</li>\n<li>\n<p>Data backup</p>\n</li>\n<li>\n<p>Monitoring and observability</p>\n</li>\n<li>\n<p>Logs and audit records</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"managing-users-and-groups\">Managing users and groups</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>Users with administrator access to OpenShift Container Platform can add, modify, and remove user permissions for Open Data Hub.</p>\n</div>\n<div class=\"sect2\">\n<h3 id=\"overview-of-user-types-and-permissions_managing-odh\">Overview of user types and permissions</h3>\n<div class=\"paragraph\">\n<p>Table 1 describes the Open Data Hub user types.</p>\n</div>\n<table class=\"tableblock frame-all grid-all stretch\">\n<caption class=\"title\">Table 1. User types</caption>\n<colgroup>\n<col style=\"width: 16.6666%;\">\n<col style=\"width: 83.3334%;\">\n</colgroup>\n<thead>\n<tr>\n<th class=\"tableblock halign-left valign-top\">User Type</th>\n<th class=\"tableblock halign-left valign-top\">Permissions</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Users</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Machine learning operations (MLOps) engineers and data scientists can access and use individual components of Open Data Hub, such as workbenches and AI pipelines.</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Administrators</p></td>\n<td class=\"tableblock halign-left valign-top\"><div class=\"content\"><div class=\"paragraph\">\n<p>In addition to the actions permitted to users, administrators can perform these actions:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Configure Open Data Hub settings.</p>\n</li>\n<li>\n<p>Access and manage workbenches.</p>\n</li>\n<li>\n<p>Access and manage pipeline applications for any project.</p>\n</li>\n</ul>\n</div></div></td>\n</tr>\n</tbody>\n</table>\n<div class=\"paragraph\">\n<p>By default, all OpenShift users have access to Open Data Hub. In addition, users in the OpenShift administrator group (<code>cluster admins</code>), automatically have administrator access in Open Data Hub.</p>\n</div>\n<div class=\"paragraph\">\n<p>Optionally, if you want to restrict access to your Open Data Hub deployment to specific users or groups, you can create user groups for users and administrators.</p>\n</div>\n<div class=\"paragraph\">\n<p>If you decide to restrict access, and you already have groups defined in your configured identity provider, you can add these groups to your Open Data Hub deployment. If you decide to use groups without adding these groups from an identity provider, you must create the groups in OpenShift Container Platform and then add users to them.</p>\n</div>\n<div class=\"paragraph\">\n<p>There are some operations relevant to Open Data Hub that require the <code>cluster-admin</code> role. Those operations include:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Adding users to the Open Data Hub user and administrator groups, if you are using groups.</p>\n</li>\n<li>\n<p>Removing users from the Open Data Hub user and administrator groups, if you are using groups.</p>\n</li>\n<li>\n<p>Managing custom environment and storage configuration for users in OpenShift Container Platform, such as Jupyter notebook resources, ConfigMaps, and persistent volume claims (PVCs).</p>\n</li>\n</ul>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Although users of Open Data Hub and its components are authenticated through OpenShift, session management is separate from authentication.\nThis means that logging out of OpenShift Container Platform or Open Data Hub does not affect a logged in Jupyter session running on those platforms.\nThis means that when a user&#8217;s permissions change, that user must log out of all current sessions in order for the changes to take effect.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"viewing-data-science-users_managing-odh\">Viewing Open Data Hub users</h3>\n<div class=\"paragraph\">\n<div class=\"title\">Additional resources</div>\n<p>If you have defined Open Data Hub user groups, you can view the users that belong to these groups.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>The Open Data Hub user group, administrator group, or both exist.</p>\n</li>\n<li>\n<p>You have the <code>cluster-admin</code> role in OpenShift Container Platform.</p>\n</li>\n<li>\n<p>You have configured a supported identity provider for OpenShift Container Platform.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform web console, click <strong>User Management</strong> &#8594; <strong>Groups</strong>.</p>\n</li>\n<li>\n<p>Click the name of the group containing the users that you want to view.</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>For administrative users, click the name of your administrator group. for example, <code>odh-admins</code>.</p>\n</li>\n<li>\n<p>For normal users, click the name of your user group, for example, <code>odh-users</code>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Group details</strong> page for the group is displayed.</p>\n</div>\n</li>\n</ul>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>In the <strong>Users</strong> section for the relevant group, you can view the users who have permission to access Open Data Hub.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"adding-users-to-user-groups_managing-odh\">Adding users to Open Data Hub user groups</h3>\n<div class=\"paragraph\">\n<p>By default, all OpenShift users have access to Open Data Hub.</p>\n</div>\n<div class=\"paragraph\">\n<p>Optionally, you can restrict user access to your Open Data Hub instance by defining user groups. You must grant users permission to access Open Data Hub by adding user accounts to the Open Data Hub user group, administrator group, or both. You can either use the default group name, or specify a group name that already exists in your identity provider.</p>\n</div>\n<div class=\"paragraph\">\n<p>The <strong>user group</strong> provides the user with access to product components in the Open Data Hub dashboard, such as AI pipelines, and associated services, such as Jupyter. By default, users in the <strong>user group</strong> have access to AI pipeline applications within projects that they created.</p>\n</div>\n<div class=\"paragraph\">\n<p>The <strong>administrator group</strong> provides the user with access to developer and administrator functions in the Open Data Hub dashboard, such as AI pipelines, and associated services, such as Jupyter. Users in the <strong>administrator group</strong> can configure AI pipeline applications in the Open Data Hub dashboard for any project.</p>\n</div>\n<div class=\"paragraph\">\n<p>If you restrict access by using user groups, users that are not in the Open Data Hub user group or administrator group cannot view the dashboard and use associated services, such as Jupyter. They are also unable to access the <strong>Cluster settings</strong> page.</p>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>If you are using LDAP as your identity provider, you need to configure LDAP syncing to OpenShift Container Platform. For more information, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/authentication_and_authorization/ldap-syncing\">Syncing LDAP groups</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"paragraph\">\n<p>Follow the steps in this section to add users to your Open Data Hub administrator and user groups.</p>\n</div>\n<div class=\"paragraph\">\n<p>Note: You can add users in Open Data Hub but you must manage the user lists in the OpenShift Container Platform web console.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have configured a supported identity provider for OpenShift Container Platform.</p>\n</li>\n<li>\n<p>You are assigned the <code>cluster-admin</code> role in OpenShift Container Platform.</p>\n</li>\n<li>\n<p>You have defined an administrator group and user group for Open Data Hub.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform web console, click <strong>User Management</strong> &#8594; <strong>Groups</strong>.</p>\n</li>\n<li>\n<p>Click the name of the group you want to add users to.</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>For administrative users, click the administrator group, for example, <code>odh-admins</code>.</p>\n</li>\n<li>\n<p>For normal users, click the user group, for example, <code>odh-users</code>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Group details</strong> page for that group opens.</p>\n</div>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Click <strong>Actions</strong> &#8594; <strong>Add Users</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Add Users</strong> dialog opens.</p>\n</div>\n</li>\n<li>\n<p>In the <strong>Users</strong> field, enter the relevant user name to add to the group.</p>\n</li>\n<li>\n<p>Click <strong>Save</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Click the <strong>Details</strong> tab for each group and confirm that the <strong>Users</strong> section contains the user names that you added.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"selecting-admin-and-user-groups_managing-odh\">Selecting Open Data Hub administrator and user groups</h3>\n<div class=\"paragraph\">\n<p>By default, all users authenticated in OpenShift can access Open Data Hub.</p>\n</div>\n<div class=\"paragraph\">\n<p>Also by default, users with <code>cluster-admin</code> permissions are Open Data Hub administrators. A <code>cluster admin</code> is a superuser that can perform any action in any project in the OpenShift cluster. When bound to a user with a local binding, they have full control over quota and every action on every resource in the project.</p>\n</div>\n<div class=\"paragraph\">\n<p>After a <code>cluster admin</code> user defines additional administrator and user groups in OpenShift, you can add those groups to Open Data Hub by selecting them in the Open Data Hub dashboard.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n<li>\n<p>The groups that you want to select as administrator and user groups for Open Data Hub already exist in OpenShift Container Platform. For more information, see\n<a href=\"https://opendatahub.io/docs/managing-odh/#managing-users-and-groups\">Managing users and groups</a>.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Settings</strong> &#8594; <strong>User management</strong>.</p>\n</li>\n<li>\n<p>Select your Open Data Hub administrator groups: Under <strong>Open Data Hub administrator groups</strong>, click the text box and select an OpenShift group. Repeat this process to define multiple administrator groups.</p>\n</li>\n<li>\n<p>Select your Open Data Hub user groups: Under <strong>Open Data Hub user groups</strong>, click the text box and select an OpenShift group. Repeat this process to define multiple user groups.</p>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\nThe <code>system:authenticated</code> setting allows all users authenticated in OpenShift to access Open Data Hub.\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>Click <strong>Save changes</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Administrator users can successfully log in to Open Data Hub and have access to the <strong>Settings</strong> navigation menu.</p>\n</li>\n<li>\n<p>Non-administrator users can successfully log in to Open Data Hub. They can also access and use individual components, such as projects and workbenches.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"_deleting_users\">Deleting users</h3>\n<div class=\"sect3\">\n<h4 id=\"about-deleting-users-and-resources_managing-odh\">About deleting users and their resources</h4>\n<div class=\"paragraph\">\n<p>If you have administrator access to OpenShift Container Platform, you can revoke a user&#8217;s access to workbenches and delete the user&#8217;s resources from Open Data Hub. Before you delete a user from Open Data Hub, it is good practice to back up the data on your persistent volume claims (PVCs).</p>\n</div>\n<div class=\"paragraph\">\n<p>Deleting a user and the user&#8217;s resources involves the following tasks:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Stop workbenches owned by the user.</p>\n</li>\n<li>\n<p>Revoke user access to workbenches.</p>\n</li>\n<li>\n<p>Remove the user from the allowed group in your OpenShift identity provider.</p>\n</li>\n<li>\n<p>After you delete a user, delete their associated configuration files from OpenShift Container Platform.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"stopping-basic-workbenches-owned-by-other-users_managing-odh\">Stopping basic workbenches owned by other users</h4>\n<div class=\"paragraph _abstract\">\n<p>Open Data Hub administrators can stop basic workbenches that are owned by other users to reduce resource consumption on the cluster, or as part of removing a user and their resources from the cluster.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n<li>\n<p>You have launched the <strong>Start basic workbench</strong> application, as described in <a href=\"https://opendatahub.io/docs/working-with-connected-applications/#starting-a-basic-workbench_connected-apps\">Starting a basic workbench</a>.</p>\n</li>\n<li>\n<p>The workbench that you want to stop is running.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>On the page that opens when you launch a basic workbench, click the <strong>Administration</strong> tab.</p>\n</li>\n<li>\n<p>Stop one or more servers.</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>If you want to stop one or more specific servers, perform the following actions:</p>\n<div class=\"olist lowerroman\">\n<ol class=\"lowerroman\" type=\"i\">\n<li>\n<p>In the <strong>Users</strong> section, locate the user that the workbench belongs to.</p>\n</li>\n<li>\n<p>To stop the workbench, perform one of the following actions:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Click the action menu (<strong>&#8942;</strong>) beside the relevant user and select <strong>Stop server</strong>.</p>\n</li>\n<li>\n<p>Click <strong>View server</strong> beside the relevant user and then click <strong>Stop workbench</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Stop server</strong> dialog box opens.</p>\n</div>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Click <strong>Stop server</strong>.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>If you want to stop all workbenches, perform the following actions:</p>\n<div class=\"olist lowerroman\">\n<ol class=\"lowerroman\" type=\"i\">\n<li>\n<p>Click the <strong>Stop all workbenches</strong> button.</p>\n</li>\n<li>\n<p>Click <strong>OK</strong> to confirm stopping all servers.</p>\n</li>\n</ol>\n</div>\n</li>\n</ul>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The <strong>Stop server</strong> link beside each server changes to a <strong>Start workbench</strong> link when the workbench has stopped.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"revoking-user-access-to-basic-workbenches_managing-odh\">Revoking user access to basic workbenches</h4>\n<div class=\"paragraph _abstract\">\n<p>You can revoke a user&#8217;s access to basic workbenches by removing the user from the Open Data Hub user groups that define access to Open Data Hub. When you remove a user from the user groups, the user is prevented from accessing the Open Data Hub dashboard and from using associated services that consume resources in your cluster.</p>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\nFollow these steps only if you have implemented Open Data Hub user groups to restrict access to Open Data Hub. To completely remove a user from Open Data Hub, you must remove them from the allowed group in your OpenShift identity provider.\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have stopped any workbenches owned by the user you want to delete.</p>\n</li>\n<li>\n<p>You are using Open Data Hub user groups, and the user is part of the user group, administrator group, or both.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform web console, click <strong>User Management</strong> &#8594; <strong>Groups</strong>.</p>\n</li>\n<li>\n<p>Click the name of the group that you want to remove the user from.</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>For administrative users, click the name of your administrator group, for example, <code>odh-admins</code>.</p>\n</li>\n<li>\n<p>For non-administrator users, click the name of your user group, for example, <code>odh-users</code>.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>The <strong>Group details</strong> page for the group is displayed.</p>\n</div>\n</li>\n<li>\n<p>In the <strong>Users</strong> section on the <strong>Details</strong> tab, locate the user that you want to remove.</p>\n</li>\n<li>\n<p>Click the action menu (<strong>&#8942;</strong>) beside the user that you want to remove and click <strong>Remove user</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>In the <strong>Users</strong> section on the <strong>Details</strong> tab of the <strong>Group details</strong> page, confirm that the user that you removed is not visible.\nIn <strong>Workloads</strong> &#8594; <strong>Pods</strong>, select the default workbench project (<code>opendatahub</code> or your custom workbench namespace), and ensure that there is no workbench pod for this user. If you see a pod named <code>jupyter-nb-&lt;username&gt;-*</code> for the user that you have removed, delete that pod to ensure that the deleted user is not consuming resources on the cluster.</p>\n</li>\n<li>\n<p>In the Open Data Hub dashboard, check the list of projects. Delete any projects that belong to the user.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"backing-up-storage-data_managing-odh\">Backing up storage data</h4>\n<div class=\"paragraph _abstract\">\n<p>It is a best practice to back up the data on your persistent volume claims (PVCs) regularly.</p>\n</div>\n<div class=\"paragraph\">\n<p>Backing up your data is particularly important before you delete a user and before you uninstall Open Data Hub, as all PVCs are deleted when Open Data Hub is uninstalled.</p>\n</div>\n<div class=\"paragraph\">\n<p>For more information about backing up PVCs for your cluster platform, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/backup_and_restore/oadp-application-backup-and-restore.html\">OADP Application backup and restore</a> in the OpenShift Container Platform documentation.</p>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/storage/understanding-persistent-storage\">Understanding persistent storage</a></p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"cleaning-up-after-deleting-users_managing-odh\">Cleaning up after deleting users</h4>\n<div class=\"paragraph _abstract\">\n<p>After you remove a user&#8217;s access to Open Data Hub, you must also delete the configuration files for the user from OpenShift Container Platform.\nRed&#160;Hat recommends that you back up the user&#8217;s data before removing their configuration files.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>(Optional) If you want to completely remove the user&#8217;s access to Open Data Hub, you have removed their credentials from your identity provider.</p>\n</li>\n<li>\n<p>You have logged in to the OpenShift Container Platform web console as a user with the <code>cluster-admin</code> role.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Delete the user&#8217;s persistent volume claim (PVC).</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Click <strong>Storage</strong> &#8594; <strong>PersistentVolumeClaims</strong>.</p>\n</li>\n<li>\n<p>If it is not already selected, select the default workbench project (<code>opendatahub</code> or your custom workbench namespace) from the project list.</p>\n</li>\n<li>\n<p>Locate the  <code>jupyter-nb-&lt;username&gt;</code> PVC.</p>\n<div class=\"paragraph\">\n<p>Replace <code>&lt;username&gt;</code> with the relevant user name.</p>\n</div>\n</li>\n<li>\n<p>Click the action menu (&#8942;) and select <strong>Delete PersistentVolumeClaim</strong> from the list.</p>\n<div class=\"paragraph\">\n<p>The <strong>Delete PersistentVolumeClaim</strong> dialog opens.</p>\n</div>\n</li>\n<li>\n<p>Inspect the dialog and confirm that you are deleting the correct PVC.</p>\n</li>\n<li>\n<p>Click <strong>Delete</strong>.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Delete the user&#8217;s ConfigMap.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Click <strong>Workloads</strong> &#8594; <strong>ConfigMaps</strong>.</p>\n</li>\n<li>\n<p>If it is not already selected, select the default workbench project (<code>opendatahub</code> or your custom workbench namespace) from the project list.</p>\n</li>\n<li>\n<p>Locate the <code>jupyterhub-singleuser-profile-&lt;username&gt;</code> ConfigMap.</p>\n<div class=\"paragraph\">\n<p>Replace <code>&lt;username&gt;</code> with the relevant user name.</p>\n</div>\n</li>\n<li>\n<p>Click the action menu (&#8942;) and select <strong>Delete ConfigMap</strong> from the list.</p>\n<div class=\"paragraph\">\n<p>The <strong>Delete ConfigMap</strong> dialog opens.</p>\n</div>\n</li>\n<li>\n<p>Inspect the dialog and confirm that you are deleting the correct ConfigMap.</p>\n</li>\n<li>\n<p>Click <strong>Delete</strong>.</p>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The user cannot access Open Data Hub and sees an \"Access permission needed\" message if they try.</p>\n</li>\n<li>\n<p>The user&#8217;s single-user profile, persistent volume claim (PVC), and ConfigMap are not visible in OpenShift Container Platform.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"creating-custom-workbench-images\">Creating custom workbench images</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>Open Data Hub includes a selection of default workbench images that a data scientist can select when they create or edit a workbench.</p>\n</div>\n<div class=\"paragraph\">\n<p>In addition, you can import a custom workbench image, for example, if you want to add libraries that data scientists often use, or if your data scientists require a specific version of a library that is different from the version provided in a default image. Custom workbench images are also useful if your data scientists require operating system packages or applications because they cannot install them directly in their running environment (data scientist users do not have root access, which is needed for those operations).</p>\n</div>\n<div class=\"paragraph\">\n<p>A custom workbench image is simply a container image. You build one as you would build any standard container image, by using a Containerfile (or Dockerfile). You start from an existing image (the <code>FROM</code> instruction), and then add your required elements.</p>\n</div>\n<div class=\"paragraph\">\n<p>You have the following options for creating a custom workbench image:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Start from one of the default images, as described in <a href=\"https://opendatahub.io/docs/managing-odh/#creating-a-custom-image-from-default-image_custom-images\">Creating a custom image from a default Open Data Hub image</a>.</p>\n</li>\n<li>\n<p>Create your own image by following the guidelines for making it compatible with Open Data Hub, as described in <a href=\"https://opendatahub.io/docs/managing-odh/#creating-a-custom-image-from-your-own-image_custom-images\">Creating a custom image from your own image</a>.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Additional resources</div>\n<p>For more information about creating images, see the following resources:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/images/creating-images\">Red Hat OpenShift Container Platform - Creating Images</a></p>\n</li>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/red_hat_openshift_service_on_aws/4/html/images/creating-images#creating-images\">Red&#160;Hat OpenShift Service on AWS - Creating images</a></p>\n</li>\n<li>\n<p><a href=\"https://docs.docker.com/engine/reference/builder/\">Red Hat OpenShift Dedicated - Dockerfile reference documentation</a></p>\n</li>\n</ul>\n</div>\n<div class=\"sect2\">\n<h3 id=\"creating-a-custom-image-from-default-image_custom-images\">Creating a custom image from a default Open Data Hub image</h3>\n<div class=\"paragraph\">\n<p>After Open Data Hub is installed on a cluster, you can find the default workbench images in the OpenShift console, under <strong>Builds</strong> &#8594; <strong>ImageStreams</strong> for the <code>redhat-ods-applications</code> project.</p>\n</div>\n<div class=\"paragraph\">\n<p>You can create a custom image by adding OS packages or applications to a default Open Data Hub image.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You know which default image you want to use as the base for your custom image.</p>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>If you want to create a custom Elyra-compatible image, the base image must be an Open Data Hub image that contains the Elyra extension.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>You have <code>cluster-admin</code> access to the OpenShift console for the cluster where Open Data Hub is installed.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Obtain the location of the default image that you want to use as the base for your custom image.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift console, select <strong>Builds</strong> &#8594; <strong>ImageStreams</strong>.</p>\n</li>\n<li>\n<p>Select the <strong>redhat-ods-applications</strong> project.</p>\n</li>\n<li>\n<p>From the list of installed imagestreams, click the name of the image that you want to use as the base for your custom image. For example, click <strong>pytorch</strong>.</p>\n</li>\n<li>\n<p>On the ImageStream details page, click <strong>YAML</strong>.</p>\n</li>\n<li>\n<p>In the <code>spec:tags</code> section, find the tag for the version of the image that you want to use.</p>\n<div class=\"paragraph\">\n<p>The location of the original image is shown in the tag&#8217;s <code>from:name</code> section, for example:</p>\n</div>\n<div class=\"paragraph\">\n<p><code>name: 'quay.io/modh/odh-pytorch-notebook@sha256:b68e0192abf7d'</code></p>\n</div>\n</li>\n<li>\n<p>Copy this location for use in your custom image.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Create a standard Containerfile or Dockerfile.</p>\n</li>\n<li>\n<p>For the <code>FROM</code> instruction, specify the base image location that you copied in Step 1, for example:</p>\n<div class=\"paragraph\">\n<p><code>FROM quay.io/modh/odh-pytorch-notebook@sha256:b68e0</code></p>\n</div>\n</li>\n<li>\n<p>Optional: Install OS images:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Switch to <code>USER 0</code> (USER 0 is required to install OS packages).</p>\n</li>\n<li>\n<p>Install the packages.</p>\n</li>\n<li>\n<p>Switch back to <code>USER 1001</code>.</p>\n<div class=\"paragraph\">\n<p>The following example creates a custom workbench image that adds Java to the default PyTorch image:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code> FROM quay.io/modh/odh-pytorch-notebook@sha256:b68e0\n\n USER 0\n\n RUN INSTALL_PKGS=\"java-11-openjdk java-11-openjdk-devel\" &amp;&amp; \\\n    dnf install -y --setopt=tsflags=nodocs $INSTALL_PKGS &amp;&amp; \\\n    dnf -y clean all --enablerepo=<em>*</em>\n\n USER 1001</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Optional: Add Python packages:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Specify <code>USER 1001</code>.</p>\n</li>\n<li>\n<p>Copy the <code>requirements.txt</code> file.</p>\n</li>\n<li>\n<p>Install the packages.</p>\n<div class=\"paragraph\">\n<p>The following example installs packages from the <code>requirements.txt</code> file in the default PyTorch image:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code> FROM quay.io/modh/odh-pytorch-notebook@sha256:b68e0\n\n USER 1001\n\n COPY requirements.txt ./requirements.txt\n\n RUN pip install -r requirements.txt</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Build the image file. For example, you can use <code>podman build</code> locally where the image file is located and then push the image to a registry that is accessible to Open Data Hub:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>$ podman build -t my-registry/my-custom-image:0.0.1 .\n$ podman push my-registry/my-custom-image:0.0.1</pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>Alternatively, you can leverage OpenShift&#8217;s image build capabilities by using <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/builds_using_buildconfig/understanding-buildconfigs\">BuildConfig</a>.</p>\n</div>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"creating-a-custom-image-from-your-own-image_custom-images\">Creating a custom image from your own image</h3>\n<div class=\"paragraph\">\n<p>You can build your own custom image. However, you must make sure that your image is compatible with OpenShift and Open Data Hub.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/images/creating-images#images-create-guide-general_create-images\">General Container image guidelines section</a> in the OpenShift Container Platform Images documentation.</p>\n</li>\n<li>\n<p>Red Hat Universal Base Image: <a href=\"https://catalog.redhat.com/software/base-images\" class=\"bare\">https://catalog.redhat.com/software/base-images</a></p>\n</li>\n<li>\n<p>Red Hat Ecosystem Catalog: <a href=\"https://catalog.redhat.com/\" class=\"bare\">https://catalog.redhat.com/</a></p>\n</li>\n</ul>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_basic_guidelines_for_creating_your_own_workbench_image\">Basic guidelines for creating your own workbench image</h4>\n<div class=\"paragraph\">\n<p>The following basic guidelines provide information to consider when you build your own custom workbench image.</p>\n</div>\n<div class=\"paragraph\">\n<p><strong>Designing your image to run with USER 1001</strong></p>\n</div>\n<div class=\"paragraph\">\n<p>In OpenShift, your container will run with a random UID and a GID of <code>0</code>. Make sure that your image is compatible with these user and group requirements, especially if you need write access to directories. Best practice is to design your image to run with <code>USER 1001</code>.</p>\n</div>\n<div class=\"paragraph\">\n<p><strong>Avoid placing artifacts in $HOME</strong></p>\n</div>\n<div class=\"paragraph\">\n<p>The persistent volume attached to the workbench will be mounted on <code>/opt/app-root/src</code>. This location is also the location of <code>$HOME</code>. Therefore, do not put any files or other resources directly in <code>$HOME</code> because they are not visible after the workbench is deployed (and the persistent volume is mounted).</p>\n</div>\n<div class=\"paragraph\">\n<p><strong>Specifying the API endpoint</strong></p>\n</div>\n<div class=\"paragraph\">\n<p>OpenShift readiness and liveness probes will query the <code>/api</code> endpoint. For a Jupyter IDE, this is the default endpoint. For other IDEs, you must implement the <code>/api</code> endpoint.</p>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_advanced_guidelines_for_creating_your_own_workbench_image\">Advanced guidelines for creating your own workbench image</h4>\n<div class=\"paragraph\">\n<p>The following guidelines provide information to consider when you build your own custom workbench image.</p>\n</div>\n<div class=\"paragraph\">\n<p><strong>Minimizing image size</strong></p>\n</div>\n<div class=\"paragraph\">\n<p>A workbench image uses a \"layered\" file system. Every time you use a COPY or a RUN command in your workbench image file, a new layer is created. Artifacts are not deleted. When you remove an artifact, for example, a file, it is \"masked\" in the next layer. Therefore, consider the following guidelines when you create your workbench image file.</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Avoid using the <code>dnf update</code> command.</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>If you start from an image that is constantly updated, such as <code>ubi9/python-39</code> from the Red Hat Catalog, you might not need to use the <code>dnf update</code> command. This command fetches new metadata, updates files that might not have impact, and increases the workbench image size.</p>\n</li>\n<li>\n<p>Point to a newer version of your base image rather than performing a <code>dnf update</code> on an older version.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Group <code>RUN</code> commands. Chain your commands by adding <code>&amp;&amp; \\</code> at the end of each line.</p>\n</li>\n<li>\n<p>If you must compile code (such as a library or an application) to include in your custom image, implement multi-stage builds so that you avoid including the build artifacts in your final image. That is, compile the library or application in an intermediate image and then copy the result to your final image, leaving behind build artifacts that you do not want included.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p><strong>Setting access to files and directories</strong></p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Set the ownership of files and folders to <code>1001:0</code> (user \"default\", group \"0\"), for example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>COPY --chown=1001:0 os-packages.txt ./</pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>On OpenShift, every container is in a standard namespace (unless you modify security). The container runs with a user that has a random user ID (uid) and with a group ID (gid) of <code>0</code>. Therefore, all folders that you want to write to - and all the files you want to (temporarily) modify - in your image must be accessible by the user that has the random user ID (uid).\nAlternatively, you can set access to any user, as shown in the following example:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>COPY --chmod=775 os-packages.txt ./</pre>\n</div>\n</div>\n</li>\n<li>\n<p>Build your image with <code>/opt/app-root/src</code> as the default location for the data that you want persisted, for example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>WORKDIR /opt/app-root/src</pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>When a user launches a workbench from the Open Data Hub <strong>Applications</strong>  <strong>Enabled</strong> page, the personal volume of the user is mounted in the user&#8217;s HOME directory (<code>/opt/app-root/src</code>). Because this location is not configurable, when you build your custom image, you must specify this default location for persisted data.</p>\n</div>\n</li>\n<li>\n<p>Fix permissions to support PIP (the package manager for Python packages) in OpenShift environments. Add the following command to your custom image (if needed, change <code>python3.11</code> to the Python version that you are using):</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>chmod -R g+w /opt/app-root/lib/python3.11/site-packages &amp;&amp; \\\n   fix-permissions /opt/app-root -P</pre>\n</div>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Your workbench image needs to serve all of its content from the base path <code>/${NB_PREFIX}</code> because the routing, handled by the Gateway API, is path-based and uses the same value as the environment variable <code>NB_PREFIX</code>.</p>\n</div>\n<div class=\"paragraph\">\n<p>The <code>NB_PREFIX</code> environment variable is injected in the workbench at runtime. Any call from a browser to a different path, for example <code>/index.html</code>, <code>/api/my-endpoint</code>, or simply <code>/</code>, will not be routed to the workbench container.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>A service within your workbench image must answer at <code>${NB_PREFIX}/api</code>, otherwise the OpenShift liveness/readiness probes fail and delete the pod for the workbench image.</p>\n<div class=\"paragraph\">\n<p>The <code>NB_PREFIX</code> environment variable specifies the URL path where the container is expected to be listening.</p>\n</div>\n<div class=\"paragraph\">\n<p>The following is an example of an Nginx configuration:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>location = ${NB_PREFIX}/api {\n\treturn 302  /healthz;\n\taccess_log  off;\n}</pre>\n</div>\n</div>\n</li>\n<li>\n<p>For idle culling to work, the <code>${NB_PREFIX}/api/kernels</code> URL must return a specifically-formatted JSON payload, as shown in the following example:</p>\n<div class=\"paragraph\">\n<p>The following is an example of an Nginx configuration:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>location = ${NB_PREFIX}/api/kernels {\n\treturn 302 $custom_scheme://$http_host/api/kernels/;\n\taccess_log  off;\n}\n\nlocation ${NB_PREFIX}/api/kernels/ {\n\treturn 302 $custom_scheme://$http_host/api/kernels/;\n\taccess_log  off;\n}\n\nlocation /api/kernels/ {\n  index access.cgi;\n  fastcgi_index access.cgi;\n  gzip  off;\n  access_log\toff;\n }</pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The returned JSON payload should be:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>{\"id\":\"rstudio\",\"name\":\"rstudio\",\"last_activity\":(time in ISO8601 format),\"execution_state\":\"busy\",\"connections\": 1}</pre>\n</div>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p><strong>Enabling CodeReady Builder (CRB) and Extra Packages for Enterprise Linux (EPEL)</strong></p>\n</div>\n<div class=\"paragraph\">\n<p>CRB and EPEL are repositories that provide packages which are absent from a standard Red Hat Enterprise Linux (RHEL) or Universal Base Image (UBI) installation. They are useful and required for installing some software, for example, RStudio.</p>\n</div>\n<div class=\"paragraph\">\n<p>On UBI9 images, CRB is enabled by default. To enable EPEL on UBI9-based images, run the following command:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre> RUN yum install -y https://download.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm</pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>To enable CRB and EPEL on Centos Stream 9-based images, run the following command:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre> RUN yum install -y yum-utils &amp;&amp; \\\n    yum-config-manager --enable crb &amp;&amp; \\\n    yum install -y https://download.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm</pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"enabling-custom-images_custom-images\">Enabling custom images in Open Data Hub</h3>\n<div class=\"paragraph\">\n<p>All Open Data Hub administrators can import custom workbench images, by default, by selecting the <strong>Settings</strong> &#8594; <strong>Environment setup</strong> &#8594; <strong>Workbench images</strong> navigation option in the Open Data Hub dashboard.</p>\n</div>\n<div class=\"paragraph\">\n<p>If the <strong>Settings</strong> &#8594; <strong>Environment setup</strong> &#8594; <strong>Workbench images</strong> option is not available, check the following settings, depending on which navigation element does not appear in the dashboard:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>The <strong>Settings</strong> menu does not appear in the Open Data Hub navigation bar.</p>\n<div class=\"paragraph\">\n<p>The visibility of the Open Data Hub dashboard <strong>Settings</strong> menu is determined by your user permissions. By default, the <strong>Settings</strong> menu is available to Open Data Hub administration users (users that are members of the <code>odh-admins</code> group). Users with the OpenShift <code>cluster-admin</code> role are automatically added to the <code>odh-admins</code> group and are granted administrator access in Open Data Hub.</p>\n</div>\n<div class=\"paragraph\">\n<p>For more information about user permissions, see <a href=\"https://opendatahub.io/docs/managing-odh/#managing-groups-and-users\">Managing users and groups</a>.</p>\n</div>\n</li>\n<li>\n<p>The <strong>Workbench images</strong> menu item does not appear under the <strong>Settings</strong> menu.</p>\n<div class=\"paragraph\">\n<p>The visibility of the <strong>Workbench images</strong> menu item is controlled in the dashboard configuration, by the value of the <code>dashboardConfig: disableBYONImageStream</code> option. It is set to <strong>false</strong> (the <strong>Workbench images</strong> menu item is visible) by default.</p>\n</div>\n<div class=\"paragraph\">\n<p>You need Open Data Hub administrator permissions to edit the dashboard configuration.</p>\n</div>\n<div class=\"paragraph\">\n<p>For more information about setting dashboard configuration options, see <a href=\"https://opendatahub.io/docs/managing-resources/#customizing-the-dashboard\">Customizing the dashboard</a>.</p>\n</div>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"importing-a-custom-workbench-image_custom-images\">Importing a custom workbench image</h3>\n<div class=\"paragraph _abstract\">\n<p>You can import custom workbench images that cater to your Open Data Hub project&#8217;s specific requirements. From the <strong>Workbench images</strong> page, you can enable or disable a previously imported workbench image and create an accelerator profile or a hardware profile as a recommended accelerator for existing workbench images.</p>\n</div>\n<div class=\"paragraph\">\n<p>You must import it so that your Open Data Hub users (data scientists) can access it when they create a project workbench.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to Open Data Hub as a user with Open Data Hub administrator privileges.</p>\n</li>\n<li>\n<p>Your custom image exists in an image registry that is accessible to Open Data Hub.</p>\n</li>\n<li>\n<p>The <strong>Settings</strong> &#8594; <strong>Environment setup</strong> &#8594; <strong>Workbench images</strong> dashboard navigation menu item is enabled, as described in <a href=\"https://opendatahub.io/docs/managing-odh/#enabling-custom-images_custom-images\">Creating a custom image from a default Open Data Hub image</a>.</p>\n</li>\n<li>\n<p>If you want to associate an accelerator with the custom image that you want to import, you know the accelerator&#8217;s identifier - the unique string that identifies the hardware accelerator. You must also have enabled GPU support. This includes installing the Node Feature Discovery and NVIDIA GPU Operators. For more information, see <a href=\"https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/index.html\" target=\"_blank\" rel=\"noopener\">NVIDIA GPU Operator on Red&#160;Hat OpenShift Container Platform</a> in the NVIDIA documentation.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, click <strong>Settings</strong> &#8594; <strong>Environment setup</strong> &#8594; <strong>Workbench images</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Workbench images</strong> page opens. Previously imported images are displayed. To enable or disable a previously imported image, on the row containing the relevant image, click the toggle in the <strong>Enable</strong> column.</p>\n</div>\n</li>\n<li>\n<p>Optional: If you want to associate an accelerator and you have not already created an accelerator profile or a hardware profile, click  <strong>Create profile</strong> on the row containing the image and complete the relevant fields. If the image does not contain an accelerator identifier, you must manually configure one before creating an associated accelerator profile or a hardware profile.</p>\n</li>\n<li>\n<p>Click <strong>Import new image</strong>. Alternatively, if no previously imported images were found, click <strong>Import image</strong>.</p>\n<div class=\"paragraph\">\n<p>The <strong>Import workbench image</strong> dialog opens.</p>\n</div>\n</li>\n<li>\n<p>In the <strong>Image location</strong> field, enter the URL of the repository containing the image. For example: <code>quay.io/my-repo/my-image:tag</code>, <code>quay.io/my-repo/my-image@sha256:xxxxxxxxxxxxx</code>, or\n<code>docker.io/my-repo/my-image:tag</code>.</p>\n</li>\n<li>\n<p>In the <strong>Name</strong> field, enter an appropriate name for the image.</p>\n</li>\n<li>\n<p>Optional: In the <strong>Description</strong> field, enter a description for the image.</p>\n</li>\n<li>\n<p>Optional: From the <strong>Accelerator identifier</strong> list, select an identifier to set its accelerator as recommended with the image. If the image contains only one accelerator identifier, the identifier name displays by default.</p>\n</li>\n<li>\n<p>Optional: Add software to the image. After the import has completed, the software is added to the image&#8217;s meta-data and displayed on the workbench creation page.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Click the <strong>Software</strong> tab.</p>\n</li>\n<li>\n<p>Click the <strong>Add software</strong> button.</p>\n</li>\n<li>\n<p>Click <strong>Edit</strong> (<span class=\"image\"><img src=\"/static/docs/images/rhoai-edit-icon.png\" alt=\"The Edit icon\"></span>).</p>\n</li>\n<li>\n<p>Enter the <strong>Software</strong> name.</p>\n</li>\n<li>\n<p>Enter the software <strong>Version</strong>.</p>\n</li>\n<li>\n<p>Click <strong>Confirm</strong> (<span class=\"image\"><img src=\"/static/docs/images/rhoai-confirm-entry-icon.png\" alt=\"The Confirm icon\"></span>) to confirm your entry.</p>\n</li>\n<li>\n<p>To add additional software, click <strong>Add software</strong>, complete the relevant fields, and confirm your entry.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Optional: Add packages to the workbench images. After the import has completed, the packages are added to the image&#8217;s meta-data and displayed on the workbench creation page.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Click the <strong>Packages</strong> tab.</p>\n</li>\n<li>\n<p>Click the  <strong>Add package</strong> button.</p>\n</li>\n<li>\n<p>Click <strong>Edit</strong> (<span class=\"image\"><img src=\"/static/docs/images/rhoai-edit-icon.png\" alt=\"The Edit icon\"></span>).</p>\n</li>\n<li>\n<p>Enter the <strong>Package</strong> name.</p>\n</li>\n<li>\n<p>Enter the package <strong>Version</strong>. For example, type <code>3.16.7</code>.</p>\n</li>\n<li>\n<p>Click <strong>Confirm</strong> (<span class=\"image\"><img src=\"/static/docs/images/rhoai-confirm-entry-icon.png\" alt=\"The Confirm icon\"></span>) to confirm your entry.</p>\n</li>\n<li>\n<p>To add an additional package, click <strong>Add package</strong>, complete the relevant fields, and confirm your entry.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Click <strong>Import</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The image that you imported is displayed in the table on the <strong>Workbench images</strong> page.</p>\n</li>\n<li>\n<p>Your custom image is available for selection when a user creates a workbench.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/images/managing-image-streams\">Managing image streams</a></p>\n</li>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/builds_using_buildconfig/understanding-buildconfigs\">Understanding build configurations</a></p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"managing-applications-that-show-in-the-dashboard\">Managing applications that show in the dashboard</h2>\n<div class=\"sectionbody\">\n<div class=\"sect2\">\n<h3 id=\"adding-an-application-to-the-dashboard_dashboard\">Adding an application to the dashboard</h3>\n<div class=\"paragraph _abstract\">\n<p>If you have installed an application in your OpenShift Container Platform cluster, an Open Data Hub administrator can add a tile for that application to the Open Data Hub dashboard (the <strong>Applications</strong>  <strong>Enabled</strong> page) to make it accessible for Open Data Hub users.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have Open Data Hub administrator privileges.</p>\n</li>\n<li>\n<p>The <code>spec.dashboardConfig.enablement</code> dashboard configuration option is set to <code>true</code> (the default).</p>\n<div class=\"paragraph\">\n<p>For more information about setting dashboard configuration options, see <a href=\"https://opendatahub.io/docs/managing-resources/#customizing-the-dashboard\">Customizing the dashboard</a>.</p>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform console as an Open Data Hub administrator.</p>\n</li>\n<li>\n<p>In the <strong>Administrator</strong> perspective, click <strong>Home</strong> &#8594; <strong>API Explorer</strong>.</p>\n</li>\n<li>\n<p>In the search bar, enter <code>OdhApplication</code> to filter by kind.</p>\n</li>\n<li>\n<p>Click the <code>OdhApplication</code> custom resource (CR) to open the resource details page.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> list, select the Open Data Hub application namespace; the default is <code>opendatahub</code>.</p>\n</li>\n<li>\n<p>Click the <strong>Instances</strong> tab.</p>\n</li>\n<li>\n<p>Click <strong>Create OdhApplication</strong>.</p>\n</li>\n<li>\n<p>On the <strong>Create OdhApplication</strong> page, copy the following code and paste it into the YAML editor.</p>\n<div class=\"listingblock lines_space console-input\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-yaml\" data-lang=\"yaml\">apiVersion: dashboard.opendatahub.io/v1\nkind: OdhApplication\nmetadata:\n  name: examplename\n  namespace: opendatahub\n  labels:\n    app: odh-dashboard\n    app.kubernetes.io/part-of: odh-dashboard\nspec:\n  enable:\n    validationConfigMap: examplename-enable\n  img: &gt;-\n    &lt;svg width=\"24\" height=\"25\" viewBox=\"0 0 24 25\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"&gt;\n    &lt;path d=\"path data\" fill=\"#ee0000\"/&gt;\n    &lt;/svg&gt;\n  getStartedLink: 'https://example.org/docs/quickstart.html'\n  route: exampleroutename\n  routeNamespace: examplenamespace\n  displayName: Example Name\n  kfdefApplications: []\n  support: third party support\n  csvName: ''\n  provider: example\n  docsLink: 'https://example.org/docs/index.html'\n  quickStart: ''\n  getStartedMarkDown: &gt;-\n    # Example\n\n    Enter text for the information panel.\n\n  description: &gt;-\n    Enter summary text for the tile.\n  category: Self-managed | Partner managed | Red Hat managed</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Modify the parameters in the code for your application.</p>\n<div class=\"admonitionblock tip\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Tip</div>\n</td>\n<td class=\"content\">\nTo see example YAML files, click <strong>Home</strong> &#8594; <strong>API Explorer</strong>, select <code>OdhApplication</code>, click the <strong>Instances</strong> tab, select an instance, and then click the <strong>YAML</strong> tab.\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>Click <strong>Create</strong>. The application details page opens.</p>\n</li>\n<li>\n<p>Log in to Open Data Hub.</p>\n</li>\n<li>\n<p>In the left menu, click <strong>Applications</strong> &#8594; <strong>Explore</strong>.</p>\n</li>\n<li>\n<p>Locate the new tile for your application and click it.</p>\n</li>\n<li>\n<p>In the information pane for the application, click <strong>Enable</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>In the left menu of the Open Data Hub dashboard, click <strong>Applications</strong>  <strong>Enabled</strong> and verify that your application is available.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"preventing-users-from-adding-applications-to-the-dashboard_dashboard\">Preventing users from adding applications to the dashboard</h3>\n<div class=\"paragraph _abstract\">\n<p>By default, Open Data Hub administrators can add applications to the Open Data Hub dashboard <strong>Application  Enabled</strong> page.</p>\n</div>\n<div class=\"paragraph\">\n<p>As an Open Data Hub administrator, you can disable the ability for Open Data Hub administrators to add applications to the dashboard.</p>\n</div>\n<div class=\"paragraph\">\n<p><strong>Note:</strong> The <strong>Start basic workbench</strong> tile is enabled by default. To disable it, see <a href=\"https://opendatahub.io/docs/managing-odh/#hiding-the-default-basic-workbench-application_dashboard\">Hiding the default basic workbench application</a>.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisite</div>\n<ul>\n<li>\n<p>You have Open Data Hub administrator privileges.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform console as an Open Data Hub administrator.</p>\n</li>\n<li>\n<p>Open the dashboard configuration file:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the <strong>Administrator</strong> perspective, click <strong>Home</strong> &#8594; <strong>API Explorer</strong>.</p>\n</li>\n<li>\n<p>In the search bar, enter <code>OdhDashboardConfig</code> to filter by kind.</p>\n</li>\n<li>\n<p>Click the <code>OdhDashboardConfig</code> custom resource (CR) to open the resource details page.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> list, select the Open Data Hub application namespace; the default is <code>opendatahub</code>.</p>\n</li>\n<li>\n<p>Click the <strong>Instances</strong> tab.</p>\n</li>\n<li>\n<p>Click the <code>odh-dashboard-config</code> instance to open the details page.</p>\n</li>\n<li>\n<p>Click the <strong>YAML</strong> tab.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>In the <code>spec.dashboardConfig</code> section, set the value of <code>enablement</code> to <code>false</code> to disable the ability for dashboard users to add applications to the dashboard.</p>\n</li>\n<li>\n<p>Click <strong>Save</strong> to apply your changes and then click <strong>Reload</strong> to make sure that your changes are synced to the cluster.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Open the Open Data Hub dashboard <strong>Application  Enabled</strong> page.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"disabling-applications-connected_dashboard\">Disabling applications connected to Open Data Hub</h3>\n<div class=\"paragraph _abstract\">\n<p>You can disable applications and components so that they do not appear on the Open Data Hub dashboard when you no longer want to use them, for example, when data scientists no longer use an application or when the application license expires.</p>\n</div>\n<div class=\"paragraph\">\n<p>Disabling unused applications allows your data scientists to manually remove these application tiles from their Open Data Hub dashboard so that they can focus on the applications that they are most likely to use.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to the OpenShift Container Platform web console.</p>\n</li>\n<li>\n<p>You are part of the <code>cluster-admins</code> user group in OpenShift Container Platform.</p>\n</li>\n<li>\n<p>You have installed or configured the service on your OpenShift Container Platform cluster.</p>\n</li>\n<li>\n<p>The application or component that you want to disable is enabled and visible on the <strong>Enabled</strong> page.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform web console, switch to the <strong>Administrator</strong> perspective.</p>\n</li>\n<li>\n<p>Switch to the <code>odh</code> project.</p>\n</li>\n<li>\n<p>Click <strong>Operators</strong> &#8594; <strong>Installed Operators</strong>.</p>\n</li>\n<li>\n<p>Click on the Operator that you want to uninstall. You can enter a keyword into the <strong>Filter by name</strong> field to help you find the Operator faster.</p>\n</li>\n<li>\n<p>Delete any Operator resources or instances by using the tabs in the Operator interface.</p>\n<div class=\"paragraph\">\n<p>During installation, some Operators require the administrator to create resources or start process instances using tabs in the Operator interface. These must be deleted before the Operator can uninstall correctly.</p>\n</div>\n</li>\n<li>\n<p>On the <strong>Operator Details</strong> page, click the <strong>Actions</strong> drop-down menu and select <strong>Uninstall Operator</strong>.</p>\n<div class=\"paragraph\">\n<p>An <strong>Uninstall Operator?</strong> dialog box is displayed.</p>\n</div>\n</li>\n<li>\n<p>Select <strong>Uninstall</strong> to uninstall the Operator, Operator deployments, and pods. After this is complete, the Operator stops running and no longer receives updates.</p>\n</li>\n</ol>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Removing an Operator does not remove any custom resource definitions or managed resources for the Operator. Custom resource definitions and managed resources still exist and must be cleaned up manually. Any applications deployed by your Operator and any configured off-cluster resources continue to run and must be cleaned up manually.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The Operator is uninstalled from its target clusters.</p>\n</li>\n<li>\n<p>The Operator is no longer displayed on the <strong>Installed Operators</strong> page.</p>\n</li>\n<li>\n<p>The disabled application is no longer available for your data scientists to use, and is marked as <code>Disabled</code> on the <strong>Enabled</strong> page of the Open Data Hub dashboard. This action may take a few minutes to occur following the removal of the Operator.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"showing-hiding-information-about-available-applications_dashboard\">Showing or hiding information about available applications</h3>\n<div class=\"paragraph _abstract\">\n<p>You can view a list of available applications in the <strong>Exploring applications</strong> page of the Open Data Hub dashboard. By default, the following information is provided for each application:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Any independent software vendor (ISV) application is indicated with a label on the tile indicating <code>Red&#160;Hat-managed</code>, <code>Partner managed</code>, or <code>Self-managed</code>. As an Open Data Hub administrator, you can hide or show the labels. For example, if you are running a self-managed environment, you might want to show all available applications regardless of the support level.</p>\n</li>\n<li>\n<p>When a user clicks on an application, an information panel is displayed and provides more information about the application, including links to quick starts or detailed documentation. You can disable or enable the appearance of application information panels.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have Open Data Hub administrator privileges.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform console as an Open Data Hub administrator.</p>\n</li>\n<li>\n<p>Open the dashboard configuration file:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the <strong>Administrator</strong> perspective, click <strong>Home</strong> &#8594; <strong>API Explorer</strong>.</p>\n</li>\n<li>\n<p>In the search bar, enter <code>OdhDashboardConfig</code> to filter by kind.</p>\n</li>\n<li>\n<p>Click the <code>OdhDashboardConfig</code> custom resource (CR) to open the resource details page.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> list, select the Open Data Hub application namespace; the default is <code>opendatahub</code>.</p>\n</li>\n<li>\n<p>Click the <strong>Instances</strong> tab.</p>\n</li>\n<li>\n<p>Click the <code>odh-dashboard-config</code> instance to open the details page.</p>\n</li>\n<li>\n<p>Click the <strong>YAML</strong> tab.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>In the <code>spec.dashboardConfig</code> section, set either or both of the following options:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><code>disableInfo</code>: Set to <code>true</code> to hide the appearance of application information panel. Set to <code>False</code> (the default) to show the application information panel.</p>\n</li>\n<li>\n<p><code>disableISVBadges</code>: Set to <code>true</code> to hide the appearance of the support-level label. Set to <code>False</code> (the default) to show the support-level label.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Click <strong>Save</strong> to apply your changes and then click <strong>Reload</strong> to make sure that your changes are synced to the cluster.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>Log in to Open Data Hub and verify that your dashboard configurations apply.</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"hiding-the-default-basic-workbench-application_dashboard\">Hiding the default basic workbench application</h3>\n<div class=\"paragraph _abstract\">\n<p>The Open Data Hub dashboard includes <strong>Start basic workbench</strong> as an enabled application by default.</p>\n</div>\n<div class=\"paragraph\">\n<p>To hide the <strong>Start basic workbench</strong> tile so that it is no longer included in the list of applications on the <strong>Applications</strong>  <strong>Enabled</strong> page, edit the dashboard configuration file.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisite</div>\n<ul>\n<li>\n<p>You have Open Data Hub administrator privileges.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform console as an Open Data Hub administrator.</p>\n</li>\n<li>\n<p>Open the dashboard configuration file:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the <strong>Administrator</strong> perspective, click <strong>Home</strong> &#8594; <strong>API Explorer</strong>.</p>\n</li>\n<li>\n<p>In the search bar, enter <code>OdhDashboardConfig</code> to filter by kind.</p>\n</li>\n<li>\n<p>Click the <code>OdhDashboardConfig</code> custom resource (CR) to open the resource details page.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> list, select the Open Data Hub application namespace; the default is <code>opendatahub</code>.</p>\n</li>\n<li>\n<p>Click the <strong>Instances</strong> tab.</p>\n</li>\n<li>\n<p>Click the <code>odh-dashboard-config</code> instance to open the details page.</p>\n</li>\n<li>\n<p>Click the <strong>YAML</strong> tab.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>In the <code>spec:notebookController</code> section, set the value of <code>enabled</code> to <code>false</code> to remove the <strong>Start basic workbench</strong> tile from the list of applications on the <strong>Applications</strong>  <strong>Enabled</strong> page.</p>\n</li>\n<li>\n<p>Click <strong>Save</strong> to apply your changes and then click <strong>Reload</strong> to make sure that your changes are synced to the cluster.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>In the Open Data Hub dashboard, click <strong>Applications</strong>  <strong>Enabled</strong>.\nThe list of applications no longer includes the <strong>Start basic workbench</strong> tile.</p>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"creating-project-scoped-resources_managing-odh\">Creating project-scoped resources</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>Open Data Hub users can access <em>global resources</em> in all Open Data Hub projects. However, they can access <em>project-scoped resources</em> only within projects that they have permissions to access.</p>\n</div>\n<div class=\"paragraph\">\n<p>As a cluster administrator, you can create the following types of project-scoped resources in any Open Data Hub project:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Workbench images</p>\n</li>\n<li>\n<p>Hardware profiles</p>\n</li>\n<li>\n<p>Model-serving runtimes for KServe</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>All resource names must be unique within a project.</p>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>A user with access permissions to a project can create project-scoped resources for that project, as described in <a href=\"https://opendatahub.io/docs/working-on-projects/#creating-project-scoped-resources-for-your-project_projects\">Creating project-scoped resources for your project</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You can access the OpenShift Container Platform console as a cluster administrator.</p>\n</li>\n<li>\n<p>You have set the <code>disableProjectScoped</code> dashboard configuration option to <code>false</code>, as described in <a href=\"https://opendatahub.io/docs/managing-resources/#customizing-the-dashboard\">Customizing the dashboard</a>.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform console as a cluster administrator.</p>\n</li>\n<li>\n<p>Copy the YAML code to create the resource.</p>\n<div class=\"paragraph\">\n<p>You can get the YAML code from a trusted source, such as an existing resource, a Git repository, or documentation.</p>\n</div>\n<div class=\"paragraph\">\n<p>For example, you can copy the YAML code from an existing resource, as follows:</p>\n</div>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the <strong>Administrator</strong> perspective, click <strong>Home</strong> &#8594; <strong>Search</strong>.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> list, select the appropriate project.</p>\n<div class=\"paragraph\">\n<p>To limit the search to global Open Data Hub resources only, select the <code>opendatahub</code> project.</p>\n</div>\n</li>\n<li>\n<p>In the <strong>Resources</strong> list, search for the relevant resource type:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>For workbench images, search for <code>ImageStream</code>.</p>\n</li>\n<li>\n<p>For hardware profiles, search for <code>HardwareProfile</code>.</p>\n</li>\n<li>\n<p>For serving runtimes, search for <code>Template</code>.\nFrom the resulting list, find the templates that have the <code>objects.kind</code> specification set to <code>ServingRuntime</code>.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Select a resource, and then click the <strong>YAML</strong> tab.</p>\n</li>\n<li>\n<p>Copy the YAML content, and then click <strong>Cancel</strong>.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>From the <strong>Project</strong> list, select the target project name.</p>\n</li>\n<li>\n<p>From the toolbar, click the <strong>+</strong> icon to open the <strong>Import YAML</strong> page.</p>\n</li>\n<li>\n<p>Paste the relevant YAML content into the code area.</p>\n</li>\n<li>\n<p>Edit the <code>metadata.namespace</code> value to specify the name of the target project.</p>\n</li>\n<li>\n<p>If necessary, edit the <code>metadata.name</code> value to ensure that the resource name is unique within the specified project.</p>\n</li>\n<li>\n<p>Optional: Edit the resource name that is displayed in the Open Data Hub console:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>For workbench images, edit the <code>metadata.annotations.opendatahub.io/notebook-image-name</code> value.</p>\n</li>\n<li>\n<p>For hardware profiles, edit the <code>spec.displayName</code> value.</p>\n</li>\n<li>\n<p>For serving runtimes, edit the <code>objects.metadata.annotations.openshift.io/display-name</code> value.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Click <strong>Create</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Verification</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the Open Data Hub console as a regular user.</p>\n</li>\n<li>\n<p>Verify that the project-scoped resource is shown in the specified project:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>For workbench images and hardware profiles, see <a href=\"https://opendatahub.io/docs/working-on-projects/#creating-a-project-workbench_projects\">Creating a workbench</a>.</p>\n</li>\n<li>\n<p>For serving runtimes, see <a href=\"https://opendatahub.io/docs/deploying-models/#deploying-models-on-the-model-serving-platform_odh-user\">Deploying models</a>.</p>\n</li>\n</ul>\n</div>\n</li>\n</ol>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"allocating-additional-resources-to-users_managing-odh\">Allocating additional resources to Open Data Hub users</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>As a cluster administrator, you can allocate additional resources to a cluster to support compute-intensive data science work. This support includes increasing the number of nodes in the cluster and changing the cluster&#8217;s allocated machine pool.</p>\n</div>\n<div class=\"paragraph\">\n<p>For more information about allocating additional resources to an OpenShift Container Platform cluster, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/machine_management/manually-scaling-machineset\">Manually scaling a compute machine set</a>.</p>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"customizing-component-deployment-resources_managing-resources\">Customizing component deployment resources</h2>\n<div class=\"sectionbody\">\n<div class=\"sect2\">\n<h3 id=\"overview-of-component-resource-customization_managing-resources\">Overview of component resource customization</h3>\n<div class=\"paragraph _abstract\">\n<p>You can customize deployment resources that are related to the Open Data Hub Operator, for example, CPU and memory limits and requests. For resource customizations to persist without being overwritten by the Operator, the <code>opendatahub.io/managed: true</code> annotation must not be present in the YAML file for the component deployment. This annotation is absent by default.</p>\n</div>\n<div class=\"paragraph\">\n<p>The following table shows the deployment names for each component in the <code>opendatahub</code> namespace:</p>\n</div>\n<table class=\"tableblock frame-all grid-all stretch\">\n<colgroup>\n<col style=\"width: 50%;\">\n<col style=\"width: 50%;\">\n</colgroup>\n<thead>\n<tr>\n<th class=\"tableblock halign-left valign-top\">Component</th>\n<th class=\"tableblock halign-left valign-top\">Deployment names</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">KServe</p></td>\n<td class=\"tableblock halign-left valign-top\"><div class=\"content\"><div class=\"ulist\">\n<ul>\n<li>\n<p>kserve-controller-manager</p>\n</li>\n<li>\n<p>odh-model-controller</p>\n</li>\n</ul>\n</div></div></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">TrustyAI</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">trustyai-service-operator-controller-manager</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Ray</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">kuberay-operator</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Kueue</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">kueue-controller-manager</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Workbenches</p></td>\n<td class=\"tableblock halign-left valign-top\"><div class=\"content\"><div class=\"ulist\">\n<ul>\n<li>\n<p>notebook-controller-deployment</p>\n</li>\n<li>\n<p>odh-notebook-controller-manager</p>\n</li>\n</ul>\n</div></div></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Dashboard</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">odh-dashboard</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Model serving</p></td>\n<td class=\"tableblock halign-left valign-top\"><div class=\"content\"><div class=\"ulist\">\n<ul>\n<li>\n<p>modelmesh-controller</p>\n</li>\n<li>\n<p>odh-model-controller</p>\n</li>\n</ul>\n</div></div></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Model registry</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">model-registry-operator-controller-manager</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">AI pipelines</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">data-science-pipelines-operator-controller-manager</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Training Operator</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">kubeflow-training-operator</p></td>\n</tr>\n</tbody>\n</table>\n</div>\n<div class=\"sect2\">\n<h3 id=\"customizing-component-resources_managing-resources\">Customizing component resources</h3>\n<div class=\"paragraph _abstract\">\n<p>You can customize component deployment resources by updating the <code>.spec.template.spec.containers.resources</code> section of the YAML file for the component deployment.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have cluster administrator privileges for your OpenShift Container Platform cluster.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform console as a cluster administrator.</p>\n</li>\n<li>\n<p>In the <strong>Administrator</strong> perspective, click <strong>Workloads</strong> &#8594; <strong>Deployments</strong>.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> drop-down list, select <code>opendatahub</code>.</p>\n</li>\n<li>\n<p>In the <strong>Name</strong> column, click the name of the deployment for the component that you want to customize resources for.</p>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>For more information about the deployment names for each component, see <a href=\"https://opendatahub.io/docs/managing-resources/#overview-of-component-resource-customization_managing-resources\">Overview of component resource customization</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>On the <strong>Deployment details</strong> page that is displayed, click the <strong>YAML</strong> tab.</p>\n</li>\n<li>\n<p>Find the <code>.spec.template.spec.containers.resources</code> section.</p>\n</li>\n<li>\n<p>Update the value of the resource that you want to customize. For example, to update the memory limit to 500Mi, make the following change:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>containers:\n        - resources:\n            limits:\n                cpu: '2'\n                memory: 500Mi\n            requests:\n                cpu: '1'\n                memory: 1Gi</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Click <strong>Save</strong>.</p>\n</li>\n<li>\n<p>Click <strong>Reload</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Log in to Open Data Hub and verify that your resource changes apply.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"disabling-component-resource-customization_managing-resources\">Disabling component resource customization</h3>\n<div class=\"paragraph _abstract\">\n<p>You can disable customization of component deployment resources, and restore default  values, by adding the <code>opendatahub.io/managed: true</code> annotation to the YAML file for the component deployment.</p>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Manually removing or setting the <code>opendatahub.io/managed: true</code> annotation to <code>false</code> after manually adding it to the YAML file for a component deployment might cause unexpected cluster issues.</p>\n</div>\n<div class=\"paragraph\">\n<p>To remove the annotation from a deployment, use the steps described in <a href=\"https://opendatahub.io/docs/managing-resources/#reenabling-component-resource-customization_managing-resources\">Re-enabling component resource customization</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have cluster administrator privileges for your OpenShift Container Platform cluster.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform console as a cluster administrator.</p>\n</li>\n<li>\n<p>In the <strong>Administrator</strong> perspective, click <strong>Workloads</strong> &#8594; <strong>Deployments</strong>.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> drop-down list, select <code>opendatahub</code>.</p>\n</li>\n<li>\n<p>In the <strong>Name</strong> column, click the name of the deployment for the component to which you want to add the annotation.</p>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>For more information about the deployment names for each component, see <a href=\"https://opendatahub.io/docs/managing-resources/#overview-of-component-resource-customization_managing-resources\">Overview of component resource customization</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>On the <strong>Deployment details</strong> page that opens, click the <strong>YAML</strong> tab.</p>\n</li>\n<li>\n<p>Find the <code>metadata.annotations:</code> section.</p>\n</li>\n<li>\n<p>Add the <code>opendatahub.io/managed: true</code> annotation.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>metadata:\n  annotations:\n     opendatahub.io/managed: true</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Click <strong>Save</strong>.</p>\n</li>\n<li>\n<p>Click <strong>Reload</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The <code>opendatahub.io/managed: true</code> annotation is displayed in the YAML file for the component deployment.</p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"reenabling-component-resource-customization_managing-resources\">Re-enabling component resource customization</h3>\n<div class=\"paragraph _abstract\">\n<p>You can re-enable customization of component deployment resources after manually disabling it.</p>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Manually removing or setting the <code>opendatahub.io/managed:</code> annotation to <code>false</code> after adding it to the YAML file for a component deployment might cause unexpected cluster issues.</p>\n</div>\n<div class=\"paragraph\">\n<p>To remove the annotation from a deployment, use the following steps to delete the deployment. The controller pod for the deployment will automatically redeploy with the default settings.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have cluster administrator privileges for your OpenShift Container Platform cluster.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform console as a cluster administrator.</p>\n</li>\n<li>\n<p>In the <strong>Administrator</strong> perspective, click <strong>Workloads</strong> &#8594; <strong>Deployments</strong>.</p>\n</li>\n<li>\n<p>From the <strong>Project</strong> drop-down list, select <code>opendatahub</code>.</p>\n</li>\n<li>\n<p>In the <strong>Name</strong> column, click the name of the deployment for the component for which you want to remove the annotation.</p>\n</li>\n<li>\n<p>Click the Options menu <span class=\"image\"><img src=\"/static/docs/images/osd-ellipsis.png\" alt=\"Options menu\"></span>.</p>\n</li>\n<li>\n<p>Click <strong>Delete Deployment</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The controller pod for the deployment automatically redeploys with the default settings.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"enabling-accelerators\">Enabling accelerators</h2>\n<div class=\"sectionbody\">\n<div class=\"sect2\">\n<h3 id=\"enabling-nvidia-gpus_managing-odh\">Enabling NVIDIA GPUs</h3>\n<div class=\"paragraph _abstract\">\n<p>Before you can use NVIDIA GPUs in Open Data Hub, you must install the NVIDIA GPU Operator.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to your OpenShift Container Platform cluster.</p>\n</li>\n<li>\n<p>You have the <code>cluster-admin</code> role in your OpenShift Container Platform cluster.</p>\n</li>\n<li>\n<p>You have installed an NVIDIA GPU and confirmed that it is detected in your environment.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>To enable GPU support on an OpenShift cluster, follow the instructions here: <a href=\"https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/index.html\" target=\"_blank\" rel=\"noopener\">NVIDIA GPU Operator on Red&#160;Hat OpenShift Container Platform</a> in the NVIDIA documentation.</p>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>After you install the Node Feature Discovery (NFD) Operator, you must create an instance of NodeFeatureDiscovery. In addition, after you install the NVIDIA GPU Operator, you must create a ClusterPolicy and populate it with default values.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>Delete the <strong>migration-gpu-status</strong> ConfigMap.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift Container Platform web console, switch to the <strong>Administrator</strong> perspective.</p>\n</li>\n<li>\n<p>Set the <strong>Project</strong> to <strong>All Projects</strong> or <strong>redhat-ods-applications</strong> to ensure you can see the appropriate ConfigMap.</p>\n</li>\n<li>\n<p>Search for the <strong>migration-gpu-status</strong> ConfigMap.</p>\n</li>\n<li>\n<p>Click the action menu (&#8942;) and select <strong>Delete ConfigMap</strong> from the list.</p>\n<div class=\"paragraph\">\n<p>The <strong>Delete ConfigMap</strong> dialog opens.</p>\n</div>\n</li>\n<li>\n<p>Inspect the dialog and confirm that you are deleting the correct ConfigMap.</p>\n</li>\n<li>\n<p>Click <strong>Delete</strong>.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Restart the dashboard replicaset.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift Container Platform web console, switch to the <strong>Administrator</strong> perspective.</p>\n</li>\n<li>\n<p>Click <strong>Workloads</strong> &#8594; <strong>Deployments</strong>.</p>\n</li>\n<li>\n<p>Set the <strong>Project</strong> to <strong>All Projects</strong> or <strong><code>opendatahub</code></strong> to ensure you can see the appropriate deployment.</p>\n</li>\n<li>\n<p>Search for the <strong>rhods-dashboard</strong> deployment.</p>\n</li>\n<li>\n<p>Click the action menu (&#8942;)  and select <strong>Restart Rollout</strong> from the list.</p>\n</li>\n<li>\n<p>Wait until the <strong>Status</strong> column indicates that all pods in the rollout have fully restarted.</p>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The reset <strong>migration-gpu-status</strong> instance is present on the <strong>Instances</strong> tab on the <code>AcceleratorProfile</code> custom resource definition (CRD) details page.</p>\n</li>\n<li>\n<p>From the <strong>Administrator</strong> perspective, go to the <strong>Operators</strong> &#8594; <strong>Installed Operators</strong> page. Confirm that the following Operators appear:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>NVIDIA GPU</p>\n</li>\n<li>\n<p>Node Feature Discovery (NFD)</p>\n</li>\n<li>\n<p>Kernel Module Management (KMM)</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>The GPU is correctly detected a few minutes after full installation of the Node Feature Discovery (NFD) and NVIDIA GPU Operators. The OpenShift CLI (<code>oc</code>) displays the appropriate output for the GPU worker node. For example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code># Expected output when the GPU is detected properly\noc describe node &lt;node name&gt;\n...\nCapacity:\n  cpu:                4\n  ephemeral-storage:  313981932Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             16076568Ki\n  nvidia.com/gpu:     1\n  pods:               250\nAllocatable:\n  cpu:                3920m\n  ephemeral-storage:  288292006229\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             12828440Ki\n  nvidia.com/gpu:     1\n  pods:               250</code></pre>\n</div>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>After installing the NVIDIA GPU Operator, create a hardware profile as described in <a href=\"https://opendatahub.io/docs/working-with-accelerators/#working-with-hardware-profiles_accelerators\">Working with hardware profiles</a>.</p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"intel-gaudi-ai-accelerator-integration_managing-odh\">Intel Gaudi AI Accelerator integration</h3>\n<div class=\"paragraph _abstract\">\n<p>To accelerate your high-performance deep learning models, you can integrate Intel Gaudi AI accelerators into Open Data Hub. This integration enables your data scientists to use Gaudi libraries and software associated with Intel Gaudi AI accelerators through custom-configured workbench instances.</p>\n</div>\n<div class=\"paragraph\">\n<p>Intel Gaudi AI accelerators offer optimized performance for deep learning workloads, with the latest Gaudi 3 devices providing significant improvements in training speed and energy efficiency. These accelerators are suitable for enterprises running machine learning and AI applications on Open Data Hub.</p>\n</div>\n<div class=\"paragraph\">\n<p>Before you can enable Intel Gaudi AI accelerators in Open Data Hub, you must complete the following steps:</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>Install the latest version of the Intel Gaudi Base Operator from OperatorHub.</p>\n</li>\n<li>\n<p>Create and configure a custom workbench image for Intel Gaudi AI accelerators. A prebuilt workbench image for Gaudi accelerators is not included in Open Data Hub.</p>\n</li>\n<li>\n<p>Manually define and configure a hardware profile for each Intel Gaudi AI device in your environment.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<p>Red&#160;Hat supports Intel Gaudi devices up to Intel Gaudi 3. The Intel Gaudi 3 accelerators, in particular, offer the following benefits:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Improved training throughput: Reduce the time required to train large models by using advanced tensor processing cores and increased memory bandwidth.</p>\n</li>\n<li>\n<p>Energy efficiency: Lower power consumption while maintaining high performance, reducing operational costs for large-scale deployments.</p>\n</li>\n<li>\n<p>Scalable architecture: Scale across multiple nodes for distributed training configurations.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>Your OpenShift platform must support EC2 DL1 instances to use Intel Gaudi AI accelerators in an Amazon EC2 DL1 instance. You can use Intel Gaudi AI accelerators in workbench instances or model serving after you enable the accelerators, create a custom workbench image, and configure the hardware profile.</p>\n</div>\n<div class=\"paragraph\">\n<p>To identify the Intel Gaudi AI accelerators present in your deployment, use the <code>lspci</code> utility. For more information, see <a href=\"https://linux.die.net/man/8/lspci\">lspci(8) - Linux man page</a>.</p>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>The presence of Intel Gaudi AI accelerators in your deployment, as indicated by the <code>lspci</code> utility, does not guarantee that the devices are ready to use. You must ensure that all installation and configuration steps are completed successfully.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://linux.die.net/man/8/lspci\">lspci(8) - Linux man page</a></p>\n</li>\n<li>\n<p><a href=\"https://aws.amazon.com/ec2/instance-types/dl1/\">Amazon EC2 DL1 Instances</a></p>\n</li>\n<li>\n<p><a href=\"https://docs.habana.ai/en/latest/Installation_Guide/Additional_Installation/OpenShift_Installation/index.html\">Intel Gaudi AI Operator OpenShift installation</a></p>\n</li>\n<li>\n<p><a href=\"https://access.redhat.com/solutions/4870701\">What version of the Kubernetes API is included with each OpenShift 4.x release?</a></p>\n</li>\n</ul>\n</div>\n<div class=\"sect3\">\n<h4 id=\"enabling-intel-gaudi-ai-accelerators_managing-odh\">Enabling Intel Gaudi AI accelerators</h4>\n<div class=\"paragraph _abstract\">\n<p>Before you can use Intel Gaudi AI accelerators in Open Data Hub, you must install the required dependencies, deploy the Intel Gaudi Base Operator, and configure the environment.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to OpenShift Container Platform.</p>\n</li>\n<li>\n<p>You have the <code>cluster-admin</code> role in OpenShift Container Platform.</p>\n</li>\n<li>\n<p>You have installed your Intel Gaudi accelerator and confirmed that it is detected in your environment.</p>\n</li>\n<li>\n<p>Your OpenShift environment supports EC2 DL1 instances if you are running on Amazon Web Services (AWS).</p>\n</li>\n<li>\n<p>You have installed the OpenShift CLI (<code>oc</code>) as described in the appropriate documentation for your cluster:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/cli_tools/openshift-cli-oc#installing-openshift-cli\" target=\"_blank\" rel=\"noopener\">Installing the OpenShift CLI</a> for OpenShift Container Platform</p>\n</li>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/red_hat_openshift_service_on_aws/4/html/cli_tools/openshift-cli-oc#installing-openshift-cli\" target=\"_blank\" rel=\"noopener\">Installing the OpenShift CLI</a> for Red&#160;Hat OpenShift Service on AWS</p>\n</li>\n</ul>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Install the latest version of the Intel Gaudi Base Operator, as described in <a href=\"https://docs.habana.ai/en/latest/Installation_Guide/Additional_Installation/OpenShift_Installation/index.html\">Intel Gaudi Base Operator OpenShift installation</a>.</p>\n</li>\n<li>\n<p>By default, OpenShift Container Platform sets a per-pod PID limit of 4096. If your workload requires more processing power, such as when you use multiple Gaudi accelerators or when using vLLM with Ray, you must manually increase the per-pod PID limit to avoid <code>Resource temporarily unavailable</code> errors. These errors occur due to PID exhaustion. Red&#160;Hat recommends setting this limit to 32768, although values over 20000 are sufficient.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Run the following command to label the node:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>oc label node &lt;node_name&gt; custom-kubelet=set-pod-pid-limit-kubelet</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Optional: To prevent workload distribution on the affected node, you can mark the node as unschedulable and then drain it in preparation for maintenance. For more information, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/nodes/working-with-nodes#nodes-nodes-working-evacuating_nodes-nodes-working\">Understanding how to evacuate pods on nodes</a>.</p>\n</li>\n<li>\n<p>Create a <code>custom-kubelet-pidslimit.yaml</code> KubeletConfig resource file:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>oc create -f custom-kubelet-pidslimit.yaml</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Populate the file with the following YAML code. Set the <code>PodPidsLimit</code> value to 32768:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-YAML\" data-lang=\"YAML\">apiVersion: machineconfiguration.openshift.io/v1\nkind: KubeletConfig\nmetadata:\n  name: custom-kubelet-pidslimit\nspec:\n  kubeletConfig:\n    PodPidsLimit: 32768\n  machineConfigPoolSelector:\n    matchLabels:\n      custom-kubelet: set-pod-pid-limit-kubelet</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Apply the configuration:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>oc apply -f custom-kubelet-pidslimit.yaml</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>This operation causes the node to reboot. For more information, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/nodes/working-with-nodes#nodes-nodes-rebooting\">Understanding node rebooting</a>.</p>\n</div>\n</li>\n<li>\n<p>Optional: If you previously marked the node as unschedulable, you can allow scheduling again after the node reboots.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Create a custom workbench image for Intel Gaudi AI accelerators, as described in <a href=\"https://opendatahub.io/docs/managing-odh/#creating-custom-workbench-images\">Creating custom workbench images</a>.</p>\n</li>\n<li>\n<p>After installing the Intel Gaudi Base Operator, create a hardware profile, as described in <a href=\"https://opendatahub.io/docs/working-with-accelerators/#working-with-hardware-profiles_accelerators\">Working with hardware profiles</a>.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>From the <strong>Administrator</strong> perspective, go to the <strong>Operators</strong> &#8594; <strong>Installed Operators</strong> page. Confirm that the following Operators appear:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Intel Gaudi Base Operator</p>\n</li>\n<li>\n<p>Node Feature Discovery (NFD)</p>\n</li>\n<li>\n<p>Kernel Module Management (KMM)</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"amd-gpu-integration_managing-odh\">AMD GPU Integration</h3>\n<div class=\"paragraph\">\n<p>You can use AMD GPUs with Open Data Hub to accelerate AI and machine learning (ML) workloads. AMD GPUs provide high-performance compute capabilities, allowing users to process large data sets, train deep neural networks, and perform complex inference tasks more efficiently.</p>\n</div>\n<div class=\"paragraph\">\n<p>Integrating AMD GPUs with Open Data Hub involves the following components:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>ROCm workbench images</strong>:\nUse the ROCm workbench images to streamline AI/ML workflows on AMD GPUs. These images include libraries and frameworks optimized with the AMD ROCm platform, enabling high-performance workloads for PyTorch and TensorFlow. The pre-configured images reduce setup time and provide an optimized environment for GPU-accelerated development and experimentation.</p>\n</li>\n<li>\n<p><strong>AMD GPU Operator</strong>:\nThe AMD GPU Operator simplifies GPU integration by automating driver installation, device plugin setup, and node labeling for GPU resource management. It ensures compatibility between OpenShift and AMD hardware while enabling scaling of GPU-enabled workloads.</p>\n</li>\n</ul>\n</div>\n<div class=\"sect3\">\n<h4 id=\"verifying-amd-gpu-availability-on-your-cluster_managing-odh\">Verifying AMD GPU availability on your cluster</h4>\n<div class=\"paragraph _abstract\">\n<p>Before you proceed with the AMD GPU Operator installation process, you can verify the presence of an AMD GPU device on a node within your OpenShift Container Platform cluster. You can use commands such as <code>lspci</code> or <code>oc</code> to confirm hardware and resource availability.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have administrative access to the OpenShift Container Platform cluster.</p>\n</li>\n<li>\n<p>You have a running OpenShift Container Platform cluster with a node equipped with an AMD GPU.</p>\n</li>\n<li>\n<p>You have access to the OpenShift CLI (<code>oc</code>) and terminal access to the node.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Use the OpenShift CLI (<code>oc</code>) to verify if GPU resources are allocatable:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>List all nodes in the cluster to identify the node with an AMD GPU:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>oc get nodes</pre>\n</div>\n</div>\n</li>\n<li>\n<p>Note the name of the node where you expect the AMD GPU to be present.</p>\n</li>\n<li>\n<p>Describe the node to check its resource allocation:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>oc describe node &lt;node_name&gt;</pre>\n</div>\n</div>\n</li>\n<li>\n<p>In the output, locate the <strong>Capacity</strong> and <strong>Allocatable</strong> sections and confirm that <code>amd.com/gpu</code> is listed. For example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>Capacity:\n  amd.com/gpu:  1\nAllocatable:\n  amd.com/gpu:  1</pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Check for the AMD GPU device using the <code>lspci</code> command:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Log in to the node:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>oc debug node/&lt;node_name&gt;\nchroot /host</pre>\n</div>\n</div>\n</li>\n<li>\n<p>Run the <code>lspci</code> command and search for the supported AMD device in your deployment. For example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>lspci | grep -E \"MI210|MI250|MI300\"</pre>\n</div>\n</div>\n</li>\n<li>\n<p>Verify that the output includes one of the AMD GPU models. For example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>03:00.0 Display controller: Advanced Micro Devices, Inc. [AMD] Instinct MI210</pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Optional: Use the <code>rocminfo</code> command if the ROCm stack is installed on the node:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre>rocminfo</pre>\n</div>\n</div>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Confirm that the ROCm tool outputs details about the AMD GPU, such as compute units, memory, and driver status.</p>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The <code>oc describe node &lt;node_name&gt;</code> command lists <code>amd.com/gpu</code> under <strong>Capacity</strong> and <strong>Allocatable</strong>.</p>\n</li>\n<li>\n<p>The <code>lspci</code> command output identifies an AMD GPU as a PCI device matching one of the specified models (for example, MI210, MI250, MI300).</p>\n</li>\n<li>\n<p>Optional: The <code>rocminfo</code> tool provides detailed GPU information, confirming driver and hardware configuration.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://github.com/ROCm/gpu-operator\">AMD GPU Operator GitHub Repository</a></p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"enabling-amd-gpus_managing-odh\">Enabling AMD GPUs</h4>\n<div class=\"paragraph _abstract\">\n<p>Before you can use AMD GPUs in Open Data Hub, you must install the required dependencies, deploy the AMD GPU Operator, and configure the environment.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to OpenShift Container Platform.</p>\n</li>\n<li>\n<p>You have the <code>cluster-admin</code> role in OpenShift Container Platform.</p>\n</li>\n<li>\n<p>You have installed your AMD GPU and confirmed that it is detected in your environment.</p>\n</li>\n<li>\n<p>Your OpenShift Container Platform environment supports EC2 DL1 instances if you are running on Amazon Web Services (AWS).</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Install the latest version of the AMD GPU Operator, as described in <a href=\"https://instinct.docs.amd.com/projects/gpu-operator/en/latest/installation/openshift-olm.html\">Install AMD GPU Operator on OpenShift</a>.</p>\n</li>\n<li>\n<p>After installing the AMD GPU Operator, configure the AMD drivers required by the Operator as described in the documentation: <a href=\"https://instinct.docs.amd.com/projects/gpu-operator/en/latest/drivers/installation.html\">Configure AMD drivers for the GPU Operator</a>.</p>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Alternatively, you can install the AMD GPU Operator from the Red&#160;Hat Catalog. For more information, see <a href=\"https://catalog.redhat.com/software/container-stacks/detail/6722781e65e61b6d4caccef8?rh-tabs-2b5yslu8z=rh-tab-v8le4ijlp\">Install AMD GPU Operator from Red Hat Catalog</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>After installing the AMD GPU Operator, create a hardware profile, as described in <a href=\"https://opendatahub.io/docs/working-with-accelerators/#working-with-hardware-profiles_accelerators\">Working with hardware profiles</a>.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>From the <strong>Administrator</strong> perspective, go to the <strong>Operators</strong> &#8594; <strong>Installed Operators</strong> page. Confirm that the following Operators appear:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>AMD GPU Operator</p>\n</li>\n<li>\n<p>Node Feature Discovery (NFD)</p>\n</li>\n<li>\n<p>Kernel Module Management (KMM)</p>\n</li>\n</ul>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Ensure that you follow all the steps for proper driver installation and configuration. Incorrect installation or configuration may prevent the AMD GPUs from being recognized or functioning properly.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"managing-workloads-with-kueue\">Managing workloads with Kueue</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>As a cluster administrator, you can manage AI and machine learning workloads at scale by integrating the Red Hat build of Kueue with Open Data Hub. This integration provides capabilities for quota management, resource allocation, and prioritized job scheduling.</p>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>The embedded Kueue component for managing distributed workloads is deprecated. Kueue is now provided through Red Hat build of Kueue, which is installed and managed by the Red Hat build of Kueue Operator. You cannot install both the embedded Kueue and the Red Hat build of Kueue Operator on the same cluster because this creates conflicting controllers that manage the same resources.</p>\n</div>\n<div class=\"paragraph\">\n<p>Open Data Hub does not automatically migrate existing workloads. To ensure your workloads continue using queue management after upgrading, cluster administrators must manually migrate from the embedded Kueue to the Red Hat build of Kueue Operator. For more information, see <a href=\"https://opendatahub.io/docs/managing-odh/#migrating-to-the-rhbok-operator_kueue\">Migrating to the Red Hat build of Kueue Operator</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"sect2\">\n<h3 id=\"overview-of-managing-workloads-with-kueue_kueue\">Overview of managing workloads with Kueue</h3>\n<div class=\"paragraph _abstract\">\n<p>You can use Kueue in Open Data Hub to manage AI and machine learning workloads at scale. Kueue controls how cluster resources are allocated and shared through hierarchical quota management, dynamic resource allocation, and prioritized job scheduling. These capabilities help prevent cluster contention, ensure fair access across teams, and optimize the use of heterogeneous compute resources, such as hardware accelerators.</p>\n</div>\n<div class=\"paragraph\">\n<p>Kueue lets you schedule diverse workloads, including distributed training jobs (<code>RayJob</code>, <code>RayCluster</code>, <code>PyTorchJob</code>), workbenches (<code>Notebook</code>), and model serving (<code>InferenceService</code>). Kueue validation and queue enforcement apply only to workloads in namespaces with the <code>kueue.openshift.io/managed=true</code> label.</p>\n</div>\n<div class=\"paragraph\">\n<p>Using Kueue in Open Data Hub provides these benefits:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Prevents resource conflicts and prioritizes workload processing</p>\n</li>\n<li>\n<p>Manages quotas across teams and projects</p>\n</li>\n<li>\n<p>Ensures consistent scheduling for all workload types</p>\n</li>\n<li>\n<p>Maximizes GPU and other specialized hardware utilization</p>\n</li>\n</ul>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_kueue_management_states\">Kueue management states</h4>\n<div class=\"paragraph\">\n<p>You configure how Open Data Hub interacts with Kueue by setting the <code>managementState</code> in the <code>DataScienceCluster</code> object.</p>\n</div>\n<div class=\"dlist\">\n<dl>\n<dt class=\"hdlist1\"><code>Unmanaged</code></dt>\n<dd>\n<p>This state is supported for using Kueue with Open Data Hub. In <code>Unmanaged</code> state, Open Data Hub integrates with an existing Kueue installation managed by the Red Hat build of Kueue Operator. You must have the Red Hat build of Kueue Operator installed and running on the cluster.</p>\n<div class=\"paragraph\">\n<p>When you enable <code>Unmanaged</code> mode, the Open Data Hub Operator creates a default <code>Kueue</code> custom resource (CR) if one does not already exist. This prompts the Red Hat build of Kueue Operator to activate Kueue on the cluster.</p>\n</div>\n</dd>\n<dt class=\"hdlist1\"><code>Managed</code></dt>\n<dd>\n<p>This state is deprecated. Previously, Open Data Hub deployed and managed an embedded Kueue distribution. <code>Managed</code> mode is not compatible with the Red Hat build of Kueue Operator. If both are installed, Open Data Hub stops reconciliation to avoid conflicts. You must migrate any environment using the <code>Managed</code> state to the <code>Unmanaged</code> state to ensure continued support.</p>\n</dd>\n<dt class=\"hdlist1\"><code>Removed</code></dt>\n<dd>\n<p>This state disables Kueue in Open Data Hub. If the state was previously <code>Managed</code>, Open Data Hub uninstalls the embedded Kueue distribution. If the state was previously <code>Unmanaged</code>, Open Data Hub stops checking for the external Kueue integration but does not uninstall the Red Hat build of Kueue Operator. An empty <code>managementState</code> value also functions as <code>Removed</code>.</p>\n</dd>\n</dl>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_queue_enforcement_for_projects\">Queue enforcement for projects</h4>\n<div class=\"paragraph\">\n<p>To ensure workloads do not bypass the queuing system, a validating webhook automatically enforces queuing rules on any project that is enabled for Kueue management. You enable a project for Kueue management by applying the <code>kueue.openshift.io/managed=true</code> label to the project namespace.</p>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>This validating webhook enforcement method replaces the Validating Admission Policy that was used with the deprecated embedded Kueue component. The system also supports the legacy <code>kueue-managed</code> label for backward compatibility, but <code>kueue.openshift.io/managed=true</code> is the recommended label going forward.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"paragraph\">\n<p>After a project is enabled for Kueue management, the webhook requires that any new or updated workload has the <code>kueue.x-k8s.io/queue-name</code> label. If this label is missing, the webhook prevents the workload from being created or updated.</p>\n</div>\n<div class=\"paragraph\">\n<p>Open Data Hub creates a default, cluster-scoped <code>ClusterQueue</code> (if one does not already exist) and a namespace-scoped <code>LocalQueue</code> for that namespace (if one does not already exist). These default resources are created with the <code>opendatahub.io/managed=false</code> annotation, so they are not managed after creation. Cluster administrators can change or delete them.</p>\n</div>\n<div class=\"paragraph\">\n<p>The webhook enforces this rule on the <code>create</code> and <code>update</code> operations for the following resource types:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><code>InferenceService</code></p>\n</li>\n<li>\n<p><code>Notebook</code></p>\n</li>\n<li>\n<p><code>PyTorchJob</code></p>\n</li>\n<li>\n<p><code>RayCluster</code></p>\n</li>\n<li>\n<p><code>RayJob</code></p>\n</li>\n</ul>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>You can apply hardware profiles to other workload types, but the validation webhook enforces the <code>kueue.x-k8s.io/queue-name</code> label requirement only for these specific resource types.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_restrictions_for_managing_workloads_with_kueue\">Restrictions for managing workloads with Kueue</h4>\n<div class=\"paragraph\">\n<p>When you use Kueue to manage workloads in Open Data Hub, the following restrictions apply:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Namespaces must be labeled with <code>kueue.openshift.io/managed=true</code> to enable Kueue validation and queue enforcement.</p>\n</li>\n<li>\n<p>All workloads that you create from the Open Data Hub dashboard, such as workbenches and model servers, must use a hardware profile that specifies a local queue.</p>\n</li>\n<li>\n<p>When you specify a local queue in a hardware profile, Open Data Hub automatically applies the corresponding <code>kueue.x-k8s.io/queue-name</code> label to workloads that use that profile.</p>\n</li>\n<li>\n<p>You cannot use hardware profiles that contain node selectors or tolerations for node placement. To direct workloads to specific nodes, use a hardware profile that specifies a local queue that is associated with a queue configured with the appropriate resource flavors.</p>\n</li>\n<li>\n<p>Because workbenches are not suspendable workloads, you can only assign them to a local queue that is associated with a non-preemptive cluster queue. The default cluster queue that Open Data Hub creates is non-preemptive.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/ai_workloads/red-hat-build-of-kueue\">Red Hat build of Kueue documentation</a></p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"kueue-workflow_kueue\">Kueue workflow</h4>\n<div class=\"paragraph\">\n<p>Managing workloads with Kueue in Open Data Hub involves tasks for OpenShift Container Platform cluster administrators, Open Data Hub administrators, and machine learning (ML) engineers or data scientists:</p>\n</div>\n<div class=\"paragraph\">\n<p><strong>Cluster administrator</strong></p>\n</div>\n<div class=\"paragraph\">\n<p>Installs and configures Kueue:</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>Installs the Red Hat build of Kueue Operator on the cluster, as described in the <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/ai_workloads/red-hat-build-of-kueue\">Red Hat build of Kueue documentation</a>.</p>\n</li>\n<li>\n<p>Activates the Kueue integration by setting the <code>managementState</code> to <code>Unmanaged</code> in the <code>DataScienceCluster</code> custom resource, as described in <a href=\"https://opendatahub.io/docs/managing-odh/#configuring-workload-management-with-kueue_kueue\">Configuring workload management with Kueue</a>.</p>\n</li>\n<li>\n<p>Configures quotas to optimize resource allocation for user workloads, as described in the <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/ai_workloads/red-hat-build-of-kueue\">Red Hat build of Kueue documentation</a>.</p>\n</li>\n<li>\n<p>Enables Kueue in the dashboard by setting <code>disableKueue</code> to <code>false</code> in the <code>OdhDashboardConfig</code> custom resource, as described in <a href=\"https://opendatahub.io/docs/managing-odh/#enabling-kueue-in-the-dashboard_managing-odh\">Enabling Kueue in the dashboard</a>.</p>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>When Kueue is enabled in the dashboard, Open Data Hub automatically enables Kueue management for all new projects created from the dashboard. For existing projects, or for projects created by using the OpenShift CLI (<code>oc</code>), you must enable Kueue management manually by applying the <code>kueue.openshift.io/managed=true</code> label to the project namespace.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<p><strong>Open Data Hub administrator</strong></p>\n</div>\n<div class=\"paragraph\">\n<p>Prepares the Open Data Hub environment:</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>Creates Kueue-enabled hardware profiles so that users can submit workloads from the Open Data Hub dashboard, as described in <a href=\"https://opendatahub.io/docs/working-with-accelerators/#working-with-hardware-profiles_accelerators\">Working with hardware profiles</a>.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<p><strong>ML Engineer or data scientist</strong></p>\n</div>\n<div class=\"paragraph\">\n<p>Submits workloads to the queuing system:</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>For workloads created from the Open Data Hub dashboard, such as workbenches and model servers, selects a Kueue-enabled hardware profile during creation.</p>\n</li>\n<li>\n<p>For workloads created by using a command-line interface or an SDK, such as distributed training jobs, adds the <code>kueue.x-k8s.io/queue-name</code> label to the workload&#8217;s YAML manifest and sets its value to the target <code>LocalQueue</code> name.</p>\n</li>\n</ol>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"configuring-workload-management-with-kueue_kueue\">Configuring workload management with Kueue</h3>\n<div class=\"paragraph _abstract\">\n<p>To use workload queuing in Open Data Hub, install the Red Hat build of Kueue Operator and activate the Kueue integration in Open Data Hub.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have cluster administrator privileges for your OpenShift Container Platform cluster.</p>\n</li>\n<li>\n<p>You are using OpenShift Container Platform 4.19 or later.</p>\n</li>\n<li>\n<p>You have installed and configured the <strong>cert-manager Operator for Red&#160;Hat OpenShift</strong> for your cluster.</p>\n</li>\n<li>\n<p>You have installed the OpenShift CLI (<code>oc</code>) as described in the appropriate documentation for your cluster:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/cli_tools/openshift-cli-oc#installing-openshift-cli\" target=\"_blank\" rel=\"noopener\">Installing the OpenShift CLI</a> for OpenShift Container Platform</p>\n</li>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/red_hat_openshift_service_on_aws/4/html/cli_tools/openshift-cli-oc#installing-openshift-cli\" target=\"_blank\" rel=\"noopener\">Installing the OpenShift CLI</a> for Red&#160;Hat OpenShift Service on AWS</p>\n</li>\n</ul>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In a terminal window, log in to the OpenShift CLI (<code>oc</code>) as shown in the following example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ oc login <em>&lt;openshift_cluster_url&gt;</em> -u <em>&lt;admin_username&gt;</em> -p <em>&lt;password&gt;</em></code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Install the Red Hat build of Kueue Operator on your OpenShift Container Platform cluster as described in the <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/ai_workloads/red-hat-build-of-kueue\">Red Hat build of Kueue documentation</a>.</p>\n</li>\n<li>\n<p>Activate the Kueue integration. You can use the predefined names for the default cluster queue and default local queue, or specify custom names.</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>To use the predefined queue names (<code>default</code>), run the following command. Replace <code>&lt;operator-namespace&gt;</code> with your operator namespace. The default operator namespace is <code>openshift-operators</code>.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc patch datasciencecluster default-dsc --type='merge' -p '{\"spec\":{\"components\":{\"kueue\":{\"managementState\":\"Unmanaged\"}}}}' -n &lt;operator-namespace&gt;</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>To specify custom queue names, run the following command. Replace <code>&lt;example-cluster-queue&gt;</code> and <code>&lt;example-local-queue&gt;</code> with your custom queue names, and replace <code>&lt;operator-namespace&gt;</code> with your operator namespace. The default operator namespace is <code>openshift-operators</code>.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc patch datasciencecluster default-dsc --type='merge' -p '{\"spec\":{\"components\":{\"kueue\":{\"managementState\":\"Unmanaged\",\"defaultClusterQueueName\":\"&lt;example-cluster-queue&gt;\",\"defaultLocalQueueName\":\"&lt;example-local-queue&gt;\"}}}}' -n &lt;operator-namespace&gt;</code></pre>\n</div>\n</div>\n</li>\n</ul>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Verification</div>\n<ol class=\"arabic\">\n<li>\n<p>Verify that the Red Hat build of Kueue pods are running:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc get pods -n openshift-kueue-operator</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>You should see output similar to the following example:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>kueue-controller-manager-d9fc745df-ph77w    1/1     Running\nopenshift-kueue-operator-69cfbf45cf-lwtpm   1/1     Running</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Verify that the default <code>ClusterQueue</code> was created:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc get clusterqueues</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Next steps</div>\n<ul>\n<li>\n<p>Configure quotas by creating and modifying <code>ResourceFlavor</code>, <code>ClusterQueue</code>, and <code>LocalQueue</code> objects. For details, see the <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/ai_workloads/red-hat-build-of-kueue\">Red Hat build of Kueue documentation</a>.</p>\n</li>\n<li>\n<p>Enable Kueue in the dashboard so that users can select Kueue-enabled options when creating workloads. When you enable Kueue, you also enable Kueue management for all new projects created from the dashboard.\nSee <a href=\"https://opendatahub.io/docs/managing-odh/#enabling-kueue-in-the-dashboard_kueue\">Enabling Kueue in the dashboard</a>.</p>\n</li>\n<li>\n<p>Cluster administrators and Open Data Hub administrators can create hardware profiles so that users can submit workloads from the Open Data Hub dashboard.\nSee <a href=\"https://opendatahub.io/docs/working-with-accelerators/#working-with-hardware-profiles_accelerators\">Working with hardware profiles</a>.</p>\n</li>\n</ul>\n</div>\n<div class=\"sect3\">\n<h4 id=\"enabling-kueue-in-the-dashboard_kueue\">Enabling Kueue in the dashboard</h4>\n<div class=\"paragraph _abstract\">\n<p>Enable Kueue in the Open Data Hub dashboard so that users can select Kueue-enabled options when creating workloads.</p>\n</div>\n<div class=\"paragraph\">\n<p>When you enable Kueue in the dashboard, Open Data Hub automatically enables Kueue management for all new projects created from the dashboard. For these projects, Open Data Hub applies the <code>kueue.openshift.io/managed=true</code> label to the namespace and creates a <code>LocalQueue</code> object if one does not already exist. The <code>LocalQueue</code> object is created with the <code>opendatahub.io/managed=false</code> annotation, so it is not managed after creation. Cluster administrators can modify or delete it as needed. A validating webhook then enforces that any new or updated workload resource in a Kueue-enabled project includes the <code>kueue.x-k8s.io/queue-name</code> label.</p>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>For existing projects, or for projects created by using the OpenShift CLI (<code>oc</code>), you must enable Kueue management manually by applying the <code>kueue.openshift.io/managed=true</code> label to the project namespace.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc label namespace &lt;project-namespace&gt; kueue.openshift.io/managed=true --overwrite</code></pre>\n</div>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have cluster administrator privileges for your OpenShift Container Platform cluster.</p>\n</li>\n<li>\n<p>You are using OpenShift Container Platform 4.19 or later.</p>\n</li>\n<li>\n<p>You have installed and activated the Red Hat build of Kueue Operator, as described in <a href=\"https://opendatahub.io/docs/managing-odh/#configuring-workload-management-with-kueue_kueue\">Configuring workload management with Kueue</a>.</p>\n</li>\n<li>\n<p>You have configured quotas, as described in the <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/ai_workloads/red-hat-build-of-kueue\">Red Hat build of Kueue documentation</a>.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In a terminal window, log in to the OpenShift CLI (<code>oc</code>) as shown in the following example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ oc login <em>&lt;openshift_cluster_url&gt;</em> -u <em>&lt;admin_username&gt;</em> -p <em>&lt;password&gt;</em></code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Update the <code>odh-dashboard-config</code> custom resource in the Open Data Hub applications namespace. Replace <code>&lt;applications-namespace&gt;</code> with your Open Data Hub applications namespace. The default is <code>opendatahub</code>.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc patch odhdashboardconfig odh-dashboard-config \\\n  -n \\&lt;applications-namespace\\&gt; \\\n  --type merge \\\n  -p <em>{\"spec\":{\"dashboardConfig\":{\"disableKueue\":false}}}</em></code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Verification</div>\n<ol class=\"arabic\">\n<li>\n<p>From the Open Data Hub dashboard, create a new project.</p>\n</li>\n<li>\n<p>Verify that the project namespace is labeled for Kueue management:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc get ns &lt;project-namespace&gt; -o jsonpath='{.metadata.labels.kueue\\.openshift\\.io/managed}{\"\\n\"}'</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The output should be <code>true</code>.</p>\n</div>\n</li>\n<li>\n<p>Confirm that a default <code>LocalQueue</code> exists for the project namespace:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc get localqueues -n &lt;project-namespace&gt;</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Create a test workload (for example, a <code>Notebook</code>) and verify that it includes the <code>kueue.x-k8s.io/queue-name</code> label.</p>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Next step</div>\n<ul>\n<li>\n<p>Cluster administrators and Open Data Hub administrators can create hardware profiles so that users can submit workloads from the Open Data Hub dashboard.\nSee <a href=\"https://opendatahub.io/docs/working-with-accelerators/#working-with-hardware-profiles_accelerators\">Working with hardware profiles</a>.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"troubleshooting-common-problems-with-Kueue_kueue\">Troubleshooting common problems with Kueue</h3>\n<div class=\"paragraph _abstract\">\n<p>If your users are experiencing errors in Open Data Hub relating to Kueue workloads, read this section to understand what could be causing the problem, and how to resolve the problem.</p>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_a_user_receives_a_failed_to_call_webhook_error_message_for_kueue\">A user receives a \"failed to call webhook\" error message for Kueue</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>After the user runs the <code>cluster.apply()</code> command, the following error is shown:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">ApiException: (500)\nReason: Internal Server Error\nHTTP response body: {\"kind\":\"Status\",\"apiVersion\":\"v1\",\"metadata\":{},\"status\":\"Failure\",\"message\":\"Internal error occurred: failed calling webhook \\\"mraycluster.kb.io\\\": failed to call webhook: Post \\\"https://kueue-webhook-service.redhat-ods-applications.svc:443/mutate-ray-io-v1-raycluster?timeout=10s\\\": no endpoints available for service \\\"kueue-webhook-service\\\"\",\"reason\":\"InternalError\",\"details\":{\"causes\":[{\"message\":\"failed calling webhook \\\"mraycluster.kb.io\\\": failed to call webhook: Post \\\"https://kueue-webhook-service.redhat-ods-applications.svc:443/mutate-ray-io-v1-raycluster?timeout=10s\\\": no endpoints available for service \\\"kueue-webhook-service\\\"\"}]},\"code\":500}</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Diagnosis</div>\n<p>The Kueue pod might not be running.</p>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Resolution</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform console, select the user&#8217;s project from the <strong>Project</strong> list.</p>\n</li>\n<li>\n<p>Click <strong>Workloads &#8594; Pods</strong>.</p>\n</li>\n<li>\n<p>Verify that the Kueue pod is running.\nIf necessary, restart the Kueue pod.</p>\n</li>\n<li>\n<p>Review the logs for the Kueue pod to verify that the webhook server is serving, as shown in the following example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">{\"level\":\"info\",\"ts\":\"2024-06-24T14:36:24.255137871Z\",\"logger\":\"controller-runtime.webhook\",\"caller\":\"webhook/server.go:242\",\"msg\":\"Serving webhook server\",\"host\":\"\",\"port\":9443}</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_a_user_receives_a_default_local_queue_not_found_error_message\">A user receives a \"Default Local Queue &#8230;&#8203; not found\" error message</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>After the user runs the <code>cluster.apply()</code> command, the following error is shown:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">Default Local Queue with kueue.x-k8s.io/default-queue: true annotation not found please create a default Local Queue or provide the local_queue name in Cluster Configuration.</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Diagnosis</div>\n<p>No default local queue is defined, and a local queue is not specified in the cluster configuration.</p>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Resolution</div>\n<ol class=\"arabic\">\n<li>\n<p>Check whether a local queue exists in the user&#8217;s project, as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift Container Platform console, select the user&#8217;s project from the <strong>Project</strong> list.</p>\n</li>\n<li>\n<p>Click <strong>Home &#8594; Search</strong>, and from the <strong>Resources</strong> list, select <strong>LocalQueue</strong>.</p>\n</li>\n<li>\n<p>If no local queues are found, create a local queue.</p>\n</li>\n<li>\n<p>Provide the user with the details of the local queues in their project, and advise them to add a local queue to their cluster configuration.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Define a default local queue.</p>\n<div class=\"paragraph\">\n<p>For information about creating a local queue and defining a default local queue, see <a href=\"https://opendatahub.io/docs/managing-odh/#configuring-quota-management-for-distributed-workloads_managing-odh\">Configuring quota management for distributed workloads</a>.</p>\n</div>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_a_user_receives_a_local_queue_provided_does_not_exist_error_message\">A user receives a \"local_queue provided does not exist\" error message</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>After the user runs the <code>cluster.apply()</code> command, the following error is shown:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">local_queue provided does not exist or is not in this namespace. Please provide the correct local_queue name in Cluster Configuration.</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Diagnosis</div>\n<p>An incorrect value is specified for the local queue in the cluster configuration, or an incorrect default local queue is defined.\nThe specified local queue either does not exist, or exists in a different namespace.</p>\n</div>\n<div class=\"olist loweralpha\">\n<div class=\"title\">Resolution</div>\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift Container Platform console, select the user&#8217;s project from the <strong>Project</strong> list.</p>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>Click <strong>Search</strong>, and from the <strong>Resources</strong> list, select <strong>LocalQueue</strong>.</p>\n</li>\n<li>\n<p>Resolve the problem in one of the following ways:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>If no local queues are found, create a local queue.</p>\n</li>\n<li>\n<p>If one or more local queues are found, provide the user with the details of the local queues in their project.\nAdvise the user to ensure that they spelled the local queue name correctly in their cluster configuration, and that the <code>namespace</code> value in the cluster configuration matches their project name.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Define a default local queue.</p>\n<div class=\"paragraph\">\n<p>For information about creating a local queue and defining a default local queue, see <a href=\"https://opendatahub.io/docs/managing-odh/#configuring-quota-management-for-distributed-workloads_managing-odh\">Configuring quota management for distributed workloads</a>.</p>\n</div>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_the_pod_provisioned_by_kueue_is_terminated_before_the_image_is_pulled\">The pod provisioned by Kueue is terminated before the image is pulled</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>Kueue waits for a period of time before marking a workload as ready for all of the workload pods to become provisioned and running.\nBy default, Kueue waits for 5 minutes.\nIf the pod image is very large and is still being pulled after the 5-minute waiting period elapses, Kueue fails the workload and terminates the related pods.</p>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Diagnosis</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform console, select the user&#8217;s project from the <strong>Project</strong> list.</p>\n</li>\n<li>\n<p>Click <strong>Workloads</strong> &#8594; <strong>Pods</strong>.</p>\n</li>\n<li>\n<p>Click the user&#8217;s pod name to open the pod details page.</p>\n</li>\n<li>\n<p>Click the <strong>Events</strong> tab, and review the pod events to check whether the image pull completed successfully.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Resolution</div>\n<p>If the pod takes more than 5 minutes to pull the image, resolve the problem in one of the following ways:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Add an <code>OnFailure</code> restart policy for resources that are managed by Kueue.</p>\n</li>\n<li>\n<p>Configure a custom timeout for the <code>waitForPodsReady</code> property in the <code>Kueue</code> custom resource (CR). The CR is installed in the <code>openshift-kueue-operator</code> namespace by the Red Hat build of Kueue Operator.</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>For more information about this configuration option, see <a href=\"https://kueue.sigs.k8s.io/docs/tasks/manage/setup_wait_for_pods_ready/#enabling-waitforpodsready\">Enabling waitForPodsReady</a> in the Kueue documentation.</p>\n</div>\n</div>\n<div class=\"sect3 _additional-resources\">\n<h4 id=\"_additional_resources\">Additional resources</h4>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><a href=\"https://opendatahub.io/docs/managing-odh/#troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh\">Troubleshooting common problems with distributed workloads for administrators</a></p>\n</li>\n<li>\n<p><a href=\"https://opendatahub.io/docs/working-with-distributed-workloads/#troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads\">Troubleshooting common problems with distributed workloads for users</a></p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"migrating-to-the-rhbok-operator_kueue\">Migrating to the Red Hat build of Kueue Operator</h3>\n<div class=\"paragraph\">\n<p>The embedded Kueue component for managing distributed workloads is deprecated.</p>\n</div>\n<div class=\"paragraph\">\n<p>Open Data Hub now uses the Red Hat build of Kueue Operator to provide enhanced workload scheduling for distributed training, workbench, and model serving workloads.</p>\n</div>\n<div class=\"paragraph\">\n<p>Check if your environment is using the embedded Kueue component by verifying the <code>spec.components.kueue.managementState</code> field in the <code>DataScienceCluster</code> custom resource. If the field is set to <code>Managed</code>, you must migrate to the Red Hat build of Kueue Operator before upgrading Open Data Hub to avoid controller conflicts and ensure continued support for queue-based workloads.</p>\n</div>\n<div class=\"paragraph\">\n<p>Open Data Hub does not automatically migrate workloads, and you cannot install both the embedded Kueue and the Red Hat build of Kueue Operator on the same cluster.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>Your environment is currently using the embedded Kueue component. That is, the <code>spec.components.kueue.managementState</code> field in the <code>DataScienceCluster</code> custom resource is set to <code>Managed</code>.</p>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>If <code>spec.components.kueue.managementState</code> is set to <code>Removed</code> or <code>Unmanaged</code>, skip this migration.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>You have cluster administrator privileges for your OpenShift Container Platform cluster.</p>\n</li>\n<li>\n<p>You are using OpenShift Container Platform 4.19 or later.</p>\n</li>\n<li>\n<p>You have installed and configured the <strong>cert-manager Operator for Red&#160;Hat OpenShift</strong> for your cluster.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Optional: When you migrate from the embedded Kueue to Red Hat build of Kueue, the Open Data Hub Operator automatically moves your existing Kueue configuration from the <code>kueue-manager-config</code> ConfigMap to the <code>Kueue</code> custom resource (CR).</p>\n<div class=\"paragraph\">\n<p>If you want to keep the <code>kueue-manager-config</code> ConfigMap for reference, run the following command. Replace <code>&lt;applications-namespace&gt;</code> with your Open Data Hub applications namespace. The default namespace is <code>opendatahub</code>.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc annotate configmap kueue-manager-config -n &lt;applications-namespace&gt; opendatahub.io/managed=false</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Log in to the OpenShift Container Platform web console as a cluster administrator.</p>\n</li>\n<li>\n<p>Uninstall the embedded Kueue component to avoid potential configuration conflicts.</p>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>If you need to keep workloads running without interruption, you can skip this step. However, skipping it is not recommended because it might cause temporary configuration issues during the Open Data Hub upgrade.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the web console, click <strong>Operators</strong> &#8594; <strong>Installed Operators</strong> and then click the Open Data Hub Operator.</p>\n</li>\n<li>\n<p>Click the <strong>Data Science Cluster</strong> tab.</p>\n</li>\n<li>\n<p>Click the <strong>default-dsc</strong> object.</p>\n</li>\n<li>\n<p>Click the <strong>YAML</strong> tab.</p>\n</li>\n<li>\n<p>Set <code>spec.components.kueue.managementState</code> to <code>Removed</code> as shown:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-yaml\" data-lang=\"yaml\">spec:\n  components:\n    kueue:\n      managementState: Removed</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Click <strong>Save</strong>.</p>\n</li>\n<li>\n<p>Wait for the Open Data Hub Operator to reconcile, and then verify that the embedded Kueue was removed:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>On the <strong>Details</strong> tab of the <code>default-dsc</code> object, check that the <strong>KueueReady</strong> condition has a <strong>Status</strong> of <code>False</code> and a <strong>Reason</strong> of <code>Removed</code>.</p>\n</li>\n<li>\n<p>Go to <strong>Workloads</strong> &#8594; <strong>Deployments</strong>, select the project where Open Data Hub is installed (for example, <code>redhat-ods-applications</code>), and confirm that Kueue-related deployments (for example, <code>kueue-controller-manager</code>) are no longer present.</p>\n</li>\n</ul>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Install the Red Hat build of Kueue Operator on your OpenShift Container Platform cluster:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Follow the steps to install the Red Hat build of Kueue Operator, as described in the <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/ai_workloads/red-hat-build-of-kueue\">Red Hat build of Kueue documentation</a>.</p>\n</li>\n<li>\n<p>Go to <strong>Operators</strong> &#8594; <strong>Installed Operators</strong> and confirm that the Red Hat build of Kueue Operator is listed with <strong>Status</strong> as <strong>Succeeded</strong>.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Activate the Red Hat build of Kueue Operator in Open Data Hub:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the web console, click <strong>Operators</strong> &#8594; <strong>Installed Operators</strong> and then click the Open Data Hub Operator.</p>\n</li>\n<li>\n<p>Click the <strong>Data Science Cluster</strong> tab.</p>\n</li>\n<li>\n<p>Click the <strong>default-dsc</strong> object.</p>\n</li>\n<li>\n<p>Click the <strong>YAML</strong> tab.</p>\n</li>\n<li>\n<p>Set <code>spec.components.kueue.managementState</code> to <code>Unmanaged</code>. You can either use the predefined names (<code>default</code>) for the default cluster queue and default local queue, or specify custom names, as shown in the following examples.</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>To use the predefined queue names, apply the following configuration:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-yaml\" data-lang=\"yaml\">spec:\n  components:\n    kueue:\n      managementState: Unmanaged</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>To specify custom queue names, apply the following configuration, replacing <code>&lt;example-cluster-queue&gt;</code> and <code>&lt;example-local-queue&gt;</code> with your custom values:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-yaml\" data-lang=\"yaml\">spec:\n  components:\n    kueue:\n      managementState: Unmanaged\n      defaultClusterQueueName: &lt;example-cluster-queue&gt;\n      defaultLocalQueueName: &lt;example-local-queue&gt;</code></pre>\n</div>\n</div>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Click <strong>Save</strong>.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Enable Kueue management for existing projects by applying the <code>kueue.openshift.io/managed=true</code> label to each project namespace:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc label namespace &lt;project-namespace&gt; kueue.openshift.io/managed=true --overwrite</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>Replace <code>&lt;project-namespace&gt;</code> with the name of your project.</p>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Kueue validation and queue enforcement apply only to workloads in namespaces labeled with <code>kueue.openshift.io/managed=true</code>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Verify that the embedded Kueue component was removed.</p>\n</li>\n<li>\n<p>Verify that the <code>DataScienceCluster</code> resource shows a healthy <code>Unmanaged</code> status for Kueue.</p>\n</li>\n<li>\n<p>Verify that existing workloads in the queue continue to be processed by the Red Hat build of Kueue controllers. Submit a new test workload to confirm functionality.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Next steps</div>\n<ul>\n<li>\n<p>Configure quotas by creating and modifying <code>ResourceFlavor</code>, <code>ClusterQueue</code>, and <code>LocalQueue</code> objects. For details, see the <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/ai_workloads/red-hat-build-of-kueue\">Red Hat build of Kueue documentation</a>.</p>\n</li>\n<li>\n<p>Enable Kueue in the dashboard so that users can select Kueue-enabled options when creating workloads. When enabled, Kueue management is automatically applied to all new projects created from the dashboard.\nSee <a href=\"https://opendatahub.io/docs/managing-odh/#enabling-kueue-in-the-dashboard_kueue\">Enabling Kueue in the dashboard</a>.</p>\n</li>\n<li>\n<p>Cluster administrators and Open Data Hub administrators can create hardware profiles so that users can submit workloads from the Open Data Hub dashboard.\nSee <a href=\"https://opendatahub.io/docs/working-with-accelerators/#working-with-hardware-profiles_accelerators\">Working with hardware profiles</a>.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"managing-distributed-workloads_managing-odh\">Managing distributed workloads</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>In Open Data Hub, distributed workloads like <code>PyTorchJob</code>, <code>RayJob</code>, and <code>RayCluster</code> are created and managed by their respective workload operators. Kueue provides queueing and admission control and integrates with these operators to decide when workloads can run based on cluster-wide quotas.</p>\n</div>\n<div class=\"paragraph\">\n<p>You can perform advanced configuration for your distributed workloads environment, such as configuring quota management, or setting up a cluster for RDMA.</p>\n</div>\n<div class=\"sect2\">\n<h3 id=\"configuring-quota-management-for-distributed-workloads_managing-odh\">Configuring quota management for distributed workloads</h3>\n<div class=\"paragraph _abstract\">\n<p>Configure quotas for distributed workloads by creating Kueue resources. Quotas ensure that you can share resources between several projects.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have logged in to OpenShift Container Platform with the <code>cluster-admin</code> role.</p>\n</li>\n<li>\n<p>You have installed the OpenShift CLI (<code>oc</code>) as described in the appropriate documentation for your cluster:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/cli_tools/openshift-cli-oc#installing-openshift-cli\" target=\"_blank\" rel=\"noopener\">Installing the OpenShift CLI</a> for OpenShift Container Platform</p>\n</li>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/red_hat_openshift_service_on_aws/4/html/cli_tools/openshift-cli-oc#installing-openshift-cli\" target=\"_blank\" rel=\"noopener\">Installing the OpenShift CLI</a> for Red&#160;Hat OpenShift Service on AWS</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>You have installed and activated the Red Hat build of Kueue Operator as described in <a href=\"https://opendatahub.io/docs/managing-odh/#configuring-workload-management-with-kueue_kueue\">Configuring workload management with Kueue</a>.</p>\n</li>\n<li>\n<p>You have installed the required distributed workloads components as described in <a href=\"https://opendatahub.io/docs/installing-open-data-hub/#installing-the-distributed-workloads-components_install\">Installing the distributed workloads components</a>.</p>\n</li>\n<li>\n<p>You have created a project that contains a workbench, and the workbench is running a default workbench image that contains the CodeFlare SDK, for example, the <strong>Standard Data Science</strong> workbench. For information about how to create a project, see <a href=\"https://opendatahub.io/docs/working-on-projects/#creating-a-project_projects\">Creating a project</a>.</p>\n</li>\n<li>\n<p>You have sufficient resources. In addition to the base Open Data Hub resources, you need 1.6 vCPU and 2 GiB memory to deploy the distributed workloads infrastructure.</p>\n</li>\n<li>\n<p>The resources are physically available in the cluster. For more information about Kueue resources, see the <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/ai_workloads/red-hat-build-of-kueue\">Red Hat build of Kueue documentation</a>.</p>\n</li>\n<li>\n<p>If you want to use graphics processing units (GPUs), you have enabled GPU support.\nThis process includes installing the Node Feature Discovery Operator and the relevant GPU Operator.\nFor more information, see <a href=\"https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/index.html\" target=\"_blank\" rel=\"noopener\">NVIDIA GPU Operator on Red&#160;Hat OpenShift Container Platform</a> in the NVIDIA documentation for NVIDIA GPUs and <a href=\"https://instinct.docs.amd.com/projects/gpu-operator/en/latest/installation/openshift-olm.html\" target=\"_blank\" rel=\"noopener\">AMD GPU Operator on Red&#160;Hat OpenShift Container Platform</a> in the AMD documentation for AMD GPUs.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In a terminal window, if you are not already logged in to your OpenShift cluster as a cluster administrator, log in to the OpenShift CLI (<code>oc</code>) as shown in the following example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ oc login <em>&lt;openshift_cluster_url&gt;</em> -u <em>&lt;admin_username&gt;</em> -p <em>&lt;password&gt;</em></code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Verify that a resource flavor exists or create a custom one, as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Check whether a <code>ResourceFlavor</code> already exists:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc get resourceflavors</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>If a <code>ResourceFlavor</code> already exists and you need to modify it, edit it in place:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc edit resourceflavor &lt;existing_resourceflavor_name&gt;</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>If a <code>ResourceFlavor</code> does not exist or you want a custom one, create a file called <code>default_flavor.yaml</code> and populate it with the following content:</p>\n<div class=\"listingblock\">\n<div class=\"title\">Empty Kueue resource flavor</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-yaml\" data-lang=\"yaml\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ResourceFlavor\nmetadata:\n  name: &lt;example_resource_flavor&gt;</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>For more examples, see <em>Example Kueue resource configurations</em>.</p>\n</div>\n</li>\n<li>\n<p>Perform one of the following actions:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>If you are modifying the existing resource flavor, save the changes.</p>\n</li>\n<li>\n<p>If you are creating a new resource flavor, apply the configuration to create the <code>ResourceFlavor</code> object:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc apply -f default_flavor.yaml</code></pre>\n</div>\n</div>\n</li>\n</ul>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Verify that a default cluster queue exists or create a custom one, as follows:</p>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Open Data Hub automatically created a default cluster queue when the Kueue integration was activated. You can verify and modify the default cluster queue, or create a custom one.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Check whether a <code>ClusterQueue</code> already exists:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc get clusterqueues</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>If a <code>ClusterQueue</code> already exists and you need to modify it (for example, to change the resources), edit it in place:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc edit clusterqueue &lt;existing_clusterqueue_name&gt;</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>If a <code>ClusterQueue</code> does not exist or you want a custom one, create a file called <code>cluster_queue.yaml</code> and populate it with the following content:</p>\n<div class=\"listingblock\">\n<div class=\"title\">Example cluster queue</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-YAML\" data-lang=\"YAML\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ClusterQueue\nmetadata:\n  name: &lt;example_cluster_queue&gt;\nspec:\n  namespaceSelector: {}  <b class=\"conum\">(1)</b>\n  resourceGroups:\n  - coveredResources: [\"cpu\", \"memory\", \"nvidia.com/gpu\"]  <b class=\"conum\">(2)</b>\n    flavors:\n    - name: \"&lt;resource_flavor_name&gt;\"  <b class=\"conum\">(3)</b>\n      resources:  <b class=\"conum\">(4)</b>\n      - name: \"cpu\"\n        nominalQuota: 9\n      - name: \"memory\"\n        nominalQuota: 36Gi\n      - name: \"nvidia.com/gpu\"\n        nominalQuota: 5</code></pre>\n</div>\n</div>\n<div class=\"colist arabic\">\n<ol>\n<li>\n<p>Defines which namespaces can use the resources governed by this cluster queue. An empty <code>namespaceSelector</code> as shown in the example means that all namespaces can use these resources.</p>\n</li>\n<li>\n<p>Defines the resource types governed by the cluster queue. This example <code>ClusterQueue</code> object governs CPU, memory, and GPU resources. If you use AMD GPUs, replace <code>nvidia.com/gpu</code> with <code>amd.com/gpu</code> in the example code.</p>\n</li>\n<li>\n<p>Defines the resource flavor that is applied to the resource types listed. In this example, the &lt;resource_flavor_name&gt; resource flavor is applied to CPU, memory, and GPU resources.</p>\n</li>\n<li>\n<p>Defines the resource requirements for admitting jobs. The cluster queue will start a distributed workload only if the total required resources are within these quota limits.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Replace the example quota values (9 CPUs, 36 GiB memory, and 5 NVIDIA GPUs) with the appropriate values for your cluster queue.\nIf you use AMD GPUs, replace <code>nvidia.com/gpu</code> with <code>amd.com/gpu</code> in the example code. For more examples, see <em>Example Kueue resource configurations</em>.</p>\n<div class=\"paragraph\">\n<p>You must specify a quota for each resource that the user can request, even if the requested value is 0, by updating the <code>spec.resourceGroups</code> section as follows:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Include the resource name in the <code>coveredResources</code> list.</p>\n</li>\n<li>\n<p>Specify the resource <code>name</code> and <code>nominalQuota</code> in the <code>flavors.resources</code> section, even if the <code>nominalQuota</code> value is 0.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Perform one of the following actions:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>If you are modifying the existing cluster queue, save the changes.</p>\n</li>\n<li>\n<p>If you are creating a new cluster queue, apply the configuration to create the <code>ClusterQueue</code> object:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc apply -f cluster_queue.yaml</code></pre>\n</div>\n</div>\n</li>\n</ul>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Verify that a local queue that points to your cluster queue exists for your project namespace, or create a custom one, as follows:</p>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>If Kueue is enabled in the Open Data Hub dashboard, new projects created from the dashboard are automatically configured for Kueue management. In those namespaces, a default local queue might already exist. You can verify and modify the local queue, or create a custom one.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Check whether a <code>LocalQueue</code> already exists for your project namespace:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc get localqueues -n &lt;project_namespace&gt;</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>If a <code>LocalQueue</code> already exists and you need to modify it (for example, to point to a different <code>ClusterQueue</code>), edit it in place:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc edit localqueue &lt;existing_localqueue_name&gt; -n &lt;project_namespace&gt;</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>If a <code>LocalQueue</code> does not exist or you want a custom one, create a file called <code>local_queue.yaml</code> and populate it with the following content:</p>\n<div class=\"listingblock\">\n<div class=\"title\">Example local queue</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-YAML\" data-lang=\"YAML\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: LocalQueue\nmetadata:\n  name: &lt;example_local_queue&gt;\n  namespace: &lt;project_namespace&gt;\nspec:\n  clusterQueue: &lt;cluster_queue_name&gt;</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Replace the <code>name</code>, <code>namespace</code>, and <code>clusterQueue</code> values accordingly.</p>\n</li>\n<li>\n<p>Perform one of the following actions:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>If you are modifying an existing local queue, save the changes.</p>\n</li>\n<li>\n<p>If you are creating a new local queue, apply the configuration to create the <code>LocalQueue</code> object:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc apply -f local_queue.yaml</code></pre>\n</div>\n</div>\n</li>\n</ul>\n</div>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>Check the status of the local queue in a project, as follows:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc get localqueues -n &lt;project_namespace&gt;</code></pre>\n</div>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/ai_workloads/red-hat-build-of-kueue\">Red Hat build of Kueue documentation</a></p>\n</li>\n<li>\n<p><a href=\"https://kueue.sigs.k8s.io/docs/concepts/\">Kueue documentation</a></p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"ref-example-kueue-resource-configurations_managing-odh\">Example Kueue resource configurations for distributed workloads</h3>\n<div class=\"paragraph _abstract\">\n<p>You can use these example configurations as a starting point for creating Kueue resources to manage your distributed training workloads.</p>\n</div>\n<div class=\"paragraph\">\n<p>These examples show how to configure Kueue resource flavors and cluster queues for common distributed training scenarios.</p>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_nvidia_gpus_without_shared_cohort\">NVIDIA GPUs without shared cohort</h4>\n<div class=\"sect4\">\n<h5 id=\"_nvidia_rtx_a400_gpu_resource_flavor\">NVIDIA RTX A400 GPU resource flavor</h5>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ResourceFlavor\nmetadata:\n  name: \"a400node\"\nspec:\n  nodeLabels:\n    instance-type: nvidia-a400-node\n  tolerations:\n  - key: \"HasGPU\"\n    operator: \"Exists\"\n    effect: \"NoSchedule\"</code></pre>\n</div>\n</div>\n</div>\n<div class=\"sect4\">\n<h5 id=\"_nvidia_rtx_a1000_gpu_resource_flavor\">NVIDIA RTX A1000 GPU resource flavor</h5>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ResourceFlavor\nmetadata:\n  name: \"a1000node\"\nspec:\n  nodeLabels:\n    instance-type: nvidia-a1000-node\n  tolerations:\n  - key: \"HasGPU\"\n    operator: \"Exists\"\n    effect: \"NoSchedule\"</code></pre>\n</div>\n</div>\n</div>\n<div class=\"sect4\">\n<h5 id=\"_nvidia_rtx_a400_gpu_cluster_queue\">NVIDIA RTX A400 GPU cluster queue</h5>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ClusterQueue\nmetadata:\n  name: \"a400queue\"\nspec:\n  namespaceSelector: {} # match all.\n  resourceGroups:\n  - coveredResources: [\"cpu\", \"memory\", \"nvidia.com/gpu\"]\n    flavors:\n    - name: \"a400node\"\n      resources:\n      - name: \"cpu\"\n        nominalQuota: 16\n      - name: \"memory\"\n        nominalQuota: 64Gi\n      - name: \"nvidia.com/gpu\"\n        nominalQuota: 2</code></pre>\n</div>\n</div>\n</div>\n<div class=\"sect4\">\n<h5 id=\"_nvidia_rtx_a1000_gpu_cluster_queue\">NVIDIA RTX A1000 GPU cluster queue</h5>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ClusterQueue\nmetadata:\n  name: \"a1000queue\"\nspec:\n  namespaceSelector: {} # match all.\n  resourceGroups:\n  - coveredResources: [\"cpu\", \"memory\", \"nvidia.com/gpu\"]\n    flavors:\n    - name: \"a1000node\"\n      resources:\n      - name: \"cpu\"\n        nominalQuota: 16\n      - name: \"memory\"\n        nominalQuota: 64Gi\n      - name: \"nvidia.com/gpu\"\n        nominalQuota: 2</code></pre>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_nvidia_gpus_and_amd_gpus_without_shared_cohort\">NVIDIA GPUs and AMD GPUs without shared cohort</h4>\n<div class=\"sect4\">\n<h5 id=\"_amd_gpu_resource_flavor\">AMD GPU resource flavor</h5>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ResourceFlavor\nmetadata:\n  name: \"amd-node\"\nspec:\n  nodeLabels:\n    instance-type: amd-node\n  tolerations:\n  - key: \"HasGPU\"\n    operator: \"Exists\"\n    effect: \"NoSchedule\"</code></pre>\n</div>\n</div>\n</div>\n<div class=\"sect4\">\n<h5 id=\"_nvidia_gpu_resource_flavor\">NVIDIA GPU resource flavor</h5>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ResourceFlavor\nmetadata:\n  name: \"nvidia-node\"\nspec:\n  nodeLabels:\n    instance-type: nvidia-node\n  tolerations:\n  - key: \"HasGPU\"\n    operator: \"Exists\"\n    effect: \"NoSchedule\"</code></pre>\n</div>\n</div>\n</div>\n<div class=\"sect4\">\n<h5 id=\"_amd_gpu_cluster_queue\">AMD GPU cluster queue</h5>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ClusterQueue\nmetadata:\n  name: \"team-a-amd-queue\"\nspec:\n  namespaceSelector: {} # match all.\n  resourceGroups:\n  - coveredResources: [\"cpu\", \"memory\", \"amd.com/gpu\"]\n    flavors:\n    - name: \"amd-node\"\n      resources:\n      - name: \"cpu\"\n        nominalQuota: 16\n      - name: \"memory\"\n        nominalQuota: 64Gi\n      - name: \"amd.com/gpu\"\n        nominalQuota: 2</code></pre>\n</div>\n</div>\n</div>\n<div class=\"sect4\">\n<h5 id=\"_nvidia_gpu_cluster_queue\">NVIDIA GPU cluster queue</h5>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">apiVersion: kueue.x-k8s.io/v1beta1\nkind: ClusterQueue\nmetadata:\n  name: \"team-a-nvidia-queue\"\nspec:\n  namespaceSelector: {} # match all.\n  resourceGroups:\n  - coveredResources: [\"cpu\", \"memory\", \"nvidia.com/gpu\"]\n    flavors:\n    - name: \"nvidia-node\"\n      resources:\n      - name: \"cpu\"\n        nominalQuota: 16\n      - name: \"memory\"\n        nominalQuota: 64Gi\n      - name: \"nvidia.com/gpu\"\n        nominalQuota: 2</code></pre>\n</div>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/ai_workloads/red-hat-build-of-kueue\">Red Hat build of Kueue documentation</a></p>\n</li>\n<li>\n<p><a href=\"https://kueue.sigs.k8s.io/docs/concepts/resource_flavor/\">Resource Flavor</a> in the Kueue documentation</p>\n</li>\n<li>\n<p><a href=\"https://kueue.sigs.k8s.io/docs/concepts/cluster_queue/\">Cluster Queue</a> in the Kueue documentation</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"configuring-a-cluster-for-rdma_managing-odh\">Configuring a cluster for RDMA</h3>\n<div class=\"paragraph _abstract\">\n<p>NVIDIA GPUDirect RDMA uses Remote Direct Memory Access (RDMA) to provide direct GPU interconnect.\nTo configure a cluster for RDMA, a cluster administrator must install and configure several Operators.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You can access an OpenShift cluster as a cluster administrator.</p>\n</li>\n<li>\n<p>Your cluster has multiple worker nodes with supported NVIDIA GPUs, and can access a compatible NVIDIA accelerated networking platform.</p>\n</li>\n<li>\n<p>You have installed Open Data Hub with the required distributed training components as described in <a href=\"https://opendatahub.io/docs/installing-open-data-hub/#installing-the-distributed-workloads-components_install\">Installing the distributed workloads components</a>.</p>\n</li>\n<li>\n<p>You have configured the distributed training resources as described in <a href=\"https://opendatahub.io/docs/managing-odh/#managing-distributed-workloads_managing-odh\">Managing distributed workloads</a>.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Console as a cluster administrator.</p>\n</li>\n<li>\n<p>Enable NVIDIA GPU support in Open Data Hub.</p>\n<div class=\"paragraph\">\n<p>This process includes installing the Node Feature Discovery Operator and the NVIDIA GPU Operator.\nFor more information, see <a href=\"https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/index.html\" target=\"_blank\" rel=\"noopener\">NVIDIA GPU Operator on Red&#160;Hat OpenShift Container Platform</a> in the NVIDIA documentation.</p>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>After the NVIDIA GPU Operator is installed, ensure that <code>rdma</code> is set to <code>enabled</code> in your <code>ClusterPolicy</code> custom resource instance.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>To simplify the management of NVIDIA networking resources, install and configure the NVIDIA Network Operator, as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Install the NVIDIA Network Operator, as described in <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/operators/administrator-tasks#olm-adding-operators-to-a-cluster\">Adding Operators to a cluster</a> in the OpenShift documentation.</p>\n</li>\n<li>\n<p>Configure the NVIDIA Network Operator, as described in the deployment examples in the <a href=\"https://docs.nvidia.com/networking/display/cokan10/network+operator\">Network Operator Application Notes</a> in the NVIDIA documentation.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>[Optional] To use Single Root I/O Virtualization (SR-IOV) deployment modes, complete the following steps:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Install the SR-IOV Network Operator, as described in the <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/networking_operators/sr-iov-operator#installing-sriov-operator\">Installing the SR-IOV Network Operator</a> section in the OpenShift documentation.</p>\n</li>\n<li>\n<p>Configure the SR-IOV Network Operator, as described in the <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/networking_operators/sr-iov-operator#configuring-sriov-operator\">Configuring the SR-IOV Network Operator</a> section in the OpenShift documentation.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Use the Machine Configuration Operator to increase the limit of pinned memory for non-root users in the container engine (CRI-O) configuration, as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift Console, in the <strong>Administrator</strong> perspective, click <strong>Compute &#8594; MachineConfigs</strong>.</p>\n</li>\n<li>\n<p>Click <strong>Create MachineConfig</strong>.</p>\n</li>\n<li>\n<p>Replace the placeholder text with the following content:</p>\n<div class=\"listingblock\">\n<div class=\"title\">Example machine configuration</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>apiVersion: machineconfiguration.openshift.io/v1\nkind: MachineConfig\nmetadata:\n  labels:\n    machineconfiguration.openshift.io/role: worker\n  name: 02-worker-container-runtime\nspec:\n  config:\n    ignition:\n      version: 3.2.0\n    storage:\n      files:\n        - contents:\n            inline: |\n              [crio.runtime]\n              default_ulimits = [\n                \"memlock=-1:-1\"\n              ]\n          mode: 420\n          overwrite: true\n          path: /etc/crio/crio.conf.d/10-custom</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Edit the <code>default_ulimits</code> entry to specify an appropriate value for your configuration.\nFor more information about default limits, see the <a href=\"https://access.redhat.com/solutions/6243491\">Set default ulimits on CRIO Using machine config</a> Knowledgebase solution.</p>\n</li>\n<li>\n<p>Click <strong>Create</strong>.</p>\n</li>\n<li>\n<p>Restart the worker nodes to apply the machine configuration.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<p>This configuration enables non-root users to run the training job with RDMA in the most restrictive OpenShift default security context.</p>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Verification</div>\n<ol class=\"arabic\">\n<li>\n<p>Verify that the Operators are installed correctly, as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift Console, in the <strong>Administrator</strong> perspective, click <strong>Workloads &#8594; Pods</strong>.</p>\n</li>\n<li>\n<p>Select your project from the <strong>Project</strong> list.</p>\n</li>\n<li>\n<p>Verify that a pod is running for each of the newly installed Operators.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Verify that RDMA is being used, as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Edit the <code>PyTorchJob</code> resource to set the <code>*NCCL_DEBUG*</code> environment variable to <code>INFO</code>, as shown in the following example:</p>\n<div class=\"listingblock\">\n<div class=\"title\">Setting the NCCL debug level to INFO</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>        spec:\n          containers:\n          - command:\n            - /bin/bash\n            - -c\n            - \"your container command\"\n            env:\n            - name: NCCL_SOCKET_IFNAME\n              value: \"net1\"\n            - name: NCCL_IB_HCA\n              value: \"mlx5_1\"\n            - name: NCCL_DEBUG\n              value: \"INFO\"</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Run the PyTorch job.</p>\n</li>\n<li>\n<p>Check that the pod logs include an entry similar to the following text:</p>\n<div class=\"listingblock\">\n<div class=\"title\">Example pod log entry</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code>NCCL INFO NET/IB : Using [0]mlx5_1:1/RoCE [RO]</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"troubleshooting-common-problems-with-distributed-workloads-for-administrators_managing-odh\">Troubleshooting common problems with distributed workloads for administrators</h3>\n<div class=\"paragraph _abstract\">\n<p>If your users are experiencing errors in Open Data Hub relating to distributed workloads, read this section to understand what could be causing the problem, and how to resolve the problem.</p>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_a_users_ray_cluster_is_in_a_suspended_state\">A user&#8217;s Ray cluster is in a suspended state</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>The resource quota specified in the cluster queue configuration might be insufficient, or the resource flavor might not yet be created.</p>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Diagnosis</div>\n<p>The user&#8217;s Ray cluster head pod or worker pods remain in a suspended state.\nCheck the status of the <code>Workload</code> resource that is created with the <code>RayCluster</code> resource.\nThe <code>status.conditions.message</code> field provides the reason for the suspended state, as shown in the following example:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">status:\n conditions:\n   - lastTransitionTime: '2024-05-29T13:05:09Z'\n     message: 'couldn''t assign flavors to pod set small-group-jobtest12: insufficient quota for nvidia.com/gpu in flavor default-flavor in ClusterQueue'</code></pre>\n</div>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Resolution</div>\n<ol class=\"arabic\">\n<li>\n<p>Check whether the resource flavor is created, as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift Container Platform console, select the user&#8217;s project from the <strong>Project</strong> list.</p>\n</li>\n<li>\n<p>Click <strong>Home &#8594; Search</strong>, and from the <strong>Resources</strong> list, select <strong>ResourceFlavor</strong>.</p>\n</li>\n<li>\n<p>If necessary, create the resource flavor.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Check the cluster queue configuration in the user&#8217;s code, to ensure that the resources that they requested are within the limits defined for the project.</p>\n</li>\n<li>\n<p>If necessary, increase the resource quota.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<p>For information about configuring resource flavors and quotas, see <a href=\"https://opendatahub.io/docs/managing-odh/#configuring-quota-management-for-distributed-workloads_managing-odh\">Configuring quota management for distributed workloads</a>.</p>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_a_users_ray_cluster_is_in_a_failed_state\">A user&#8217;s Ray cluster is in a failed state</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>The user might have insufficient resources.</p>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Diagnosis</div>\n<p>The user&#8217;s Ray cluster head pod or worker pods are not running.\nWhen a Ray cluster is created, it initially enters a <code>failed</code> state.\nThis failed state usually resolves after the reconciliation process completes and the Ray cluster pods are running.</p>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Resolution</div>\n<p>If the failed state persists, complete the following steps:</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform console, select the user&#8217;s project from the <strong>Project</strong> list.</p>\n</li>\n<li>\n<p>Click <strong>Workloads &#8594; Pods</strong>.</p>\n</li>\n<li>\n<p>Click the user&#8217;s pod name to open the pod details page.</p>\n</li>\n<li>\n<p>Click the <strong>Events</strong> tab, and review the pod events to identify the cause of the problem.</p>\n</li>\n<li>\n<p>Check the status of the <code>Workload</code> resource that is created with the <code>RayCluster</code> resource.\nThe <code>status.conditions.message</code> field provides the reason for the failed state.</p>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_a_users_ray_cluster_does_not_start\">A user&#8217;s Ray cluster does not start</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>After the user runs the <code>cluster.apply()</code> command, when they run either the <code>cluster.details()</code> command or the <code>cluster.status()</code> command, the Ray cluster status remains as <code>Starting</code> instead of changing to <code>Ready</code>.\nNo pods are created.</p>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Diagnosis</div>\n<p>Check the status of the <code>Workload</code> resource that is created with the <code>RayCluster</code> resource.\nThe <code>status.conditions.message</code> field provides the reason for remaining in the <code>Starting</code> state.\nSimilarly, check the <code>status.conditions.message</code> field for the <code>RayCluster</code> resource.</p>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Resolution</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform console, select the user&#8217;s project from the <strong>Project</strong> list.</p>\n</li>\n<li>\n<p>Click <strong>Workloads &#8594; Pods</strong>.</p>\n</li>\n<li>\n<p>Verify that the KubeRay pod is running.\nIf necessary, restart the KubeRay pod.</p>\n</li>\n<li>\n<p>Review the logs for the KubeRay pod to identify errors.</p>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_a_user_cannot_create_a_ray_cluster_or_submit_jobs\">A user cannot create a Ray cluster or submit jobs</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>After the user runs the <code>cluster.apply()</code> command, an error similar to the following text is shown:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">RuntimeError: Failed to get RayCluster CustomResourceDefinition: (403)\nReason: Forbidden\nHTTP response body: {\"kind\":\"Status\",\"apiVersion\":\"v1\",\"metadata\":{},\"status\":\"Failure\",\"message\":\"rayclusters.ray.io is forbidden: User \\\"system:serviceaccount:regularuser-project:regularuser-workbench\\\" cannot list resource \\\"rayclusters\\\" in API group \\\"ray.io\\\" in the namespace \\\"regularuser-project\\\"\",\"reason\":\"Forbidden\",\"details\":{\"group\":\"ray.io\",\"kind\":\"rayclusters\"},\"code\":403}</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Diagnosis</div>\n<p>The correct OpenShift login credentials are not specified in the <code>TokenAuthentication</code> section of the user&#8217;s notebook code.</p>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Resolution</div>\n<ol class=\"arabic\">\n<li>\n<p>Advise the user to identify and specify the correct OpenShift login credentials as follows:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift Container Platform console header, click your username and click <strong>Copy login command</strong>.</p>\n</li>\n<li>\n<p>In the new tab that opens, log in as the user whose credentials you want to use.</p>\n</li>\n<li>\n<p>Click <strong>Display Token</strong>.</p>\n</li>\n<li>\n<p>From the <strong>Log in with this token</strong> section, copy the <code>token</code> and <code>server</code> values.</p>\n</li>\n<li>\n<p>Specify the copied <code>token</code> and <code>server</code> values in your notebook code as follows:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">auth = TokenAuthentication(\n    token = \"<em>&lt;token&gt;</em>\",\n    server = \"<em>&lt;server&gt;</em>\",\n    skip_tls=False\n)\nauth.login()</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Verify that the user has the correct permissions and is part of the <code>odh-users</code> group.</p>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3 _additional-resources\">\n<h4 id=\"_additional_resources_2\">Additional resources</h4>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><a href=\"https://opendatahub.io/docs/working-with-distributed-workloads/#troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads\">Troubleshooting common problems with distributed workloads for users</a></p>\n</li>\n<li>\n<p><a href=\"https://opendatahub.io/docs/managing-odh/#troubleshooting-common-problems-with-Kueue_kueue\">Troubleshooting common problems with Kueue</a></p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"configuring-external-oidc-provider_managing-odh\">Configuring a central authentication service for an external OIDC identity provider</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>The built-in OpenShift OAuth server supports integration with various identity providers. However, it has limitations in direct OpenID Connect (OIDC) configurations on Red&#160;Hat OpenShift Service on AWS (ROSA) and on-premises OpenShift Container Platform (OCP) 4.20 and later clusters. The internal <code>oauth</code> service can be disabled or removed, which breaks dependencies like <code>oauth-proxy</code> sidecar containers.</p>\n</div>\n<div class=\"paragraph\">\n<p>You can configure an external OIDC identity provider directly with Open Data Hub by configuring a centralized Gateway API. The Gateway API configuration provides a secure, scalable, and manageable authentication solution because it centralizes the authentication logic and decouples it from individual backend services.</p>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>OpenID Connect (OIDC) configuration is currently available in Open Data Hub 3.0 as a Technology Preview feature. Technology Preview features are not supported with Red&#160;Hat production service level agreements (SLAs) and might not be functionally complete.\nRed&#160;Hat does not recommend using them in production.\nThese features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.</p>\n</div>\n<div class=\"paragraph\">\n<p>For more information about the support scope of Red&#160;Hat Technology Preview features, see <a href=\"https://access.redhat.com/support/offerings/techpreview/\">Technology Preview Features Support Scope</a>.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"sect2\">\n<h3 id=\"about-centralized-auth-oidc_managing-odh\">About centralized authentication Gateway API</h3>\n<div class=\"paragraph\">\n<p>A Gateway API with centralized authentication centralizes ingress traffic for all services behind a single domain, providing the following advanced capabilities:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Centralized authentication: A single authentication service requiring only one client ID and secret from the external OIDC Identity Provider (IDP).</p>\n</li>\n<li>\n<p>Simplified backend services: Backend services assume all incoming traffic is authenticated and contains necessary user headers.</p>\n</li>\n<li>\n<p>Authorization handling: Services still handle authorization at the service or pod level using sidecars like <code>kube-rbac-proxy</code>.</p>\n</li>\n<li>\n<p>Encrypted Communication: Traffic from the gateway to the backend services is fully encrypted with Transport Layer Security (TLS).</p>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>The Gateway API is implemented via an Istio Gateway on OpenShift Container Platform (OCP) 4.19 and later. Since the Istio Gateway is built on the Envoy Proxy, it provides access to powerful Envoy-specific Custom Resource Definitions (CRDs), such as <code>EnvoyFilter</code>. The <code>opendatahub-operator</code> manages the deployment of <code>kube-auth-proxy</code>. The Operator then configures the Istio Gateway to use this service via an <code>EnvoyFilter</code> Custom Resource (CR).</p>\n</div>\n<div class=\"paragraph\">\n<p>For more information on supported OpenID Connect (OIDC) identity providers, see OpenShift Container Platform documentation on <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/authentication_and_authorization/external-auth#external-auth-providers_external-auth\">Direct authentication identity providers</a></p>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"configuring-oidc-auth-gateway-api_managing-odh\">Configuring OpenID Connect (OIDC) authentication for Gateway API</h3>\n<div class=\"paragraph _abstract\">\n<p>As a Open Data Hub administrator, you can configure an OpenID Connect (OIDC) authentication for Gateway API using parameters from your external OIDC identity provider.</p>\n</div>\n<div class=\"admonitionblock important\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Important</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>You must configure the OpenShift Container Platform for direct authentication with an external OIDC identity provider before configuring the Open Data Hub Gateway for the Gateway to function properly.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have configured the OpenShift Container Platform for direct authentication with an external OIDC identity provider.</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>To configure OpenShift for direct authentication, follow the appropriate OpenShift Container Platform documentation: <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/authentication_and_authorization/external-auth\">Enabling direct authentication with an external OIDC identity provider</a>.</p>\n</li>\n<li>\n<p>To configure OpenShift for direct authentication using ROSA, follow the appropriate Red&#160;Hat OpenShift Service on AWS documentation: <a href=\"https://docs.redhat.com/en/documentation/red_hat_openshift_service_on_aws/4/html/install_clusters/rosa-hcp-cluster-no-cni#rosa-sts-byo-oidc_rosa-hcp-cluster-no-cni\">Creating an OpenID Connect configuration</a>.</p>\n</li>\n</ul>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\nYou must configure OpenShift for direct authentication using the same OIDC provider that the Gateway uses.\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>You have successfully installed and deployed Open Data Hub.</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>You have deployed the DataScienceCluster (DSC) and DSCInitialization. For more information, see <a href=\"https://opendatahub.io/docs/installing-open-data-hub/#installing-the-odh-operator-v2_installv2\">Installing Open Data Hub</a>.</p>\n</li>\n<li>\n<p>You have deployed the Open Data Hub Operator in the <code>rhods-operator</code> namespace.</p>\n</li>\n<li>\n<p>You have enabled Gateway API support on OCP 4.19 or later with Istio Gateway.</p>\n</li>\n<li>\n<p>You have the following external authentication provider details:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Issuer URL</p>\n</li>\n<li>\n<p>Client ID</p>\n</li>\n<li>\n<p>Client Secret</p>\n</li>\n<li>\n<p>Realm name (for Keycloak)</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>You have cluster administrator access which is required to create secrets and configure <code>GatewayConfig</code>.</p>\n</li>\n</ul>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"paragraph\">\n<p>For detailed step-by-step instructions, troubleshooting, and field definitions, refer to the OpenShift Container Platform documentation on <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/authentication_and_authorization/external-auth#external-auth-configuring_external-auth\">Configuring an external OIDC identity provider</a>.</p>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift CLI (<code>oc</code>), verify the OpenShift authentication type by running the following command:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get authentication.config/cluster -o jsonpath='{.spec.type}'</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>If the authentication is successful, you will see the following output: <code>OIDC</code></p>\n</div>\n</li>\n<li>\n<p>Verify that your OIDC provider is configured as expected by running the following command:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get authentication.config/cluster -o jsonpath='{.spec.oidcProviders[*].name}'</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>If the OIDC configuration is successful, you will see your provider name (e.g., <code>keycloak</code>).</p>\n</div>\n</li>\n<li>\n<p>Verify that the <code>kube-apiserver</code> has rolled out changes as expected.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get co kube-apiserver</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>If success is indicated, the expected output should look like the following example:</p>\n</div>\n<div class=\"listingblock output\">\n<div class=\"content\">\n<pre>NAME              VERSION   AVAILABLE   PROGRESSING   DEGRADED   SINCE\nkube-apiserver    4.14.9    True        False         False      1d</pre>\n</div>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\nThe rollout can take 20 minutes or more. Wait until all nodes have the new revision before proceeding. You can proceed to Gateway configuration steps when <code>oc get authentication.config/cluster</code> shows <code>type: OIDC</code>, <code>oc get co kube-apiserver</code> shows the authentication rollout is complete, and you can successfully authenticate to OpenShift using OIDC credentials.\n</td>\n</tr>\n</table>\n</div>\n</li>\n<li>\n<p>Define the the following environment variables. You must replace the placeholder values with the actual details from your OIDC Identity Provider (IdP):</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\"># Replace with your actual values\nKEYCLOAK_DOMAIN=\"&lt;keycloak.example.com&gt;\"\nKEYCLOAK_REALM=\"&lt;your-realm&gt;\"\nKEYCLOAK_CLIENT_ID=\"&lt;your-client-id&gt;\"\nKEYCLOAK_CLIENT_SECRET=\"&lt;your-client-secret&gt;\"</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Create the client secret in the <code>openshift-ingress</code> namespace:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc create secret generic keycloak-client-secret \\\n    --from-literal=clientSecret=$KEYCLOAK_CLIENT_SECRET \\\n    -n openshift-ingress</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Update the <code>GatewayConfig</code> custom resource to enable OIDC authentication by patching it with the secret reference and OIDC details:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc patch gatewayconfig default-gateway --type='merge' -p='{\n    \"spec\": {\n      \"oidc\": {\n        \"issuerURL\": \"https://'$KEYCLOAK_DOMAIN'/realms/'$KEYCLOAK_REALM'\",\n        \"clientID\": \"'$KEYCLOAK_CLIENT_ID'\",\n        \"clientSecretRef\": {\n          \"name\": \"keycloak-client-secret\",\n          \"key\": \"clientSecret\"\n        }\n      }\n    }\n  }'</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Verify that the client secret has been created and that the <code>GatewayConfig</code> shows the correct OIDC configuration:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get secret keycloak-client-secret -n openshift-ingress\n$ oc get gatewayconfig default-gateway -o jsonpath='{.spec.oidc}'</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>Expected output for secret and <code>GatewayConfig</code> should look like the following example:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\"># Expected output (for secret)\nNAME                     TYPE     DATA   AGE\nkeycloak-client-secret   Opaque   1      2m\n# Expected output (for GatewayConfig)\n{\"clientID\":\"your-client-id\",\"clientSecretRef\":{\"key\":\"clientSecret\",\"name\":\"keycloak-client-secret\"},\"issuerURL\":\"https://keycloak.example.com/realms/your-realm\"}</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Verification</div>\n<ol class=\"arabic\">\n<li>\n<p>After configuring and authenticating the Gateway for your identity provider, you need to ensure that you can access your OpenShift console.</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>Access the gateway by accessing the Console link:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get consolelink</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Login with your OIDC credentials and verify the following:</p>\n<div class=\"olist lowerroman\">\n<ol class=\"lowerroman\" type=\"i\">\n<li>\n<p>You are redirected to the OIDC provider login page. A successful authentication redirects back to the Gateway.</p>\n</li>\n<li>\n<p>Your Open Data Hub components are accessible (for example: Dashboard, Notebooks).</p>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Check the <code>GatewayConfig</code> status to verify that the OIDC configuration was successfully provisioned:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get gatewayconfig default-gateway -o yaml</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output is the full YAML configuration of the <code>GatewayConfig</code> resource, showing the OIDC configuration details under <code>spec.oidc</code> and confirming successful deployment by displaying both the <code>Ready</code> and <code>ProvisioningSucceeded</code> conditions with a <code>status: \"True\"</code> value.</p>\n</div>\n</li>\n<li>\n<p>Verify the <code>kube-auth-proxy</code> deployment is running successfully in the <code>openshift-ingress</code> namespace:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get deployment kube-auth-proxy -n openshift-ingress</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output looks like the following example:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">NAME              READY   UP-TO-DATE   AVAILABLE   AGE\nkube-auth-proxy   1/1     1            1           5m</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Check the status and accessibility of the <code>data-science-gateway</code>:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get gateway data-science-gateway -n openshift-ingress</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output looks like the following example:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">NAME                   CLASS                        ADDRESS                                                                        PROGRAMMED   AGE\ndata-science-gateway   data-science-gateway-class   aa87f5da7f0c748d5aa63b4916604108-107643684.us-east-1.elb.amazonaws.com         True         5m</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Test the OIDC discovery endpoint by running the following command:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">curl -s https://your-keycloak-domain/realms/your-realm/.well-known/openid-configuration</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output is a JSON object containing the OIDC configuration endpoints (<code>issuer</code>, <code>authorization_endpoint</code>, <code>token_endpoint</code>, etc.) that confirm the OIDC provider is publicly discoverable.</p>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Next steps</div>\n<p>Once the external OIDC is configured and authenticated, the Cluster Administrator must perform the necessary authorization by mapping external Identity Provider (IdP) groups to specific OpenShift <code>ClusterRoles</code> to grant access to projects and resources.</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>Create a <code>ClusterRole</code> that grants users read and list access to OpenShift projects in the console:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-yaml\" data-lang=\"yaml\">apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: odh-projects-read\nrules:\n- apiGroups: [\"project.openshift.io\"]\n  resources: [\"projects\"]\n  verbs: [\"get\",\"list\"]</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Bind the <code>odh-projects-read</code> ClusterRole to your IdP group (for example, <code>odh-users</code>).</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc adm policy add-cluster-role-to-group odh-projects-read odh-users</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Grant the ability to create and manage new projects by assigning the built-in self-provisioner ClusterRole to your group.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc adm policy add-cluster-role-to-group self-provisioner odh-users</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_security_considerations\">Security considerations</h4>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Secret Management: Store OIDC client secrets securely and rotate them regularly.</p>\n</li>\n<li>\n<p>Network Policies: Consider implementing network policies to restrict access to the authentication proxy.</p>\n</li>\n<li>\n<p>TLS Configuration: Ensure all OIDC communication uses Transport Layer Security (TLS).</p>\n</li>\n<li>\n<p>Token Validation: While <code>kube-auth-proxy</code> validates tokens, ensure your OIDC provider is configured with appropriate token lifetimes.</p>\n</li>\n<li>\n<p>Audit Logging: Enable audit logging for authentication events.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"troubleshooting-common-problems-gateway-api_managing-odh\">Troubleshooting common problems with Gateway API configuration</h3>\n<div class=\"paragraph _abstract\">\n<p>If your users are experiencing errors in Open Data Hub relating to Gateway API configuration, read this section to understand what could be causing the problem, and how to resolve the problem.</p>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_the_gatewayconfig_status_shows_as_not_ready\">The <code>GatewayConfig</code> status shows as not ready</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>While setting up the OIDC, the <code>GatewayConfig</code> status shows as not ready. You see error messages about missing OIDC configuration and the <code>GatewayConfig</code> resource shows its status as <code>Ready: False</code>.</p>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Diagnosis</div>\n<ol class=\"arabic\">\n<li>\n<p>Check <code>GatewayConfig</code> status by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get gatewayconfig default-gateway -o yaml</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Check for specific error messages by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc describe gatewayconfig default-gateway</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output confirms that the GatewayConfig resource is successfully provisioned by showing the OIDC configuration details under <code>Spec.Oidc</code> and displaying both the <code>Ready</code> and <code>ProvisioningSucceeded</code> status conditions with a <code>True</code> status.</p>\n</div>\n</li>\n<li>\n<p>Verify that the OIDC configuration is correct by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get gatewayconfig default-gateway -o jsonpath='{.spec.oidc}'</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>Expected output shows the following example:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">{\"clientID\":\"your-client-id\",\"clientSecretRef\":{\"key\":\"clientSecret\",\"name\":\"keycloak-client-secret\"},\"issuerURL\":\"https://keycloak.example.com/realms/your-realm\"}</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Resolution</div>\n<ol class=\"arabic\">\n<li>\n<p>Verify the OIDC secret exists and is correct by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get secret keycloak-client-secret -n openshift-ingress</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Check OIDC issuer URL accessibility by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">curl -I https://your-keycloak-domain/realms/your-realm/.well-known/openid-configuration</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output confirms the OIDC issuer URL is accessible by returning the HTTP status code <code>HTTP/2 200</code> and the correct <code>content-type: application/json header</code>.</p>\n</div>\n</li>\n<li>\n<p>Ensure that the client Secret is correct.</p>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_authentication_proxy_fails_to_start\">Authentication proxy fails to start</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>The authentication proxy component fails to start after deploying <code>kube-auth-proxy</code>. The associated Pods are in a failing state, showing statuses such as <code>CrashLoopBackOff</code> or <code>Pending</code>, and the <code>kube-auth-proxy</code> Deployment is not ready.</p>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Diagnosis</div>\n<ol class=\"arabic\">\n<li>\n<p>Check the <code>kube-auth-proxy</code> deployment status by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get deployment kube-auth-proxy -n openshift-ingress</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output confirms that the deployment is successfully provisioned, showing <code>1/1</code> under the <code>READY</code> column.</p>\n</div>\n</li>\n<li>\n<p>Check the Pod logs by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc logs -l app=kube-auth-proxy -n openshift-ingress</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output confirms that the OAuth2 Proxy is configured and starting on the specified ports.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\"># Expected output\ntime=\"2024-01-15T10:30:00Z\" level=info msg=\"OAuth2 Proxy configured\"\ntime=\"2024-01-15T10:30:00Z\" level=info msg=\"OAuth2 Proxy starting on :4180\"\ntime=\"2024-01-15T10:30:00Z\" level=info msg=\"OAuth2 Proxy starting on :8443\"</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Check the Pod events for errors by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc describe pod -l app=kube-auth-proxy -n openshift-ingress</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output should look like the following example.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\"># Expected output\nName:          kube-auth-proxy-7d4f8b9c6-xyz12\nNamespace:     openshift-ingress\nStatus:        Running\nContainers:\n  kube-auth-proxy:\n    State:          Running\n    Ready:          True\n    Restart Count:  0\nEvents:\n  Type    Reason       Age   From                 Message\n  ----    ------       ----  ----                 -------\n  Normal  Scheduled    5m    default-scheduler    Successfully assigned openshift-ingress/kube-auth-proxy-7d4f8b9c6-xyz12 to worker-node-1</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Resolution</div>\n<ol class=\"arabic\">\n<li>\n<p>Verify that the authentication secret contains the correct client secret by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get secret kube-auth-proxy-creds -n openshift-ingress -o yaml</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output should contain the keys <code>OAUTH2_PROXY_CLIENT_SECRET</code>, <code>OAUTH2_PROXY_COOKIE_SECRET</code>, and <code>OAUTH2_PROXY_CLIENT_ID</code>.</p>\n</div>\n</li>\n<li>\n<p>Check if the OIDC issuer URL is accessible from the cluster by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">curl -I https://your-keycloak-domain/realms/your-realm/.well-known/openid-configuration</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output should return the HTTP status code <code>HTTP/2 200</code>.</p>\n</div>\n</li>\n<li>\n<p>Ensure that the client ID exists in your OIDC provider.</p>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_the_gateway_is_inaccessible\">The Gateway is inaccessible</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>After configuring OIDC, you cannot access the Gateway URL: <a href=\"https://data-science-gateway.$CLUSTER_DOMAIN\" class=\"bare\">https://data-science-gateway.$CLUSTER_DOMAIN</a>. Attempts to access the URL return 502 (Bad Gateway) or 503 (Service Unavailable) errors, indicating a networking failure that prevents external access or traffic routing to the service endpoint.</p>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Diagnosis</div>\n<ol class=\"arabic\">\n<li>\n<p>Check the Gateway status of <code>data-science-gateway</code> by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get gateway data-science-gateway -n openshift-ingress</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output shows <code>PROGRAMMED</code> column as <code>True</code>, and a valid address is listed under the <code>ADDRESS</code> column.</p>\n</div>\n</li>\n<li>\n<p>Check the <code>HTTPRoute</code> status by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get httproute -n openshift-ingress</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output shows that the <code>oauth-callback-route</code> is present.</p>\n</div>\n</li>\n<li>\n<p>Check the <code>EnvoyFilter</code> by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get envoyfilter -n openshift-ingress</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output shows that the <code>authn-filter</code> is present.</p>\n</div>\n</li>\n<li>\n<p>Check the <code>kube-auth-proxy</code> Service by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get service kube-auth-proxy -n openshift-ingress</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output shows that the Service and correct ports are present, like the following example:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\"># Expected output\nNAME              TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)           AGE\nkube-auth-proxy   ClusterIP   172.30.31.69   &lt;none&gt;        8443/TCP,9000/TCP   41h</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Resolution</div>\n<ol class=\"arabic\">\n<li>\n<p>Verify the Gateway has a valid address by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get gateway data-science-gateway -n openshift-ingress -o jsonpath='{.status.addresses}'</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output shows a valid IP address or hostname.</p>\n</div>\n</li>\n<li>\n<p>Check if the <code>HTTPRoute</code> is properly configured by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc describe httproute oauth-callback-route -n openshift-ingress</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output confirms proper parent references and backend services.</p>\n</div>\n</li>\n<li>\n<p>Ensure the <code>EnvoyFilter</code> is applied correctly by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc describe envoyfilter authn-filter -n openshift-ingress</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected outputconfirms the proper configuration for <code>kube-auth-proxy</code>.</p>\n</div>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_the_oidc_authentication_fails\">The OIDC authentication fails</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>The OIDC authentication fails and you are unable to log in through the Gateway. You also experience symptoms such as redirect loops or explicit authentication errors after attempting to log in.</p>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Diagnosis</div>\n<ol class=\"arabic\">\n<li>\n<p>Check the <code>kube-auth-proxy</code> logs for specific error messages by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc logs -l app=kube-auth-proxy -n openshift-ingress</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output confirms that the OAuth2 Proxy is configured and starting on the specified ports.</p>\n</div>\n</li>\n<li>\n<p>Verify the OIDC configuration in the <code>kube-auth-proxy</code> Secret by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get secret kube-auth-proxy-creds -n openshift-ingress -o yaml</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output shows that the Secret contains the keys <code>OAUTH2_PROXY_CLIENT_ID</code>, <code>OAUTH2_PROXY_CLIENT_SECRET</code>, and <code>OAUTH2_PROXY_COOKIE_SECRET</code>. The output should look like the following example.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\"># Expected output\napiVersion: v1\nkind: Secret\nmetadata:\n  name: kube-auth-proxy-creds\n  namespace: openshift-ingress\ntype: Opaque\ndata:\n  OAUTH2_PROXY_CLIENT_ID: b2RoLWNsaWVudA==  # base64 encoded \"data-science\"\n  OAUTH2_PROXY_CLIENT_SECRET: &lt;base64-encoded-secret&gt;\n  OAUTH2_PROXY_COOKIE_SECRET: &lt;base64-encoded-cookie-secret&gt;</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Test the OIDC discovery endpoint by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">curl -s https://your-keycloak-domain/realms/your-realm/.well-known/openid-configuration | jq .</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output returns the complete JSON configuration, including valid endpoints for <code>issuer</code>, <code>authorization_endpoint</code>, and <code>token_endpoint</code>.</p>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Resolution</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OIDC provider (for example, Keycloak) and verify that the redirect URI registered for the client matches the expected endpoint on the Gateway: <code>https://data-science-gateway.$CLUSTER_DOMAIN/oauth2/callback</code>. Mismatches are a frequent cause of redirect loops.</p>\n</li>\n<li>\n<p>Check if the client secret is properly set by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">echo $KEYCLOAK_CLIENT_SECRET | base64 -d</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output matches the secret in your OIDC provider.</p>\n</div>\n</li>\n<li>\n<p>Ensure that the issuer URL is accessible and correct by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">curl -I https://your-keycloak-domain/realms/your-realm/.well-known/openid-configuration</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output returns <code>HTTP/2 200</code>.</p>\n</div>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_the_dashboard_is_not_accessible_after_authentication\">The dashboard is not accessible after authentication</h4>\n<div class=\"paragraph\">\n<div class=\"title\">Problem</div>\n<p>After successfully authenticating with OIDC, you experience an authorization failure that prevents access to the dashboard. The failure results in 403 Forbidden errors while accessing the dashboard.</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>Check the <code>odh-dashboard</code> Deployment status by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get deployment -n opendatahub odh-dashboard</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected outcome confirms that the Pods are running, similar to the following example.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">NAME            READY   UP-TO-DATE   AVAILABLE   AGE\nodh-dashboard   2/2     2            2           7d5h</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Check the dashboard logs for any authorization errors by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc logs -l app=odh-dashboard -n opendatahub</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>In the expected output, the logs confirm the Dashboard is running and ready to serve requests.</p>\n</div>\n</li>\n<li>\n<p>Verify the user permissions by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc auth can-i get projects --as=your-username</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output confirms that the user has the required access.</p>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Resolution</div>\n<ol class=\"arabic\">\n<li>\n<p>Ensure that you have cluster-level RBAC permissions by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc adm policy add-cluster-role-to-user view your-username</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output confirms that the view cluster role has been added to the user.</p>\n</div>\n</li>\n<li>\n<p>Verify that the <code>odh-dashboard</code> HTTPRoute is properly configured with correct parent references (linking it to the Gateway) by running the following command.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get httproute odh-dashboard -n opendatahub -o yaml</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output shows proper parent references to the Gateway.</p>\n</div>\n</li>\n<li>\n<p>Check if the user is in the expected groups that may have roles bound to them required by the dashboard.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-bash\" data-lang=\"bash\">$ oc get user your-username -o yaml</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The expected output confirms that the user is in the <code>odh-users</code> group.</p>\n</div>\n</li>\n</ol>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"backing-up-data_data-mgmt\">Backing up data</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph\">\n<p>Backing up Open Data Hub involves various components, including the OpenShift Container Platform cluster and storage data.</p>\n</div>\n<div class=\"sect2\">\n<h3 id=\"backing-up-storage-data_data-mgmt\">Backing up storage data</h3>\n<div class=\"paragraph _abstract\">\n<p>It is a best practice to back up the data on your persistent volume claims (PVCs) regularly.</p>\n</div>\n<div class=\"paragraph\">\n<p>Backing up your data is particularly important before you delete a user and before you uninstall Open Data Hub, as all PVCs are deleted when Open Data Hub is uninstalled.</p>\n</div>\n<div class=\"paragraph\">\n<p>For more information about backing up PVCs for your cluster platform, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/backup_and_restore/oadp-application-backup-and-restore.html\">OADP Application backup and restore</a> in the OpenShift Container Platform documentation.</p>\n</div>\n<div class=\"ulist _additional-resources\">\n<div class=\"title\">Additional resources</div>\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/storage/understanding-persistent-storage\">Understanding persistent storage</a></p>\n</li>\n</ul>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"backing-up-your-cluster_data-mgmt\">Backing up your cluster</h3>\n<div class=\"paragraph _abstract\">\n<p>If you plan to upgrade or uninstall Open Data Hub on your cluster, back up your cluster data so that you can restore it later if needed.</p>\n</div>\n<div class=\"paragraph\">\n<p>For more information, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html-single/backup_and_restore/index\">Backup and restore</a> in the OpenShift Container Platform documentation.</p>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"managing-observability_managing-odh\">Managing observability</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>Open Data Hub provides centralized platform observability: an integrated, out-of-the-box solution for monitoring the health and performance of your Open Data Hub instance and user workloads.</p>\n</div>\n<div class=\"paragraph\">\n<p>This centralized solution includes a dedicated, pre-configured observability stack, featuring the OpenTelemetry Collector (OTC) for standardized data ingestion, Prometheus for metrics, and the Red&#160;Hat build of Tempo for distributed tracing. This architecture enables a common set of health metrics and alerts for Open Data Hub components and offers mechanisms to integrate with your existing external observability tools.</p>\n</div>\n<div class=\"sect2\">\n<h3 id=\"enabling-the-observability-stack_managing-odh\">Enabling the observability stack</h3>\n<div class=\"paragraph _abstract\">\n<p>The observability stack collects and correlates metrics, traces, and alerts for Open Data Hub so that you can monitor, troubleshoot, and optimize Open Data Hub components. A cluster administrator must explicitly enable this capability in the <code>DataScienceClusterInitialization</code> (DSCI) custom resource.</p>\n</div>\n<div class=\"paragraph\">\n<p>Once enabled, you can perform the following actions:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Accelerate troubleshooting by viewing metrics, traces, and alerts for Open Data Hub components in one place.</p>\n</li>\n<li>\n<p>Maintain platform stability by monitoring health and resource usage and receiving alerts for critical issues.</p>\n</li>\n<li>\n<p>Integrate with existing tools by exporting telemetry to third-party observability solutions through the Red Hat build of OpenTelemetry.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have cluster administrator privileges for your OpenShift Container Platform cluster.</p>\n</li>\n<li>\n<p>You have installed Open Data Hub.</p>\n</li>\n<li>\n<p>You have installed the following Operators, which provide the components of the observability stack:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><strong>Cluster Observability Operator</strong>: Deploys and manages Prometheus and Alertmanager for metrics and alerts.</p>\n</li>\n<li>\n<p><strong>Tempo Operator</strong>: Provides the Tempo backend for distributed tracing.</p>\n</li>\n<li>\n<p><strong>Red Hat build of OpenTelemetry</strong>: Deploys the OpenTelemetry Collector for collecting and exporting telemetry data.</p>\n</li>\n</ul>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform web console as a cluster administrator.</p>\n</li>\n<li>\n<p>In the OpenShift Container Platform console, click <strong>Operators</strong>  <strong>Installed Operators</strong>.</p>\n</li>\n<li>\n<p>Search for the <strong>Open Data Hub</strong> Operator, and then click the Operator name to open the Operator details page.</p>\n</li>\n<li>\n<p>Click the <strong>DSCInitialization</strong> tab.</p>\n</li>\n<li>\n<p>Click the default instance name (for example, <strong>default-dsci</strong>) to open the instance details page.</p>\n</li>\n<li>\n<p>Click the <strong>YAML</strong> tab to show the instance specifications.</p>\n</li>\n<li>\n<p>In the <code>spec.monitoring</code> section, set the value of the <code>managementState</code> field to <code>Managed</code>, and configure metrics, alerting, and tracing settings as shown in the following example:</p>\n<div class=\"listingblock\">\n<div class=\"title\">Example monitoring configuration</div>\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-yaml\" data-lang=\"yaml\"># ...\nspec:\n  monitoring:\n    managementState: Managed                 # Required: Enables and manages the observability stack\n    namespace: opendatahub    # Required: Namespace where monitoring components are deployed\n    alerting: {}                              # Alertmanager configuration, uses default settings if empty\n    metrics:                                  # Prometheus configuration for metrics collection\n      replicas: 1                             # Optional: Number of Prometheus instances\n      resources:                              # CPU and memory requests and limits for Prometheus pods\n        cpulimit: 500m                        # Optional: Maximum CPU allocation in millicores\n        cpurequest: 100m                      # Optional: Minimum CPU allocation in millicores\n        memorylimit: 512Mi                    # Optional: Maximum memory allocation in mebibytes\n        memoryrequest: 256Mi                  # Optional: Minimum memory allocation in mebibytes\n      storage:                                # Storage configuration for metrics data\n        size: 5Gi                             # Required: Storage size for Prometheus data\n        retention: 90d                        # Required: Retention period for metrics data in days\n      exporters: {}                           # External metrics exporters\n    traces:                                   # Tempo backend for distributed tracing\n      sampleRatio: '0.1'                      # Optional: Portion of traces to sample, expressed as a decimal\n      storage:                                # Storage configuration for trace data\n        backend: pv                           # Required: Storage backend for Tempo traces (pv, s3, or gcs)\n        retention: 2160h                      # Optional: Retention period for trace data in hours\n      exporters: {}                           # External traces exporters\n# ...</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Click <strong>Save</strong> to apply your changes.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>Verify that the observability stack components are running in the configured namespace:</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>In the OpenShift Container Platform web console, click <strong>Workloads</strong>  <strong>Pods</strong>.</p>\n</li>\n<li>\n<p>From the project list, select <strong>opendatahub</strong>.</p>\n</li>\n<li>\n<p>Confirm that there are running pods for your configuration. The following pods indicate that the observability stack is active:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">alertmanager-data-science-monitoringstack-#      2/2   Running   0   1m\ndata-science-collector-collector-#               1/1   Running   0   1m\nprometheus-data-science-monitoringstack-#        2/2   Running   0   1m\ntempo-data-science-tempomonolithic-#             1/1   Running   0   1m\nthanos-querier-data-science-thanos-querier-#     2/2   Running   0   1m</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"collecting-metrics-from-user-workloads_managing-odh\">Collecting metrics from user workloads</h3>\n<div class=\"paragraph _abstract\">\n<p>After a cluster administrator enables the observability stack in your cluster, metric collection becomes available but is not automatically active for all deployed workloads.\nThe monitoring system relies on a specific label to identify which pods Prometheus should scrape for metrics.</p>\n</div>\n<div class=\"paragraph\">\n<p>To include a workload, such as a user-created workbench, training job, or inference service, in the centralized observability stack, add the label <code>monitoring.opendatahub.io/scrape=true</code> to the pod template in the workload&#8217;s deployment configuration.\nThis ensures that all pods created by the deployment include the label and are automatically scraped by Prometheus.</p>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>Apply the <code>monitoring.opendatahub.io/scrape=true</code> label only to workloads that expose metrics and that you want the observability stack to monitor.\nDo not add this label to operator-managed workloads, because the operator might overwrite or remove it during reconciliation.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>A cluster administrator has enabled the observability stack as described in <em>Enabling the observability stack</em>.</p>\n</li>\n<li>\n<p>You have Open Data Hub administrator privileges or you are the project owner.</p>\n</li>\n<li>\n<p>You have deployed a workload that exposes a <code>/metrics</code> endpoint, such as a workbench server or model service pod.</p>\n</li>\n<li>\n<p>You have access to the project where the workload is running.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform web console as a cluster administrator or project owner.</p>\n</li>\n<li>\n<p>Click <strong>Workloads</strong>  <strong>Deployments</strong>.</p>\n</li>\n<li>\n<p>In the <strong>Project</strong> list at the top of the page, select the project where your workload is deployed.</p>\n</li>\n<li>\n<p>Identify the deployment that you want to collect metrics from and click its name.</p>\n</li>\n<li>\n<p>On the <strong>Deployment details</strong> page, click the <strong>YAML</strong> tab.</p>\n</li>\n<li>\n<p>In the YAML editor, add the required label under the <code>spec.template.metadata.labels</code> section, as shown in the following example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-yaml\" data-lang=\"yaml\">apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: &lt;example_name&gt;\n  namespace: &lt;example_namespace&gt;\nspec:\n  template:\n    metadata:\n      labels:\n        monitoring.opendatahub.io/scrape: 'true'\n# ...</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Click <strong>Save</strong>.</p>\n<div class=\"paragraph\">\n<p>OpenShift automatically rolls out a new ReplicaSet and pods with the updated label.\nWhen the new pods start, the observability stack begins scraping their metrics.</p>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<div class=\"title\">Verification</div>\n<p>Verify that metrics are being collected by accessing the Prometheus instance deployed by Open Data Hub.</p>\n</div>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>Access Prometheus by using a route:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift Container Platform web console, click <strong>Networking</strong>  <strong>Routes</strong>.</p>\n</li>\n<li>\n<p>From the project list, select <strong>opendatahub</strong>.</p>\n</li>\n<li>\n<p>Locate the route associated with the Prometheus service, such as <code>data-science-prometheus-route</code>.</p>\n</li>\n<li>\n<p>Click the <strong>Location</strong> URL to open the Prometheus web console.</p>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Alternatively, access Prometheus locally by using port forwarding:</p>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>List the Prometheus pods:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc get pods -n opendatahub -l prometheus=data-science-monitoringstack</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Start port forwarding:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc port-forward __&lt;prometheus-pod-name&gt;__ 9090:9090 -n opendatahub</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>In a web browser, open the following URL:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">http://localhost:9090</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>In the Prometheus web console, search for a metric exposed by your workload.</p>\n<div class=\"paragraph\">\n<p>If the label is applied correctly and the workload exposes metrics, the metrics appear in the Prometheus instance deployed by Open Data Hub.</p>\n</div>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"exporting-metrics-to-external-observability-tools_managing-odh\">Exporting metrics to external observability tools</h3>\n<div class=\"paragraph _abstract\">\n<p>You can export Open Data Hub operational metrics to an external observability platform, such as Grafana, Prometheus, or any OpenTelemetry-compatible backend.\nThis allows you to visualize and monitor Open Data Hub metrics alongside data from other systems in your existing observability environment.</p>\n</div>\n<div class=\"paragraph\">\n<p>Metrics export is configured in the <code>DataScienceClusterInitialization</code> (DSCI) custom resource by populating the <code>.spec.monitoring.metrics.exporters</code> field.\nWhen you define one or more exporters in this field, the OpenTelemetry Collector (OTC) deployed by Open Data Hub automatically updates its configuration to include each exporter in its metrics pipeline. If this field is empty or undefined, metrics are collected only by the in-cluster Prometheus instance that is deployed with Open Data Hub.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have cluster administrator privileges for your OpenShift Container Platform cluster.</p>\n</li>\n<li>\n<p>The observability stack is enabled as described in <em>Enabling the observability stack</em>.</p>\n</li>\n<li>\n<p>The external observability platform can receive metrics through a supported export protocol.</p>\n</li>\n<li>\n<p>You know the URL of your external metrics receiver endpoint.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform web console as a cluster administrator.</p>\n</li>\n<li>\n<p>Click <strong>Operators</strong>  <strong>Installed Operators</strong>.</p>\n</li>\n<li>\n<p>Select the <strong>Open Data Hub</strong> Operator from the list.</p>\n</li>\n<li>\n<p>Click the <strong>DSCInitialization</strong> tab.</p>\n</li>\n<li>\n<p>Click the default DSCI instance, for example, <strong>default-dsci</strong>, to open its details page.</p>\n</li>\n<li>\n<p>Click the <strong>YAML</strong> tab.</p>\n</li>\n<li>\n<p>In the <code>spec.monitoring.metrics</code> section, add an <code>exporters</code> list that defines the external receiver configuration, as shown in the following example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-yaml\" data-lang=\"yaml\">spec:\n  monitoring:\n    metrics:\n      exporters:\n        - name: &lt;external_exporter_name&gt;\n          type: &lt;type&gt;\n          endpoint: https://example-otlp-receiver.example.com:4317</code></pre>\n</div>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><code>name</code>: A unique, descriptive name for the exporter configuration. Do not use reserved names such as <code>prometheus</code> or <code>otlp/tempo</code>.</p>\n</li>\n<li>\n<p><code>type</code>: The protocol used for export, for example:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><code>otlp</code>: For OpenTelemetry-compatible backends using gRPC or HTTP.</p>\n</li>\n<li>\n<p><code>prometheusremotewrite</code>: For Prometheus-compatible systems that use the remote write protocol.</p>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p><code>endpoint</code>: The full URL of your external metrics receiver. For OTLP, endpoints typically use port <code>4317</code> (gRPC) or <code>4318</code> (HTTP). For Prometheus remote write, endpoints typically end with <code>/api/v1/write</code>. For example:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><code>otlp</code>: <code>https://example-otlp-receiver.example.com:4317</code> (gRPC) or <code>https://example-otlp-receiver.example.com:4318</code> (HTTP)</p>\n</li>\n<li>\n<p><code>prometheusremotewrite</code>: <code>https://example-prometheus-remote.example.com/api/v1/write</code></p>\n</li>\n</ul>\n</div>\n</li>\n</ul>\n</div>\n</li>\n<li>\n<p>Click <strong>Save</strong>.</p>\n<div class=\"paragraph\">\n<p>The OpenTelemetry Collector automatically reloads its configuration and begins forwarding metrics to the specified external endpoint.</p>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Verification</div>\n<ol class=\"arabic\">\n<li>\n<p>Verify that the OpenTelemetry Collector pods restart and apply the new configuration:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc get pods -n opendatahub</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The <code>data-science-collector-collector-*</code> pods should restart and display a <strong>Running</strong> status.</p>\n</div>\n</li>\n<li>\n<p>In your external observability platform, verify that new metrics from Open Data Hub appear in the metrics list or dashboard.</p>\n</li>\n</ol>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>If you remove the <code>.spec.monitoring.metrics.exporters</code> configuration from the DSCI, the OpenTelemetry Collector automatically reverts to collecting metrics only for the in-cluster Prometheus instance.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"viewing-traces-in-external-tracing-platforms_managing-odh\">Viewing traces in external tracing platforms</h3>\n<div class=\"paragraph _abstract\">\n<p>When tracing is enabled in the <code>DataScienceClusterInitialization</code> (DSCI) custom resource, Open Data Hub deploys the Red Hat build of Tempo as the tracing backend and the Red Hat build of OpenTelemetry Collector (OTC) to receive and route trace data.</p>\n</div>\n<div class=\"paragraph\">\n<p>To view and analyze traces outside of Open Data Hub, complete the following tasks:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Configure your instrumented applications to send traces to the OpenTelemetry Collector.</p>\n</li>\n<li>\n<p>Connect your preferred visualization tool, such as Grafana or Jaeger, to the Tempo Query API.</p>\n</li>\n</ul>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>A cluster administrator has enabled tracing as part of the observability stack in the DSCI configuration.</p>\n</li>\n<li>\n<p>You have access to the monitoring namespace, for example <code>opendatahub</code>.</p>\n</li>\n<li>\n<p>You have network access or cluster administrator privileges to create a route or port forward from the cluster.</p>\n</li>\n<li>\n<p>Your application is instrumented with an OpenTelemetry SDK or library to generate and export trace data.</p>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Find the OpenTelemetry Collector endpoint.</p>\n<div class=\"paragraph\">\n<p>The OpenTelemetry Collector receives trace data from instrumented applications by using the OpenTelemetry Protocol (OTLP).</p>\n</div>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift Container Platform web console, navigate to <strong>Networking</strong>  <strong>Services</strong>.</p>\n</li>\n<li>\n<p>In the <strong>Project</strong> list, select the monitoring namespace, for example, <code>opendatahub</code>.</p>\n</li>\n<li>\n<p>Locate the Service named <code>data-science-collector</code> or a similar name associated with the OpenTelemetry Collector.</p>\n</li>\n<li>\n<p>Use the Service name or ClusterIP as the OTLP endpoint in your application configuration.</p>\n<div class=\"paragraph\">\n<p>Your application must export traces to one of the following ports on the collector service:</p>\n</div>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>gRPC: <code>4317</code></p>\n</li>\n<li>\n<p>HTTP: <code>4318</code></p>\n<div class=\"paragraph\">\n<p>Example environment variable:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">OTEL_EXPORTER_OTLP_ENDPOINT=http://data-science-collector.opendatahub.svc.cluster.local:4318</code></pre>\n</div>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>See the <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/red_hat_build_of_opentelemetry/index\">Red Hat build of OpenTelemetry documentation</a> for details about configuring application instrumentation.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n</ul>\n</div>\n</li>\n</ol>\n</div>\n</li>\n<li>\n<p>Connect your visualization tool to the Tempo query service.</p>\n<div class=\"paragraph\">\n<p>You can use a visualization tool, such as Grafana or Jaeger, to query and display traces from the Red Hat build of Tempo deployed by Open Data Hub.</p>\n</div>\n<div class=\"olist loweralpha\">\n<ol class=\"loweralpha\" type=\"a\">\n<li>\n<p>In the OpenShift Container Platform web console, navigate to <strong>Networking</strong>  <strong>Services</strong>.</p>\n</li>\n<li>\n<p>In the <strong>Project</strong> list, select the monitoring namespace, for example, <code>opendatahub</code>.</p>\n</li>\n<li>\n<p>Locate the Service named <code>tempo-query</code> or <code>tempo-query-frontend</code>.</p>\n</li>\n<li>\n<p>To make the service accessible to external tools, a cluster administrator must perform one of the following actions:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p>Create a route: Expose the Tempo Query service externally by creating an OpenShift route.</p>\n</li>\n<li>\n<p>Use port forwarding: Temporarily forward a local port to the Tempo Query service by using the OpenShift CLI (<code>oc</code>):</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc port-forward svc/tempo-query-frontend 3200:3200 -n opendatahub</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>After the port is forwarded, connect your visualization tool to the Tempo Query API endpoint, for example:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">http://localhost:3200</code></pre>\n</div>\n</div>\n<div class=\"admonitionblock note\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Note</div>\n</td>\n<td class=\"content\">\n<div class=\"paragraph\">\n<p>See the <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/distributed_tracing/distr-tracing-tempo-installing\">Tempo Operator documentation</a> for details about connecting to Tempo.</p>\n</div>\n</td>\n</tr>\n</table>\n</div>\n</li>\n</ul>\n</div>\n</li>\n</ol>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Verification</div>\n<ol class=\"arabic\">\n<li>\n<p>Confirm that your instrumented application is generating and exporting trace data.</p>\n</li>\n<li>\n<p>Verify that the OpenTelemetry Collector pod is running in the monitoring namespace:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc get pods -n opendatahub | grep collector</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The <code>data-science-collector-collector-*</code> pod should display a <strong>Running</strong> status.</p>\n</div>\n</li>\n<li>\n<p>Access your visualization tool and confirm that new traces appear in the trace list or search view.</p>\n</li>\n</ol>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"accessing-built-in-alerts_managing-odh\">Accessing built-in alerts</h3>\n<div class=\"paragraph _abstract\">\n<p>The centralized observability stack deploys a Prometheus Alertmanager instance that provides a common set of built-in alerts for Open Data Hub components.\nThese alerts monitor critical platform conditions, such as operator downtime, crashlooping pods, and unresponsive services.</p>\n</div>\n<div class=\"paragraph\">\n<p>By default, the Alertmanager is internal to the cluster and is not exposed through a route.\nYou can access the Alertmanager web interface locally by using the OpenShift CLI (<code>oc</code>).</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have Open Data Hub administrator privileges.</p>\n</li>\n<li>\n<p>The observability stack is enabled as described in <em>Enabling the observability stack</em>.</p>\n</li>\n<li>\n<p>You know the monitoring namespace, for example <code>opendatahub</code>.</p>\n</li>\n<li>\n<p>You have installed the OpenShift CLI (<code>oc</code>) as described in the appropriate documentation for your cluster:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/cli_tools/openshift-cli-oc#installing-openshift-cli\" target=\"_blank\" rel=\"noopener\">Installing the OpenShift CLI</a> for OpenShift Container Platform</p>\n</li>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/red_hat_openshift_service_on_aws/4/html/cli_tools/openshift-cli-oc#installing-openshift-cli\" target=\"_blank\" rel=\"noopener\">Installing the OpenShift CLI</a> for Red&#160;Hat OpenShift Service on AWS</p>\n</li>\n</ul>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In a terminal window, log in to the OpenShift CLI (<code>oc</code>) as a cluster administrator:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc login https://api.198.51.100.10:6443</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Verify that the Alertmanager pods are running in the monitoring namespace:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc get pods -n opendatahub | grep alertmanager</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>Example output:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">alertmanager-data-science-monitoringstack-0   2/2   Running   0   2h\nalertmanager-data-science-monitoringstack-1   2/2   Running   0   2h</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Confirm that a ClusterIP service exposes the Alertmanager web interface on port 9093:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc get svc -n opendatahub | grep alertmanager</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>Example output:</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">data-science-monitoringstack-alertmanager     ClusterIP   198.51.100.5   &lt;none&gt;   9093/TCP</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Start a local port forward to the Alertmanager service:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">$ oc port-forward svc/data-science-monitoringstack-alertmanager 9093:9093 -n opendatahub</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>In a web browser, open the following URL to access the Alertmanager web interface:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code class=\"language-terminal\" data-lang=\"terminal\">http://localhost:9093</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>Confirm that the Alertmanager web interface opens at <code>http://localhost:9093</code> and displays active alerts for Open Data Hub components.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>\n<div class=\"sect1\">\n<h2 id=\"viewing-logs-and-audit-records_managing-odh\">Viewing logs and audit records</h2>\n<div class=\"sectionbody\">\n<div class=\"paragraph _abstract\">\n<p>As a cluster administrator, you can use the Open Data Hub Operator logger to monitor and troubleshoot issues. You can also use OpenShift Container Platform audit records to review a history of changes made to the Open Data Hub Operator configuration.</p>\n</div>\n<div class=\"sect2\">\n<h3 id=\"configuring-the-operator-logger_managing-odh\">Configuring the Open Data Hub Operator logger</h3>\n<div class=\"paragraph _abstract\">\n<p>You can change the log level for Open Data Hub Operator components by setting the <code>.spec.devFlags.logmode</code> flag for the <strong>DSC Initialization</strong>/<code>DSCI</code> custom resource during runtime. If you do not set a <code>logmode</code> value, the logger uses the INFO log level by default.</p>\n</div>\n<div class=\"paragraph\">\n<p>The log level that you set with <code>.spec.devFlags.logmode</code> applies to all components, not just those in a <strong>Managed</strong> state.</p>\n</div>\n<div class=\"paragraph\">\n<p>The following table shows the available log levels:</p>\n</div>\n<table class=\"tableblock frame-all grid-all stretch\">\n<colgroup>\n<col style=\"width: 20%;\">\n<col style=\"width: 20%;\">\n<col style=\"width: 20%;\">\n<col style=\"width: 20%;\">\n<col style=\"width: 20%;\">\n</colgroup>\n<thead>\n<tr>\n<th class=\"tableblock halign-left valign-top\">Log level</th>\n<th class=\"tableblock halign-left valign-top\">Stacktrace level</th>\n<th class=\"tableblock halign-left valign-top\">Verbosity</th>\n<th class=\"tableblock halign-left valign-top\">Output</th>\n<th class=\"tableblock halign-left valign-top\">Timestamp type</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>devel</code> or <code>development</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">WARN</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">INFO</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Console</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Epoch timestamps</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>\"\"</code>  (or no <code>logmode</code> value set)</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">ERROR</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">INFO</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">JSON</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Human-readable timestamps</p></td>\n</tr>\n<tr>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\"><code>prod</code> or <code>production</code></p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">ERROR</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">INFO</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">JSON</p></td>\n<td class=\"tableblock halign-left valign-top\"><p class=\"tableblock\">Human-readable timestamps</p></td>\n</tr>\n</tbody>\n</table>\n<div class=\"paragraph\">\n<p>Logs that are set to <code>devel</code> or <code>development</code> generate in a plain text console format.\nLogs that are set to <code>prod</code>, <code>production</code>, or which do not have a level set generate in a JSON format.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have administrator access to the <code>DSCInitialization</code> resources in the OpenShift Container Platform cluster.</p>\n</li>\n<li>\n<p>You have installed the OpenShift CLI (<code>oc</code>) as described in the appropriate documentation for your cluster:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/cli_tools/openshift-cli-oc#installing-openshift-cli\" target=\"_blank\" rel=\"noopener\">Installing the OpenShift CLI</a> for OpenShift Container Platform</p>\n</li>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/red_hat_openshift_service_on_aws/4/html/cli_tools/openshift-cli-oc#installing-openshift-cli\" target=\"_blank\" rel=\"noopener\">Installing the OpenShift CLI</a> for Red&#160;Hat OpenShift Service on AWS</p>\n</li>\n</ul>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift Container Platform as a cluster administrator.</p>\n</li>\n<li>\n<p>Click <strong>Operators</strong>  <strong>Installed Operators</strong> and then click the Open Data Hub Operator.</p>\n</li>\n<li>\n<p>Click the <strong>DSC Initialization</strong> tab.</p>\n</li>\n<li>\n<p>Click the <strong>default-dsci</strong> object.</p>\n</li>\n<li>\n<p>Click the <strong>YAML</strong> tab.</p>\n</li>\n<li>\n<p>In the <code>spec</code> section, update the <code>.spec.devFlags.logmode</code> flag with the log level that you want to set.</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>apiVersion: dscinitialization.opendatahub.io/v2\nkind: DSCInitialization\nmetadata:\n  name: default-dsci\nspec:\n  devFlags:\n    logmode: development</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Click <strong>Save</strong>.</p>\n</li>\n</ol>\n</div>\n<div class=\"paragraph\">\n<p>You can also configure the log level from the OpenShift CLI (<code>oc</code>) by using the following command with the <code>logmode</code> value set to the log level that you want.</p>\n</div>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>oc patch dsci default-dsci -p '{\"spec\":{\"devFlags\":{\"logmode\":\"development\"}}}' --type=merge</code></pre>\n</div>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>If you set the component log level to <code>devel</code> or <code>development</code>, logs generate more frequently and include logs at <code>WARN</code> level and above.</p>\n</li>\n<li>\n<p>If you set the component log level to <code>prod</code> or <code>production</code>, or do not set a log level, logs generate less frequently and include logs at <code>ERROR</code> level or above.</p>\n</li>\n</ul>\n</div>\n<div class=\"sect3\">\n<h4 id=\"_viewing_the_open_data_hub_operator_logs\">Viewing the Open Data Hub Operator logs</h4>\n<div class=\"olist arabic\">\n<ol class=\"arabic\">\n<li>\n<p>Log in to the OpenShift CLI (<code>oc</code>).</p>\n</li>\n<li>\n<p>Run the following command to stream logs from all Operator pods:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>for pod in $(oc get pods -l name=opendatahub-operator -n openshift-operators -o name); do\n  oc logs -f \"$pod\" -n openshift-operators &amp;\ndone</code></pre>\n</div>\n</div>\n<div class=\"paragraph\">\n<p>The Operator pod logs open in your terminal.</p>\n</div>\n<div class=\"admonitionblock tip\">\n<table>\n<tr>\n<td class=\"icon\">\n<div class=\"title\">Tip</div>\n</td>\n<td class=\"content\">\nPress <code>Ctrl+C</code> to stop viewing. To fully stop all log streams, run <code>kill $(jobs -p)</code>.\n</td>\n</tr>\n</table>\n</div>\n</li>\n</ol>\n</div>\n</div>\n</div>\n<div class=\"sect2\">\n<h3 id=\"viewing-audit-records_managing-odh\">Viewing audit records</h3>\n<div class=\"paragraph _abstract\">\n<p>Cluster administrators can use OpenShift Container Platform auditing to see changes made to the Open Data Hub Operator configuration by reviewing modifications to the DataScienceCluster (DSC) and DSCInitialization (DSCI) custom resources. Audit logging is enabled by default in standard OpenShift Container Platform cluster configurations.\nFor more information, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/security_and_compliance/audit-log-view#audit-log-view\" target=\"_blank\" rel=\"noopener\">Viewing audit logs</a> in the OpenShift Container Platform documentation.</p>\n</div>\n<div class=\"paragraph\">\n<p>The following example shows how to use the OpenShift Container Platform audit logs to see the history of changes made (by users) to the DSC and DSCI custom resources.</p>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Prerequisites</div>\n<ul>\n<li>\n<p>You have cluster administrator privileges for your OpenShift Container Platform cluster.</p>\n</li>\n<li>\n<p>You have installed the OpenShift CLI (<code>oc</code>) as described in the appropriate documentation for your cluster:</p>\n<div class=\"ulist\">\n<ul>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/cli_tools/openshift-cli-oc#installing-openshift-cli\" target=\"_blank\" rel=\"noopener\">Installing the OpenShift CLI</a> for OpenShift Container Platform</p>\n</li>\n<li>\n<p><a href=\"https://docs.redhat.com/en/documentation/red_hat_openshift_service_on_aws/4/html/cli_tools/openshift-cli-oc#installing-openshift-cli\" target=\"_blank\" rel=\"noopener\">Installing the OpenShift CLI</a> for Red&#160;Hat OpenShift Service on AWS</p>\n</li>\n</ul>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"olist arabic\">\n<div class=\"title\">Procedure</div>\n<ol class=\"arabic\">\n<li>\n<p>In a terminal window, if you are not already logged in to your OpenShift Container Platform cluster as a cluster administrator, log in to the OpenShift Container Platform CLI as shown in the following example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>$ oc login <em>&lt;openshift_cluster_url&gt;</em> -u <em>&lt;admin_username&gt;</em> -p <em>&lt;password&gt;</em></code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>To access the full content of the changed custom resources, set the OpenShift Container Platform audit log policy to <code>WriteRequestBodies</code> or a more comprehensive profile. For more information, see <a href=\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/security_and_compliance/audit-log-policy-config#configuring-audit-policy_audit-log-policy-config\" target=\"_blank\" rel=\"noopener\">Configuring the audit log policy</a>.</p>\n</li>\n<li>\n<p>Fetch the audit log files that are available for the relevant control plane nodes. For example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>oc adm node-logs --role=master --path=kube-apiserver/ \\\n  | awk '{ print $1 }' | sort -u \\\n  | while read node ; do\n      oc adm node-logs $node --path=kube-apiserver/audit.log &lt; /dev/null\n    done \\\n  | grep opendatahub &gt; /tmp/kube-apiserver-audit-opendatahub.log</code></pre>\n</div>\n</div>\n</li>\n<li>\n<p>Search the files for the DSC and DSCI custom resources. For example:</p>\n<div class=\"listingblock\">\n<div class=\"content\">\n<pre class=\"highlight\"><code>jq 'select((.objectRef.apiGroup == \"dscinitialization.opendatahub.io\"\n                or .objectRef.apiGroup == \"datasciencecluster.opendatahub.io\")\n              and .user.username != \"system:serviceaccount:openshift-operators:redhat-ods-operator-controller-manager\"\n              and .verb != \"get\" and .verb != \"watch\" and .verb != \"list\")' &lt; /tmp/kube-apiserver-audit-opendatahub.log</code></pre>\n</div>\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ulist\">\n<div class=\"title\">Verification</div>\n<ul>\n<li>\n<p>The commands return relevant log entries.</p>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>","id":"46c66196-c4a1-5cc4-abc9-aa6651624fd2","document":{"title":"Managing Open Data Hub"}},"markdownRemark":null},"pageContext":{"id":"46c66196-c4a1-5cc4-abc9-aa6651624fd2"}},"staticQueryHashes":["2604506565"],"slicesMap":{}}